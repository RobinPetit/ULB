\documentclass{report}

\usepackage{hyperref}
\usepackage[french]{babel}
\usepackage{commath}
\usepackage{palatino, eulervm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage[bottom]{footmisc}
\usepackage[parfill]{parskip}

\title{Calcul différentiel et intégral II}
\author{R. Petit}
\date{année académique 2016 - 2017}

% amsthm
\newtheorem{thm}{Théorème}[chapter]
\newtheorem{prp}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollaire}
\renewcommand{\proofname}{\it{Démonstration}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}[chapter]

\newcommand{\K}{\mathbb K}
\newcommand{\C}{\mathbb C}
\newcommand{\R}{\mathbb R}
\newcommand{\Rp}{\R^{+}}
\newcommand{\Rm}{\R^{-}}
\newcommand{\Q}{\mathbb Q}
\newcommand{\Z}{\mathbb Z}
\newcommand{\N}{\mathbb N}
\newcommand{\Ns}{\N^{*}}
\newcommand{\tq}{\text{ t.q. }}
\DeclareMathOperator{\Mat}{Mat}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\adh}{adh}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% sequence; parameters: sequence letter, sequence index, index set
\newcommand{\seq}[3]{\left(#1_{#2}\right)_{#2 \in #3}}
% sequence of instanciated function; parameters: sequence function letter, sequence index, function variable name, index set
\newcommand{\seqf}[4]{\left(#1_{#2}\left(#3\right)\right)_{#2 \in #4}}
% metric set convergence; parameters: variable name, variable limit, distance function
\newcommand{\mconv}[3]{\xrightarrow[#1 \to #2]{#3}}
% Convergence
\newcommand{\CONV}[5]{\xrightarrow[#2 \to #3]{#4 \text{ #5 } #1}}
% Simple convergence
\newcommand{\CVS}[3]{\CONV{#1}{#2}{#3}{CVS}{sur}}
% Simple convergence on compacts
\newcommand{\CVSc}[3]{\CONV{#1}{#2}{#3}{CVS}{sur tout cpct de}}
% uniform convergence
\newcommand{\CVU}[3]{\CONV{#1}{#2}{#3}{CVU}{sur}}
% uniform convergence on compacts
\newcommand{\CVUc}[3]{\CONV{#1}{#2}{#3}{CVU}{sur tout cpct de}}

\newcommand{\El}[2]{\mathcal E\!\left(#1, #2\right)}

\newcommand{\restr}[2]{\left.#1\vphantom{\big|}\right|_{#2}}
\newcommand{\intint}[2]{\left\llbracket#1, #2\right\rrbracket}
\newcommand{\scpr}[2]{\left\langle #1, #2\right\rangle}

\newcommand{\evfn}[3]{\left(#1\left(#2, #3\right), \norm {\cdot}_{\infty}\right)}
\newcommand{\evnC}[3]{{\evfn {C^{#1}}{#2}{#3}}}
\newcommand{\evnCb}[3]{{\evfn {C_b^{#1}}{#2}{#3}}}
\newcommand{\toC}[1]{\xrightarrow{C^{#1}}}
\newcommand{\tocont}{\toC 0}
\newcommand{\minfty}{{-\infty}}
\newcommand{\pinfty}{{+\infty}}
\newcommand{\grantedproof}{\begin{proof} \underline{Admis.} \end{proof}}
\newcommand{\evn}{espace vectoriel normé}
\newcommand{\evnc}{{\evn} complet}
\newcommand{\CDII}{{CDI 1}}
\newcommand{\CDIII}{{CDI 2}}

\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

\begin{document}

\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

\part{Fonctions, séries et intégrales}
\chapter{Suites et séries de fonctions}
	\section{Rappels}
		\subsection{Topologie métrique}
			\subsubsection{Espaces métriques}
				\begin{déf} Soit $X$ un ensemble. Une \textit{distance} sur $X$ est une application $d : X \times X \to \Rp$ telle que~:

				\begin{enumerate}
					\item $\forall x, y \in X : d(x, y) = d(y, x)$ (symétrie)~;
					\item $\forall x, y, z \in X : d(x, z) \leq d(x, y) + d(y, z)$ (inégalité triangulaire)~;
					\item $\forall x, y \in X : \left(d(x, y) = 0 \iff x = y\right)$ (séparation\footnote{Également appelé
					      \textit{principe d'identité des indiscernables.}}).
				\end{enumerate}
				\end{déf}

				\begin{déf}  On appelle \textit{espace métrique} $(X, d)$ un espace $X$ muni d'une distance $d$ sur $X$. \end{déf}

				\begin{déf} Soient $(X, d)$ un espace métrique, $\seq xn\N$ et $x \in X$ La suite $(x_n)$ converge vers $x$ dans $(X, d)$ lorsque~:
				\[\forall \varepsilon > 0 : \exists N \in \N \tq \forall n \geq \N : d(x_n, x) < \varepsilon.\]

				Cela se note~:
				\[x_n \mconv n\pinfty d x.\]
				\end{déf}

				\begin{prp} Soit $\seq xn\N$ une suite dans $(X, d)$, un espace métrique. Soient $x, y \in X$. Si~:
				\[x_n \mconv n\pinfty d x \qquad\qquad \text{et} \qquad\qquad x_n \mconv n\pinfty d y,\]
				alors $x = y$. \end{prp}

				\begin{proof} Soit $\varepsilon > 0$. Puisque $x_n \to x$ et $x_n \to y$, on sait qu'il existe $N_1, N_2 \in \N$ tels que~:
				\[\forall n \geq N_1 : d(x_n, x) < \frac \varepsilon2 \qquad\qquad \text{et} \qquad\qquad \forall n \geq N_2 : d(x_n, y) < \frac \varepsilon2.\]

				Dès lors, soit $N \coloneqq \max\{N_1, N_2\}$. On peut dire~:
				\[\forall n \geq N : d(x, y) \leq d(x, x_n) + d(x_n, y) < \frac \varepsilon2 + \frac \varepsilon2 = \varepsilon.\]

				On en déduit $d(x, y) = 0$ et donc $x = y$ par séparation. \end{proof}

			\subsubsection{Espaces vectoriels}
				\begin{déf} Soit $\K$, un sous-corps de $\C$. On appelle \textit{norme} sur le $\K$-e.v. $E$ toute application $n : E \to \Rp$ telle que~:

				\begin{enumerate}
					\item $\forall x \in E : \left(n(x) = 02 \iff x = 0\right)$~;
					\item $\forall x \in E : \forall \lambda \in \K : n(\lambda x) = \abs \lambda n(x)$~;
					\item $\forall x, y \in E : n(x + y) \leq n(x) + n(y)$.
				\end{enumerate}
				\end{déf}

				\begin{prp} Soit $(E, n)$ un $\K$-\evn. L'application $d$ suivante est une distance sur $E$ (on l'appelle la
				\textit{distance associée à la norme $n$})~:
				\[d : E \times E \to \Rp : (x, y) \mapsto n(y-x).\]
				\end{prp}

				\begin{proof} EXERCICE.
				\end{proof}

				\begin{rmq} Si $(E, n)$ est un \evn, $\seq xn\N$ est une suite de $E$, et si $x \in E$, alors on dit~:
				\[x_n \mconv n\pinfty n x\]
				lorsque~:
				\[x_n \mconv n\pinfty{} x\]
				au sens de la distance associée à la norme $n$.
				\end{rmq}

				\begin{ex} $\R$ est un $\R$-e.v. normé avec pour norme $n : x \mapsto \abs x$. \end{ex}

				\begin{ex} Soient $d \in \Ns$, $p \in [1, \pinfty)$. Pour $x = (x_i)_{1 \leq i \leq d} \in \C^d$, on définit~:
				\[n(x) = \norm x_p \coloneqq \left(\sum_{k=0}^d\abs {x_i}^p\right)^{\frac 1p}.\]
				On a alors $(\C^d, n)$ est un $\C$-\evn. Également $(\C^d, n)$ et $(\R^d, n)$  sont des $\R$-espaces vectoriels normés.
				\end{ex}

				\begin{déf} Soit $x \in \C^d$. On définit la \textit{norme infinie} de $x$ dans $\C^d$ par~:
				\[\norm x_\infty \coloneqq \max_{1 \leq i \leq d}\abs {x_i}.\]
				\end{déf}

				\begin{ex} Soit $d \in \Ns$. $(\C^d, \norm \cdot_\infty)$ est un $\C$-\evn. Également, $(\R^d, \norm \cdot_\infty)$
				et $(\C^d, \norm \cdot_\infty)$ sont des $\R$-espaces vectoriels normés. \end{ex}

				\begin{proof} EXERCICE.
				\end{proof}

				\begin{déf} Soit $\seq xn\N$ une suite. On dit que la suite $(x_n)$ est \textit{presque nulle} s'il existe $N \in \N$ tel que
				$\forall n \geq N : x_n = 0$. \end{déf}

				\begin{ex} Soient $P \in \C[x]$ et $\seq ak\N$ la suite presque nulle des coefficients de $P$. On pose~:
				\[\norm P_\infty \coloneqq \sup_{k \in \N}\abs {a_k} = \max_{k \in \N}\abs {a_k}.\]

				Alors $\norm \cdot_\infty$ est une norme sur $\C[x]$.
				\end{ex}

				\begin{proof} EXERCICE.
				\end{proof}

			\subsubsection{Ouverts, fermés, compacts}
				\begin{déf} Soit $(X, d)$ un espace métrique. On appelle \textit{boule ouverte} de centre $x \in X$ et de rayon $r \gneqq 0$ l'ensemble~:
				\[B(x, r[ \coloneqq \left\{y \in X \tq d(x, y) \lneqq r\right\}.\]

				On définit également la \textit{boule fermée} de centre $x$ et de rayon $r$ l'ensemble~:
				\[B(x, r] \coloneqq \{y \in X \tq d(x, y) \leq r\}.\]
				\end{déf}

				\begin{déf} Soit $(X, d)$ un espace métrique et soit $O \subset X$. On dit que $O$ est une partie \textit{ouvert} dans $X$ lorsque~:
				\[\forall x \in O : \exists r \gneqq 0 \tq B(x, r)  \subset O.\]
				\end{déf}

				\begin{rmq} Pour tout $X$, les ensembles $\emptyset$ et $X$ sont tous deux des ouverts de $X$. \end{rmq}

				\begin{déf} Soit $(X, d)$ un espace métrique. Une partie $F \subset X$  de $X$ est dite \textit{fermée} dans $X$ lorsque $X \setminus F$
				est ouvert. \end{déf}

				\begin{prp} Dans un espace métrique $(X, d)$, soit $\seq OiI$ une famille d'ouverts de $X$ indicés par un ensemble $I \neq \emptyset$.
				Alors $\left(\bigcup_{i \in I}O_i\right)$ est un ouvert de $X$. Si de plus $I$ est fini, alors $\left(\bigcap_{i \in I}\right)$ est
				un ouvert de $X$. \end{prp}

				\begin{ex} Prenons $X = \R$ et $O_i = (-1-\frac 1i, 1 + \frac 1i)$. Alors $\left(\bigcap_{i \in \Ns}O_i\right) = [-1, 1]$ qui n'est pas
				un ouvert de $X$. \end{ex}

				\begin{proof} EXERCICE.
				\end{proof}

				\begin{déf}[Compacts par Borel-Lebesgue] Soit $(X, d)$ un espace métrique. Une partie $K \subset X$ est dite \textit{compacte} si
				$K \neq \emptyset$ et si, de tout recouvrement de $K$ par des ouverts de $X$, on peut extraire un sous-recouvrement fini.

				C'est-à-dire lorsque~:
				\begin{enumerate}
					\item $K \neq \emptyset$~;
					\item $\forall I \neq \emptyset : \forall \seq OiI$ ouverts de $X \tq K \subset \left(\bigcup_{i \in I}O_i\right) : \exists J \subset I$
					      fini $\tq K \subset \left(\bigcup_{j \in J}O_j\right)$.
				\end{enumerate}
				\end{déf}

				\begin{prp}[Compacts par Bolzano-Weierstrass] Soit $(X, d)$ un espace métrique. Une partie $K$ de $X$ est compacte si et seulement si~:

				\begin{enumerate}
					\item $K \neq \emptyset$~;
					\item de toute suite de points de $K$, on peut extraire une sous-suite convergente dans $K$.
				\end{enumerate}
				\end{prp}

				\grantedproof

				\begin{ex} L'ensemble $[0, 1]$ est un compact de $\R$. \end{ex}

				\begin{prp} Soit $(X, d)$, un espace métrique et $K \subset X$, une partie compacte. Alors $K$ est fermé et borné. \end{prp}

				\begin{proof} EXERCICE. (Absurde)
				\end{proof}

				\begin{prp} Soit $(E, n)$ un $\K$-e.v. normé de dimension finie. Alors les parties compactes de $E$ sont les parties fermées
				bornées non nulles. \end{prp}

				\grantedproof

			\subsubsection{Suites de Cauchy}
				\begin{déf} Soit $(X, d)$, un espace métrique. On dit que $\seq xn\N$ est \textit{de Cauchy} dans $X$ lorsque~:
				\[\forall \varepsilon > 0 : \exists N \in \N \tq \forall m, n \geq N : d(x_n, x_m) < \varepsilon.\]
				\end{déf}

				\begin{prp} Si $\seq xn\N$ est convergente dans l'espace métrique $(X, d)$, alors elle est de Cauchy. \end{prp}

				\begin{proof} Si $x$ est la limite de la suite $(x_n)$, on pose $\varepsilon > 0$. Il existe $N \in \N$ tel que~:
				\[\forall n \geq \N : d(x, x_n) < \frac \varepsilon2.\]

				Donc $\forall m, n \geq N : d(x_m, x_n) \leq d(x_m, x) + d(x, x_n) < \varepsilon$.
				\end{proof}

				\begin{déf} Un espace métrique $(M, d)$ est dit \textit{complet} quand toute suite de Cauchy de points de $X$ converge dans $X$. \end{déf}

				\begin{déf} Un espace vectoriel $E$ est dit \textit{de Banach} lorsque toute suite de Cauchy de vecteurs de $E$ converge dans $E$. \end{déf}

				\begin{rmq} On remarque que dans un espace métrique complet, une suite converge si et seulement si elle est de Cauchy
				(ce qui est entre autres le cas de $\R$).

				De plus, les suites de Cauchy permettent, dans des espaces complets, de montrer que des suites convergent sans connaitre leur limite. \end{rmq}

				\begin{ex} Les espaces métriques $(\R, \abs \cdot)$ et $(\C, \abs \cdot)$ sont des espaces de Banach. Et pour tout $p \in [1, \pinfty)$ et
				$q \in \N$, les espaces métriques $(\R^q, \norm \cdot_p)$ et $(\C^q, \norm \cdot_p)$ sont des espaces de Banach. \end{ex}

			\subsubsection{Continuité}
				\begin{déf} Soient $(X, d_X)$ et $(Y, d_Y)$ deux espaces métriques. Une application $f : X \to Y$ est dite continue en $x_0 \in X$ lorsque~:
				\[\forall \varepsilon > 0 : \exists \delta \gneqq 0 \tq \forall x \in X :
					\left(d_X(x, x_0) < \delta \Rightarrow d_X(f(x), f(x_0)) < \varepsilon\right).\]

				On dit que $f$ est continue sur $A \subset X$ lorsque $f$ est continue en tout $a \in A$.
				\end{déf}

				\begin{prp} Une fonction $f : (X, d) \to (Y, d)$ est continue sur $X$ lorsque l'image réciproque par $f$ de $(Y, d)$ est un ouvert de $(X, d)$.
				\end{prp}

				\grantedproof

				\begin{prp} Une fonction $f : (X, d) \to (Y, d)$ est continue en $x_0 \in X$ si et seulement si l'image par $f$ de toute suite de points de
				$X$ convergente en $x_0$ est une suite convergente en $f(x_0)$. \end{prp}

				\grantedproof

				\begin{déf} Soit $f : (X, d) \to (Y, d)$. $f$ est dite \textit{lipschitzienne} de constante $K \geq 0$ lorsque~
				\[\forall (x, y) \in X^2 : d(f(x), f(y)) \leq d(x, y).\]
				\end{déf}

				\begin{prp} Si $f : (X, d) \to (Y, d)$ est lipschitzienne, alors elle est continue sur $X$. \end{prp}

				\begin{proof} EXERCICE.
				\end{proof}

				\begin{déf} Soit $\seq ak\N$, une suite dans un espace métrique $(X, d)$. On dit que $(a_k)$ est \textit{presque nulle} lorsqu'il existe
				$N \in \N$ tel que $\forall n \geq N : a_n = 0$. \end{déf}

				\begin{ex}~
				\begin{itemize}
					\item Pour tout $i \in \N$, l'application $c_i : \C[x] \to \C : P = \sum_{k=0}^\pinfty a_kx^k \mapsto a_i$ est continue de
					      $(\C[x], \norm \cdot_\infty)$ dans $(\C, \abs \cdot)$. En effet, pour $i \in \N$, $P = \sum_{k=0}^\pinfty a_kx^k$, et
					      $Q = \sum_{k=0}^\pinfty b_kx^k$, on a~:
						  \[\abs{c_i(P) - c_i(Q)} = \abs{a_i - b_i} \leq \norm{P-Q}_\infty = \max_{k \in \N}\abs{a_k - b_k}.\]

					      On en déduit que $c_i$ est lipschitzienne sur $\C[x]$ et donc continue sur $\C[x]$.
					\item Soit $n \in \N$. Posons~:
					      \[P_n = \sum_{k=0}^n\frac 1{k!}x^k \in \C[x].\]

					      On observe que $\seq Pn\N$ est de Cauchy dans $(\C[x], \norm \cdot_\infty)$ car~:
					      \[\norm{P_n - P_m}_\infty = \norm{\sum_{k=0}^n\frac 1{k!}x^k - \sum_{k=0}^m\frac 1{k!}x^k}_\infty.\]

					      On a alors~:
					      \[\norm{P_n - P_m}_\infty = \norm {\sum_{k=\min\{m, n\}+1}^{\max\{m, n\}}\frac 1{k!}x^k}_\infty =
					      	\max_{\min\{m, n\}+1 \leq k \leq \max\{m, n\}}\frac 1{k!} = \frac 1{(\min\{m, n\}+1)!}.\]

					      Montrons que $\seq Pn\N$ est de Cauchy. Supposons (par l'absurde) que $\seq Pn\N$ converge vers $P \in (\C[x], \norm \cdot_\infty)$.
					      Notons $(a_k) \subset \C$, la suite presque nulle des coefficients de $P$. Pour $i \in \N$, on a $c_i(P) = \frac 1{i!}$ quand
					      $n \geq i$. Or par la propriété de Lipschitz, on sait que $c_i(P_n) \mconv n\pinfty{} c_i(P) = a_i$. Or $(a_k)$ est presque nulle et
					      $a_i = \frac 1{i!}$. Il y a donc contradiction. Donc $(P_n)$ ne converge pas dans $(\C[x], \norm \cdot_\infty)$. Dès lors,
					      $(\C[x], \norm \cdot_\infty)$ n'est pas complet.
				\end{itemize}
				\end{ex}

	\section{Convergence de suites de fonctions}
		\subsection[Convergence simple]{Convergence simple\protect\footnote{La convergence simple est la notion de convergence «~minimale~» que l'on va exiger.
		Il existe des convergences encore plus élémentaires (voir théorie de l'intégration de Lebesgue), mais qui se trouvent en dehors des objectifs du cours.}}
			\begin{déf} Soit $X$ un ensemble et $(Y, d)$ un espace métrique. On dit que la suite $\seqf fnx\N$ où $f_n : X \to (Y, d)$
			\textit{converge simplement} sur $X$ lorsque~:
			\[\forall x \in X : \seqf fnx\N \text{converge dans } (Y, d).\]
			\end{déf}

			\begin{déf} Dans ce cas, la suite a pour limite simple la fonction~:
			\[f : X \to (Y, d) : x \mapsto \lim_{n \to \pinfty}f_n(x)\]
			et est bien définie. Cela se note~:
			\[f_n \xrightarrow[n \underset{X}{\to} \pinfty]{CVS} f \qquad\qquad \text{ou} \qquad\qquad f_n \CVS Xn\pinfty f.\]
			\end{déf}

			\begin{ex} Soient $X = [0, 1]$ et $Y = \R$. On pose $f_n(x) = x^n$ pour tout $n \in \N$.
			\begin{itemize}
				\item Si $x \in [0, 1)$, alors la suite $\seqf fnx\N$ est une suite géométrique de raison $x$ avec $\abs x < 1$ donc la suite converge vers 0~;
				\item si $x = 1$,a lors $f_n(x) = 1$ pour tout $n \in \N$. Donc la suite $\seqf fnx\N$ converge simplement sur $[0, 1]$ vers la fonction~:
				      \[f : [0, 1] \to \R : x \mapsto \begin{cases}0 &\text{ si } x  < 1 \\ 1 &\text{ si } x = 1\end{cases}.\]
			\end{itemize}
			\end{ex}

			\begin{rmq}~
			\begin{itemize}
				\item On a «~perdu~» la continuité des fonctions $f_n$ par passage à la limite~;
				\item ici, la convergence simple peut s'écrire ainsi, à l'aide de quantificateurs~:
				      \[\forall \varepsilon > 0 : \forall x \in X : \exists N \in \N \tq \forall n \geq N : d(f_n(x), f(x)) < \varepsilon.\]

				      On remarque donc que $N$ dépend de $x$ (ordre des quantificateurs).
			\end{itemize}
			\end{rmq}

		\subsection{Convergence uniforme}
			\begin{déf} Soient $X$ un ensemble, $(Y, d)$ un espace métrique, et $f_n : X \to (Y, d)$. On dit que $(f_n)$ \textit{converge uniformément} sur $X$
			vers $f : X \to (Y, d)$ lorsque~:
			\[\forall \varepsilon > 0 : \exists N \in \N \tq \forall n \geq N : \forall x \in X : d(f_n(x), f(x)) < \varepsilon.\]

			Cela se note~:
			\[f_n \CVU Xn\pinfty f.\]
			\end{déf}

			\begin{rmq} La définition est très proche de la convergence simple. La différence étant que pour une convergence uniforme, il faut que
			$N \in \N$ ne dépende pas de la valeur de $x$. \end{rmq}

			\begin{prp} Soient $X$ un ensemble, $(Y, d)$ un espace métrique, $\seqf fnx\N$ une suite de fonctions de $X$ dans $(Y, d)$ et $f : X \to (Y, d)$.
			Si $(f_n)$ converge uniformément sur $X$ vers $f$, alors $(f_n)$ converge simplement sur $X$ vers $f$. \end{prp}

			\begin{proof} EXERCICE.
			\end{proof}

			\begin{ex} Prenons $X = \R = Y$ et pour tout $n \geq 1$, définissons $f_n(x) = \sqrt{x^2 + \frac 1n}$. Fixons $x \in \R$. On trouve alors~:
			\[\seqf fnx\N = \seq {\sqrt{x^2 + \frac 1n}}n\N \to \sqrt {x^2} = \abs x.\]

			Donc~:
			\[f_n \CVS Xn\pinfty \abs \cdot.\]
			\end{ex}

			\begin{thm} Soient $(X, d)$, $(Y, d)$ deux espaces métriques. Soient $f_n : X \to Y$, $a \in X$. On suppose~:
			\begin{itemize}
				\item $\exists f \tq f_n \CVU Xn\pinfty f$~;
				\item $\forall n \in \N : f_n$ est continue en $a$.
			\end{itemize}

			Alors $f$ est continue en $a$.
			\end{thm}

			\begin{proof}  Soit $\varepsilon > 0$. Par convergence uniforme des $f_n$, on sait~:
			\[\exists N \in \N \tq \forall n \geq N : \forall x \in X : d(f_n(x), f(x)) < \frac \varepsilon3.\]

			De plus, la fonction $f_N$ est continue en $a$ par hypothèse. Dès lors, on sait qu'il existe $\delta$ tel que~:
			\[\forall x \in X : d(x, a) < \delta \Rightarrow d(f_N(x), f_N(a)) < \frac \varepsilon3.\]

			Ainsi, prenons $x \in X$ tel que $d(x, a) < \delta$. On a alors~:
			\[d(f(x), f(a)) \leq d(f(x), f_N(x)) + d(f_N(x), f(a)) \leq d(f(x), f_N(x)) + d(f_N(x), f_N(a)) + d(f_N(a), f(a)) \leq 3\frac \varepsilon3 = \varepsilon.\]
			\end{proof}

			\begin{cor} Si $f_n \in C^0(X, Y)$ et $f_n \CVU Xn\pinfty$, alors $f \in C^0(X, Y)$. \end{cor}

			\begin{proof} Les fonctions $f_n$ sont continues en tout point et $f_n \CVU Xn\pinfty$ par hypothèse. Dès lors, pour tout point $a \in X$, par le
			théorème précédent, on peut dire $f$ continue en $a$. Dès lors $f \in C^0(X, Y)$.
			\end{proof}

		\subsection{L'espace $B(X, E)$}
			\begin{déf} Soient $X \neq \emptyset$ et $(E, \norm \cdot_E)$ un \evn. On note~:
			\[B(X, E) \coloneqq \left\{f : X \to E \tq f \text{ est bornée sur } X\right\}.\]

			Pour $f \in B(X, E)$, on définit~:
			\[\norm f_\infty \coloneqq \sup_{x \in X}\norm {f(x)}_E.\]
			\end{déf}

			\begin{prp} $\left(B(X, E), \norm \cdot_\infty\right)$ est un \evn. \end{prp}

			\begin{proof} EXERCICE.
			\end{proof}

			\begin{thm}\label{thm:BXEcpltssiEcplt} $\left(B(X, E), \norm \cdot_\infty\right)$ est complet si et seulement si $(E, \norm \cdot_E)$ est complet.
			\end{thm}

			\begin{proof} Supposons d'abord $\left(B(X, E), \norm \cdot_\infty\right)$ complet et montrons que $(E, \norm \cdot_E)$ est complet.

			Soit $(x_n)_n$ une suite de Cauchy d'éléments de $E$. Soit $(f_n)$ une suite de fonctions de $B(X, E)$ telle que~:
			\[\forall n \in \N : \forall x \in X : f_n(x) = x_n.\]

			Puisque $(x_n)$ est de Cauchy, on sait que~:
			\[\forall \varepsilon > 0 : \exists N \in \N \tq \forall m, n \geq N : d(x_m, x_n) < \varepsilon.\]
			Or, avec $a \in X$ fixé, on peut alors dire $\forall m, n \geq N : d(f_m(a), f_n(a)) < \varepsilon$, et ce peu importe le $a$ choisi (car les
			$f_n$ sont constantes). On a donc $(f_n)$ une suite de Cauchy dans $B(X, E)$ car $d(f_m(a), f_n(a)) = \norm {f_m - f_n}_\infty$. Or, par
			complétude de $B(X, E)$, on sait qu'il existe $f \in B(X, E)$ telle que $f_n \to f$. La fonction $f$ est également constante. Posons $L$ la seule
			image de $f$. Soit $\varepsilon > 0$. On sait qu'il existe $n \in \N$ tel que $\forall n \geq N : \norm {f_n - f}_\infty < \varepsilon.$

			Or~:
			\[\varepsilon > \norm {f_n - f}_\infty = \sup_{x \in X} \norm {f_n(x) - f(x)}_E = \norm {f_n(a) - f(a)}_E = \norm {x_n - L}.\]
			Dès lors, on sait que $(x_n)$ converge dans $E$.

			Montrons maintenant que si $(E, \norm \cdot_E)$ est complet, alors $(B(X, E), \norm \cdot_\infty)$ est complet également.

			Soit $(f_n)_n$ une suite de Cauchy de fonctions de $(B(X, E), \norm \cdot_\infty)$. Fixons $\varepsilon > 0$. Il existe alors $N \in \N$ tel que~:
			\[\forall m, n \geq N : \norm {f_m - f_n}_\infty < \varepsilon.\]

			Soit $x \in X$. On observe que~:
			\[\forall m, n \geq N : \norm {f_n(x) - f_m(x)}_E \leq \norm {f_n - f_m}_\infty < \varepsilon.\]
			La suite $(f_n(x))_n$ est donc une suite de Cauchy dans $(E, \norm \cdot_E)$. Par complétude de $E$, on sait qu'il existe $f(x) \in E$ tel que
			$f_n(x) \to f(x)$. Montrons maintenant que $f \in B(X, E)$.

			La suite $(f_n)_n$ est de Cauchy et donc bornée. Soit $M \gneqq 0$ tel que $\forall n \in \N : \norm {f_n}_\infty < M$. Passons à la limite dans
			$(B(X, E)$. On a alors~:
			\[\forall n \in \N : \forall x \in X : \norm {f(x)}_E < M.\]

			Ainsi, $f \in B(X, E)$ par définition.

			Soit alors $\varepsilon > 0$. Pour tout $m, n \in \N$ et pour tout $x \in X$, on a~:
			\[\norm {f_n(x) - f_m(x)}_E  \leq \norm {f_n - f_m}_\infty \leq \varepsilon.\]

			Passons alors à la limite e $m$, ce qui donne~:
			\[\norm {f_n(x) - f(x)}_E \leq \norm {f_n - f}_\infty \leq \varepsilon.\]
			Dès lors~:
			\[\forall n \geq N : \norm {f_n - f}_\infty \leq \varepsilon.\]
			\end{proof}

			\begin{rmq} Quand $X \neq \emptyset$ et $Y = E$ est un \evn, on a~:
			\[f_n \CVU Xn\pinfty f \iff
				\begin{cases}&\exists N \in \N \tq \forall n \geq N : f_n - f \in B(X, E) \\ &f_n - f \xrightarrow[n \to \pinfty]{\norm \cdot_\infty} 0\end{cases}.\]
			\end{rmq}

		\subsection{Convergence uniforme sur tout compact}
			\begin{déf} Soit $X$, une partie non-vide d'un \evn de dimension finie $(E, \norm \cdot_E)$. Soit $(Y, d)$ un espace métrique.
			Une suite $f_n : X \to Y$ converge uniformément vers $f : X \to Y$ sur tout compact lorsque~:
			\[\forall \text{ compact } K \subset X : \restr {f_n}K \CVU Kn\pinfty \restr fK.\]

			Cela se note~:
			\[f_n \CVUc Xn\pinfty f.\]
			\end{déf}

			\begin{prp}\label{prp:cvuccontinues} Si la suite $f_n$ converge uniformément sur tout compact de $X$ et si toutes les fonctions $f_n$ sont continues
			en $a \in X$, alors $f$ est continue en $a$.
			\end{prp}

			\begin{proof} EXERCICE.
			\end{proof}

			\begin{ex} Prenons $X = Y = \R$. On définit $f_n(x) = \sum_{k=0}^n\frac {x^k}{k!}$. On a alors $f_n \CVS Xn\pinfty \exp$.

			De plus~:
			\[\norm {f_n - \exp}_\infty = \sup_{x \in \R} \abs {\sum_{k=0}^n\frac {x^k}{k!} - \exp(x)} = \pinfty.\]
			Donc $f_n$ ne converge pas uniformément vers $\exp$. Montrons maintenant que $f_n$ converge uniformément vers $\exp$ sur tout compact de $\R$.
			Soit $K \subset \R$ un compact. On sait qu'il existe $a, b \in \R, a < b$ tels que $K \subset [a, b]$. Pour $x \in [a, b]$, par Lagrange, on a~:
			\[\exp(x) - \sum_{k=0}^n\frac {x^k}{k!} = \frac {x^{n+1}}{(n+1)!}\exp(c_x),\]
			avec $c_x \in [a, b]$.

			Ainsi~:
			\[\abs {\exp(x) - \sum_{k=0}^n\frac {x^k}{k!}} \leq \frac {(b-a)^{n+1}}{(n+1)!}\sup_{x \in [a, b]}\exp(x) \xrightarrow[n \to \pinfty]{} 0.\]

			D'où $f_n \xrightarrow[n \to \pinfty]{[a, b]} f$ et donc la convergence uniforme sur tout compact de $f_n$ vers $f$.
			\end{ex}

	\section{Suites de fonctions et opérations d'intégration et de dérivation}
		\subsection{Passage à la limite dans une intégrale de Riemann}
			Soit $X$ un pavé de $\R^d$ (donc $X = \prod_{i=1}^d[a_i, b_i]$ avec $a_i < b_i \forall i \in \{1, \ldots, d\}$).

			\begin{thm} Soit $f_n : X \to \R$ intégrables au sens de Riemann sur $X$. Supposons $f_n \CVU Xn\pinfty f$. Alors~:
			\begin{itemize}
				\item $f$ est intégrable au sens de Riemann~;
				\item la $\left(\int_X f_n(x)\dif x\right)_n$ converge vers $\int_Xf(x)\dif x$.\footnote{Cela veut dire que~:
					\[\lim_{n \to \pinfty}\int_X f_n(x)\dif x = \int_X \lim_{n \to \pinfty} f_n(x)\dif x.\]}
			\end{itemize}
			\end{thm}

			\begin{proof} On note $\mathcal E(X, \R) \coloneqq \{f : X \to \R \tq f \text{ est élémentaire}\}$.

			Soit $\varepsilon > 0$. Par la convergence uniforme, on sait qu'il existe $N \in \N$ tel que~:
			\[\forall n \geq N : \norm {f_n - f}_\infty \leq \frac \varepsilon{4\abs X},\]
			où $\abs X = \prod_{i=1}^d(b_i - a_i)$.

			Par intégrabilité de $f_N$, on sait qu'il existe $\varphi, \psi \in \mathcal E(X, \R)$ telles que~:
			\[\psi \leq f_N \leq \varphi \qquad\qquad \text{ et } \qquad\qquad \int_X(\varphi - \psi) < \frac \varepsilon2.\]

			On a alors~:
			\[\psi - f_N \leq f \leq \varphi + f_N,\]
			ou encore~:
			\[\psi - \frac \varepsilon{4\abs X} \leq f \leq \varphi + \frac \varepsilon{4\abs X}.\]

			En posant $\overline \psi \coloneqq \psi - \frac \varepsilon{4\abs X}$ et $\overline \varphi \coloneqq \varphi + \frac \varepsilon{4\abs X}$, on a
			$\overline \psi, \overline \varphi \in \mathcal E(X, \R)$. De plus~:
			\[\int_X(\psi-\varphi) = \int_X\left(\psi + \frac \varepsilon{4\abs X} - \left(\varphi - \frac \varepsilon{4\abs X}\right)\right)
				= \frac \varepsilon{2\abs X}\abs X + \int_X \psi - \varphi < 2\frac \varepsilon2 = \varepsilon.\]

			Dès lors, on en déduit $f$ intégrable au sens de Riemann.

			Fixons $\varepsilon > 0$. Par convergence uniforme de $f_n$ vers $f$ sur $X$, on sait que~:
			\[\exists N \in \N \tq \forall n \geq N : \norm {f_n - f}_\infty < \frac \varepsilon{\abs X}\]

			Et donc~:
			\[\abs {\int_X f_n(x)\dif x - \int_X f(x)\dif x} = \abs {\int_X (f_n-f)(x)\dif x} \leq \abs {\int_X\norm {f_n-f}_\infty\dif x}
				= \abs X\norm{f_n-f}_\infty \leq \abs X\frac \varepsilon{\abs X} = \varepsilon.\]

			Finalement, la suite $\left(\int_X f_n(x)\dif x\right)_n$ converge dans $\R$ vers $\int_X f(x)\dif x$.
			\end{proof}

			\begin{rmq}~
			\begin{enumerate}
				\item Il est possible d'avoir les résultats sans vérifier les hypothèses. Par exemple, $X = [0, 1] \subset \R = Y$, avec $f_n(x) = x^n$.
				      On sait que $f_n \CVS Xn\pinfty 1_{\{x=1\}}$ et que la convergence n'est pas uniforme sur $[0, 1]$. On remarque alors~:
				      \[\lim_{n\to\pinfty}\int_0^1f_n(x)\dif x = \lim_{n\to\pinfty}\frac 1{n+1} = 0 = \int_0^11_{\{x=1\}}(x)\dif x
				      	= \int_0^1\lim_{n\to\pinfty}f_n(x)\dif x~;\]
				\item si les hypothèses ne sont pas vérifiées, la conclusion peut être fausse. Par exemple, $X = [0, 1] \subset \R = Y$. On définit ($n \geq 1$)~:
				      \[f_n(x) = \begin{cases}
				      	2n\alpha_nx &\text{ si } 0 \leq x < \frac 1{2n} \\
				        2\alpha_n - 2n\alpha_nx &\text{ si }\frac 1{2n} \leq x < \frac 1n \\
				        0 &\text{ sinon}\end{cases},\]
				      où $\alpha_n \in \R^+_0 \tq \forall n \in \N^* : \int_0^1f_n(x)\dif x = 1$, donc $\alpha_n = 2n$.

				      On a alors $f_n \CVS Xn\pinfty 0 = f$. La fonction nulle $0(x)$ est intégrable au sens de Riemann sur $[0, 1]$.

				      Finalement, on a~:
				      \[\int_0^1\lim_{n \to \pinfty}f_n(x)\dif x = \int_0^1f(x)\dif x = 0 \qquad \text{ et } \qquad \lim_{n \to \pinfty}\int_0^1f_n(x)\dif x = 1.\]

				      Dans ce cas précis, on ne peut pas passer à la limite.
			\end{enumerate}
			\end{rmq}

		\subsection{Passage à la limite dans une dérivation ordinaire ou partielle}
			\begin{thm} Soit $\emptyset \neq \Omega \subset \R^d$, un ouvert. Soient $f_n : \Omega \to \R$, toutes de classe $C^1$ sur $\Omega$. Supposons~:
			\begin{itemize}
				\item $f_n \CVSc \Omega n\pinfty f$~;
				\item $\forall i \in \intint 1d : \pd {f_n}{x_i} \CVU \Omega n\pinfty g_i$.
			\end{itemize}

			Alors~:
			\begin{enumerate}
				\item $f \in C^1(\Omega, \R)$~;
				\item $\forall i \in \intint 1d : \pd f{x_i} = \lim_{n \to \pinfty} \pd {f_n}{x_i}$ dans $\Omega$~;
				\item $f_n \CVUc \Omega n\pinfty f$.
			\end{enumerate}
			\end{thm}

			\begin{proof} Soit $x \in \Omega$. Par ouverture de $\Omega$, on sait qu'il existe $\delta \gneqq 0$ tel que $B(x, \delta[ \subset \Omega$.
			On en déduit que $B(x, \frac \delta2]$ est incluse dans $B(x, \delta[$. Or $B(x, \frac \delta2]$ est fermé et borné par définition.
			$B(x \frac \delta2]$ est donc un compact de $\Omega$.

			Soient $i \in \intint 1d$ et $h \in [\pm \frac \delta2]$. On a alors~:
			\[\forall n \in \N : f_n(x + he_i) = f_n(x) + \int_0^h\pd f{x_i}(x+s e_i)\dif s.\]

			Or comme $f_n \CVSc \Omega n\pinfty f$ et pour tout $i$, $\pd {f_n}{x_i}$ converge uniformément vers $g_i$ sur $B(x, \frac \delta2]$, il vient~:
			\[f_n(x + he_i) = f_n(x) + \int_0^hg_i(x+se_i)\dif s,\]
			où $\{e_1, \ldots e_d\}$ est la base canonique de $\R^d$.

			On en déduit alors que $f$ admet une dérivée partielle par rapport à $x_i$ en $x$~:
			\[\pd f{x_i}(x) = g_i(x).\]

			De plus, les $f_n$ sont $C^1(\Omega, \R)$, et donc les dérivées partielles $\pd {f_n}{x_i}$ sont $C^0(\Omega, \R)$ pour tout $i$ et par convergence
			uniforme sur les compacts, $g_i \in C^0(\Omega, \R)$ (Proposition~\ref{prp:cvuccontinues}).

			On en déduit alors $f \in C^1(\Omega, \R)$ avec $\pd f{x_i} = g_i$ pour tout $i$ dans $\Omega$ (points 1 et 2 à montrer).

			Il reste donc à montrer le point 3.

			Soit $K \subset \Omega$, un compact. Par ouverture de $\Omega$, on sait que pour tout $a \in K$, on a~:
			\[\exists r_a \gneqq 0 \tq B(a, r_a[ \subset \Omega.\]

			Dès lors, on sait que~:
			\[K \subset \bigcup_{a \in K}B\left(a, \frac {r_a}2\right[.\]

			Par complétude, on sait qu'il existe un sous-recouvrement fini de $K$, c'est-à-dire $p \in \N^*$ et $(a_i)_{i \in \intint 1p} \in K^p$ tel que~:
			\[K \subset \bigcup_{i=1}^pB\left(a_i, \frac {r_{a_i}}2\right[.\]

			Par convergence simple de $f_n$ vers $f$, et puisque les $a_i$ sont en nombre fini, on peut alors exprimer~:
			\[\forall \varepsilon > 0 : \exists N \in \N \tq \forall n \geq N : \forall k \in \intint 1p\abs {f_n(a_i) - f(a_i)} < \varepsilon.\]

			Fixons donc $\varepsilon > 0$, soit $N$ correspondant et soit $x \in K$. Il existe $k \in \intint 1p$ tel que $x \in B(a_k, \frac {r_{a_k}}2[$ car
			les boules ouvertes forment un recouvrement de $K$. On a alors~:
			\[f_n(x) = f_n(a_k) + \int_0^1\scpr {\nabla f_n(a_k + t(x - a_k))}{(x - a_k)}\dif t,\]
			et~:
			\[f(x) = f(a_k) + \int_0^1\scpr {\nabla f(a_k + t(x - a_k))}{(x - a_k)}\dif t.\]

			Par différence, on a~:
			\[\abs {f_n(x) - f(x)} \leq \abs {f_n(a_k) - f(a_k)} + \int_0^1\norm {\nabla f_n(a_k + t(x - a_k))
				- \nabla f(a_k + t(x - a_k))}\dif t \cdot \norm {x - a_k}.\]

			Par convergence uniforme sur $\left(\bigcup_{i=1}^pB(a_i, \frac {r_{a_i}}2]\right)$ de $\nabla f_n$ vers $\nabla f$, on sait que~:
			\[\exists N \in \N \tq \forall n \geq N : \norm {\nabla f_n - \nabla f}_{\infty, \bigcup_{i=1}^pB\left(a_i, \frac {r_{a_i}}2\right]} <
				\frac {2\varepsilon}{\displaystyle \max_{i \in \intint 1p} r_{a_i}}.\]

			Finalement, on a~:
			\[\forall x \in K : \forall n \geq N : \norm {f_n(x) - f(x)} \leq
				\varepsilon + \frac {r_{a_k}}{2} \cdot \frac {2\varepsilon}{\displaystyle \max_{i \in \intint 1d}r_{a_i}} \leq 2\varepsilon.\]

			Ainsi, pour $n \geq N$, on a~:
			\[\norm {f_n - f}_{\infty, K} \leq 2\varepsilon.\]
			\end{proof}

			\begin{rmq} Ce théorème est vrai en particulier pour $d = 1$, et $\Omega$ un segment de $\R$. \end{rmq}

			\begin{ex}[Contre-exemples ne vérifiant pas les hypothèses donc ne pouvant faire passer la limite dans la dérivation]
			\begin{enumerate}
				\item $f_n(x) = \frac {\sin(n^2x)}n, n \geq 1, x \in X = \R$. On a donc $f_n \CVU \R n\pinfty 0 = f$ car $\abs {f_n(x) - f(x)} \leq \frac 1n \to 0$
				      avec $\frac 1n$ ne dépendant pas de $x$. Les $f^n$ sont $C^\infty(\R)$ et sont donc dérivables~:
				      \[\od {f_n}x = n\cos(n^2x),\]
				      et donc~:
				      \[\od {f_n}x\sVert[3]_{x=0} = n \to \pinfty.\]

			          On en déduit~:
				      \[\lnot\left(\od {f_n}x \xrightarrow[n \to \pinfty]{} \od fx\right).\]

				\item $f_n(x) = \frac {x^n}n, n \geq 1, x \in X = [0, 1]$. On a $f_n \CVU Xn\pinfty 0$. Puisque les $f_n$ sont $C^\infty(X, \R)$, on a~:
				      \[\od {f_n}x = x^{n-1} \xrightarrow[n \to \pinfty]{} 1_{\{x=1\}},\]
				      qui n'est pas une dérivée. À nouveau, la suite des dérivées des $f_n$ ne tend pas vers la dérivée de $f$.
			\end{enumerate}
			\end{ex}

			\begin{cor} Soient $p \in \N^*, \Omega \subset \R^d$, un ouvert non-vide. Soit $f_n : \Omega \to \R$ de classe $C^p(\Omega, \R)$. Supposons~:
			\begin{itemize}
				\item $\displaystyle \forall q \in \intint 0{p-1} : \forall (i_1, \ldots, i_q) \in \intint 1d^q :
					\frac {\partial^qf_n}{\partial x_{i_1}\ldots\partial x_{i_q}} \CVU \Omega n\pinfty g_{i_1, \ldots, i_q}$~;
				\item $\displaystyle \forall (i_1, \ldots i_p) \in \intint 1d^p :
					\frac {\partial^pf_n}{\partial x_{i_1}\ldots\partial x_{i_p}} \CVU \Omega n\pinfty g_{i_1, \ldots i_q}$.
			\end{itemize}
			Alors~:
			\begin{enumerate}
				\item $f = g_\emptyset \in C^p(\Omega, \R)$~;
				\item $\displaystyle \forall q \in \intint 1p : \forall (i_1, \ldots, i_q) \in \intint 1d^q :
					\frac {\partial^qf}{\partial x_{i_1}\ldots\partial x_{i_q}} = g_{i_1, \ldots, i_q}$~;
				\item $\forall q \in \intint 0{p-1} : \forall (i_1, \ldots, i_q) \in \intint 1d^q :
					\frac {\partial^qf_n}{\partial x_{i_1}\ldots\partial x_{i_q}} \CVUc \Omega n\pinfty g_{i_1, \ldots, i_q}$.
			\end{enumerate}
			\end{cor}

			\begin{proof} EXERCICE. (Récurrence sur $p$ par le résultat précédent)
			\end{proof}

	\section{Séries de fonctions}
		\subsection{Retranscription des résultats sur les suites}
			\begin{déf} Soit $u_n : X \to Y$ où $X \neq \emptyset$ et $Y$ est un \evn. On appelle \textit{somme partielle d'ordre $n$ de la série de terme
			général $u_n$} la fonction suivante~:
			\[S_n : X \to Y : x \mapsto \sum_{k=0}^nu_k(x).\]

			On dit que la série de terme général $u_n$ \textit{converge simplement} sur $X$ lorsque $S_n$ converge simplement sur $X$. De même pour la
			\textit{convergence uniforme} sur $X$ et la \textit{convergence uniforme sur tout compact} de $X$.
			\end{déf}

			\begin{thm}\label{thm:fncvusériecvg} Soient $(X, d)$ un espace métrique et $Y$ un \evn. Soit $u_n : X \to Y$. Si $\forall n \in \N : u_n$ est continue en
			$a \in X$ et si la série de terme général $u_n$ converge uniformément sur $X$, alors~:
			\[S \coloneqq \lim_{n \to \pinfty}S_n \text{ est continue en } a.\]
			\end{thm}

			\begin{proof} EXERCICE.
			\end{proof}

			\begin{thm} Soit $X \neq \emptyset$, un pavé de $\R^d$ et soit $u_n : X \to Y \tq \sum_{n \geq 0}u_n \CVU Xn\pinfty S$ avec $u_n$ intégrable au
			sens de Riemann pour tout $n$. Alors~:
			\begin{enumerate}
				\item $S$ est intégrable au sens de Riemann sur $X$~;
				\item la suite $\int_XS_n(x)\dif x$ converge vers $\int_XS(x)\dif x$.
			\end{enumerate}
			\end{thm}

			\begin{proof} EXERCICE.
			\end{proof}

			\begin{thm} Soit $\Omega \subset \R^d$, un ouvert non-nul et soit $u_n : \Omega \to \R$ de classe $C^p(\Omega, \R)$ avec $p \in \N^*$.
			Supposons~:
			\begin{itemize}
				\item $\sum_{n \geq 0}u_n \CVS \Omega n\pinfty S$~;
				\item $\displaystyle \forall \alpha \in \N^d \tq \abs \alpha \coloneqq \sum_{i=1}^d\alpha_i \leq p :
					\sum_{n \geq 0}\frac {\partial^{\abs \alpha}}{\partial x_1^{\alpha_1}\ldots\partial x_d^{\alpha_d}}u_n \CVS \Omega n\pinfty s_{\alpha}$~;
				\item lorsque $\abs \alpha = p$, la convergence ci-dessus est uniforme sur les compacts de $\Omega$.
			\end{itemize}

			Alors~:
			\begin{enumerate}
				\item $S \in C^p(\Omega, \R)$~;
				\item $\displaystyle \forall \alpha \in \N^d :
					\frac {\partial^{\abs \alpha}}{\partial x_1^{\alpha_1}\ldots\partial x_d^{\alpha_d}}S =
						\sum_{n \geq 0}\frac {\partial^{\abs \alpha}}{\partial x_1^{\alpha_1}\ldots\partial x_d^{\alpha_d}}u_n$~;
				\item Il y a convergence uniforme sur les compacts de $\Omega$ des séries de dérivées partielles d'ordre $0$ à $p-1$.
			\end{enumerate}
			\end{thm}

		\subsection{Convergence normale}
			\begin{déf} Soient $X \neq \emptyset$ et $Y$ un \evn. On dit que la série de terme général $u_n : X \to Y$ converge normalement sur $X$ lorsque~:
			\[\sum_{n \geq 0}\norm {u_n}_{\infty, X} < \pinfty.\]
			\end{déf}

			\begin{déf} On dit que la série de terme général $u_n : X \to Y$ vérifie le critère de Weierstrass lorsqu'il existe $\seq Mn\N$ telle que~:
			\begin{itemize}
				\item $\displaystyle \forall n \in \N : \forall x \in X : \norm {u_n(x)}_E \leq M_n$~;
				\item $\displaystyle \sum_{n \geq 0}M_n < \pinfty$.
			\end{itemize}
			\end{déf}

			\begin{rmq} $\sum_{n \geq 0}u_n$ converge normalement sur $X$ si et seulement si elle vérifie le critère de Weierstrass.
			\end{rmq}

			\begin{prp} Si $(E, \norm \cdot_E)$ est un \evnc, et si $\sum_{n \geq 0}u_n$ converge normalement sur $X$ alors $\sum_{n \geq 0}$
			converge uniformément sur $X$.
			\end{prp}

			\begin{proof} Écrivons $S_n = \sum_{k=0}^nu_k \in B(X, E)$. Par convergence normale, la suite $\sigma_n = \sum_{k \geq 0}\norm {u_k}_{\infty, X}$
			converge. De plus, $(\sigma_n)$ est de Cauchy dans $\Rp$. Donc~:
			\[\forall \varepsilon > 0 : \exists N \in \N \tq \forall n, m \geq N : \abs {\sigma_n - \sigma_m} < \varepsilon.\]

			Ainsi~:
			\begin{align*}
				\norm {S_n - S_m}_{\infty, X} &= \norm {\sum_{k=\min(m, n)+1}^{\max(m, n)}u_k}_{\infty, X} \leq \sum_{k=\min(m, n)+1}^{\max(m, n)}\norm {u_k}_{\infty, X} \\
				&\leq \abs {\sigma_n - \sigma_m} < \varepsilon.
			\end{align*}

			Donc $(S_n)_n$ est de Cauchy dans $\left(B(X, E), \norm \cdot_{\infty, X}\right)$. Cet espace est complet car $(E, \norm \cdot_E)$ l'est
			(Théorème~\ref{thm:BXEcpltssiEcplt}). Et donc, $(S_n)_n$ converge uniformément sur $X$.
			\end{proof}

			\begin{rmq} On peut écrire~:
			\[CVN \underset {\text{complet}}\Rightarrow CVU \Rightarrow CVS,\]
			mais les réciproques sont habituellement fausses.
			\end{rmq}
% 3rd class
			\begin{cor} Si $f_n : X \to Y$ (avec $Y$ un \evnc) est $\tq$~:
			\begin{align*}
				\begin{cases}
					&\forall n \in \N : \exists M_n \geq 0 \tq \norm {f_{n+1} - f_n}_{\infty, X} \leq M_n \\
					&\sum_{m \geq 0}M_m < \pinfty,
				\end{cases}
			\end{align*}
			alors $\seq fn\N$ converge uniformément sur $X$.
			\end{cor}

			\begin{proof} La série de terme général $u_n = f_{n+1}-f_n$ converge normalement sur $X$ car elle vérifie le critère de Weierstrass sur $X$. Par
			complétude de $Y$, la série $\sum u_n$ converge uniformément sur $X$.

			Pour $n \in \N$, on calcule~:
			\[S_n = \sum_{k=0}^nu_k = f_{n+1}-f_0.\]
			Donc la suite $\seq fn\N$ converge uniformément sur $X$.
			\end{proof}

		\subsection{Transformation d'Abel}
			\begin{thm} Soient $Y$ un \evnc, $\seq gn\N \in Y^{\N}$, et $\seq fn\N \in (\Rp)^{\N}$. Supposons~:
			\[
				\begin{cases}
					&\exists M \gneqq 0 \tq \forall n \in \N : \norm {\sum_{k=0}^ng_k}_Y \leq M \\
					&f_n  \mconv n\pinfty{} 0\text{ en décroissant.}
				\end{cases}
			\]
			Alors $f_ng_n$ est le terme général d'une série convergente.
			\end{thm}

			\begin{proof} On pose~:
			\[\forall k \in \Ns : G_k = \sum_{m=0}^kg_m\]

			Calculons, pour $n, p \in \Ns$~:
			\begin{align*}
				S_{n+p} - S_n &= \sum_{k=n+1}^{n+p}f_kg_k = \sum_{k=n+1}^{n+p}f_k(G_k - G_{k-1}) = \sum_{k=n+1}^{n+p}f_kG_k - \sum_{k=n+1}^{n+p}f_kG_{k-1}
				= \sum_{k=n+1}^{n+p}f_kG_k - \sum_{k=n}^{n+p-1}f_{k+1}G_k \\
				&= \sum_{n+1}^{n+p-1}G_k(f_k - f_{k+1}) + f_{n+p}G_{n+p} - f_{n+1}G_n.
			\end{align*}

			Ainsi~:
			\begin{align*}
				\norm {S_{n+p} - S_n}_Y &\leq M\sum_{k=n+1}^{n+p}(f_k-f_{k+1}) + Mf_{n+p} + Mf_{n+1} = M(f_{n+1}-f_{n+p}) + M(f_{n+p} + f_{n+1}) \\
				&= 2Mf_{n+1} \xrightarrow [n \to \pinfty]{} 0,
			\end{align*}
			et la convergence de dépend pas de $p$. On a alors que la suite $\seq Sn\N$ est de Cauchy, et par complétude de $Y$, $S_n$ converge, ce qui implique que la
			série de terme général $f_ng_n$ converge.
			\end{proof}

			\begin{thm} Soient $X$ un \evnc et $X \neq 0$. Soient~:
			\begin{align*}
				g_n &: X \to Y, \\
				f_n &: X \to \Rp.
			\end{align*}

			Supposons~:
			\begin{itemize}
				\item qu'il existe $M \gneqq 0$ tel que $\forall n \in \N : \norm {\sum_{k=1}^ng_k}_{\infty, X} \leq M$~;
				\item que $f_n \CVU Xn\pinfty 0$ en décroissant.
			\end{itemize}

			Alors $f_ng_n$ est le terme général d'une série qui converge uniformément sur $X$.
			\end{thm}

			\begin{proof} Par la preuve précédente, on a~:
			\[\norm {S_{n+p} - S_n}_Y \leq 2Mf_{n+1}(x) \leq 2M\norm {f_{n+1}}_{\infty, X}.\]
			On déduit donc~:
			\[\norm {S_{n+p}-S_n}_{\infty, X} \leq 2M\norm {f_{n+1}}_{\infty, X}.\]

			On sait donc que $\seq Sn\N$ est de Cauchy dans $B(X, Y)$. Par complétude de $Y$, la série de terme général $f_ng_n$ converge uniformément sur $X$.

			On remarque en effet que les $S_n$ sont bornés car $f_n \CVU Xn\pinfty 0$, ce qui implique $\norm {f_n}_{\infty, X}$ bornée, au moins à partir d'un certain
			$n \in \N$. De plus, $\norm {\sum_kg_k} < M$ assure que $g_k$ est uniformément bornée.
			\end{proof}

		\subsection{Exemple d'une fonction continue sur $\R$ nulle part dérivable}
			Considérons la fonction $\varphi : \R \to \R : x \mapsto \abs x$ sur $[-1, 1]$ et 2-périodique. La fonction $\varphi$ est continue sur $\R$. Posons~:
			\[\forall k \in \N : u_k : \R \to \R : x \mapsto \left(\frac 34\right)^k\varphi(4^kx).\]

			On sait que $\forall k \in \N : \norm {u_k}_\infty = \left(\frac 34\right)^k \in [0, 1]$. Ainsi, la série de terme général $u_k$ converge normalement
			sur $\R$ par le critère de Weierstrass. Par le Théorème~\ref{thm:fncvusériecvg}, la fonction~:
			\[f : \R \to \R : x \mapsto \sum_{k \geq 0}u_k(x)\]
			est continue sur $\R$.

			Montrons maintenant la fonction $f$ n'est jamais dérivable.

			Construisons $\alpha_n$ et $\beta_n$ tels que~:
			\begin{align*}\begin{cases}
				&\forall n \in \N : \alpha_n \leq x \leq \beta_n, \\
				&\beta_n - \alpha_n \xrightarrow[]{} 0, \\
				&\forall n \in \N : \abs {\frac {f(\beta_n) - f(\alpha_n)}{\beta_n - \alpha_n}} \geq \frac 123^n.
			\end{cases}\end{align*}

			Soit $n \in \Ns$. Choisissez $p \in \Z$ tel que $p = \floor {4^nx}$ (et donc $p \leq 4^nx < p+1$). Posons $\alpha_n = \frac p{4^n}$ et
			$\beta_n = \frac {p+1}{4^n}$. On a alors~:
			\[f(\beta_n) - f(\alpha_n) = \sum_{k \geq 0}\left(\varphi(4^k\beta_n)\left(\frac 34\right)^k - \varphi(4^k\alpha_n)\left(\frac 34\right)^k\right)
				= \sum_{k \geq 0}\left(\frac 34\right)^k\left(\varphi(4^k\beta_n) - \varphi(4^k\alpha_n)\right)\]

			On observe que~:
			\begin{itemize}
				\item si $k \lneqq n$, alors $4^k\beta_n = 4^{k-n}(p+1)$ et $4^k\alpha_n = 4^{k-n}p$. Puisque $\varphi$ est lipschitzienne de constante 1, on a~:
					\[\varphi(4^k\beta_n) - \varphi(4^k\alpha_n) \leq 4^{k-n}(p+1-p) = 4^{k-n}~;\]
				\item si $k = n$, alors $\abs {\varphi(4^k\beta_n) - \varphi(4^k\alpha_n)} = 1$~;
				\item si $k \gneqq n$, alors $4^k\alpha_n = 4^{k-n}p \in 4\Z \subset 2\Z$ donc $\varphi(4^k\alpha_n) = 0$.
					De même, on a $\varphi(4^k\beta_n) = 0$.
			\end{itemize}

			Ainsi~:
			\[f(\beta_n) - f(\alpha_n) = \sum_{k=0}^{n-1}\left(\frac 34\right)^k\left(\varphi(4^k\beta_n) - \varphi(4^k\alpha_n)\right) +
				\left(\frac 34\right)^n\left(\varphi(4^n\beta_n) - \varphi(4^n\alpha_n)\right).\]

			Or, par inégalité triangulaire inversée, on a~:
			\[\abs {f(\beta_n) - f(\alpha_n)} \geq \left(\frac 34\right)^n\abs {\varphi(4^n\beta_n) - \varphi(4^k\alpha_n)}
				- \sum_{k=0}^{n-1}\left(\frac 34\right)^k4^{k-n} \geq \frac 12\left(\frac 34\right)^n.\]

			Et puisque $\beta_n - \alpha_n = 4^{-n}$, il vient~:
			\[\abs {\frac {f(\beta_n) - f(\alpha_n)}{\beta_n - \alpha_n}} \geq \frac 123^n,\]
			ce qui contredit la dérivabilité en $x$.
	\section{Séries de puissances}
		\subsection{Théorie du rayon}
			On se donne $(Y, \norm \cdot)$, un $\C$-ev complet.

			\begin{déf} On appelle \textit{série de puissance} toute série de fonctions~:
			\[u_n : \C \to Y,\]
			dont le terme général est sous la forme $u_n(z) = a_n(z-z_0)^n$, avec $z_0 \in \C$ fixé et $(a_n) \subset Y$.
			\end{déf}

			\begin{rmq} $Y = \Mat_{n \times n}(\C)$.
			\end{rmq}

			\begin{déf} Définissons $\overline {\Rp} \coloneqq \Rp \cup \{\pinfty\}$.
			\end{déf}

			\begin{thm}\label{thm:rayondeconvergence} Soit $R \coloneqq \left(\limsup_{n \to \pinfty}\norm {a_n}_Y^{\frac 1n}\right)^{-1}$. Quelque soit
			$z \in \C$~:
			\begin{itemize}
				\item si $\abs {z - z_0} \lneqq R$, alors $\sum_{n \geq 0}u_n(z)$ converge absolument~;
				\item si $\abs {z - z_0} \gneqq R$, alors $\sum_{n \geq 0}u_n(z)$ diverge grossièrement (le terme général ne tend pas vers 0 pour $n \to \pinfty$
				en norme dans $Y$).
			\end{itemize}
			\end{thm}

			\begin{proof} Soit $z \in \C$ tel que $\abs {z - z_0} < R$. Alors il existe $R' \gneqq 0 \tq \abs {z - z_0} < R' < R$ et~:
			\[\frac 1R + \frac 1{R'} < \frac 1{\abs {z - z_0}}.\]

			Puisque $R^{-1} = \limsup_{n \to \pinfty}\norm{a_n}_Y^{\frac 1n}$, il existe $N \in \N \tq$~:
			\[\forall n \geq N : \norm {a_n}_Y^{\frac 1n} \leq \limsup_{n \to \pinfty} \norm {a_n}_Y^{\frac 1n} = \frac 1R \leq \frac 1{R'}.\]

			Dès lors~: $\norm {a_n}_Y \leq \frac 1{(R')^n}$, ou encore $\abs {z - z_0}\norm {a_n}_Y \leq \frac {\abs {z - z_0}^n}{(R')^n}$. On a donc~:
			\[\norm {(z-z_0)^na_n}_Y \leq \left(\frac {\abs {z - z_0}}{R'}\right)^n.\]

			Et comme $\abs {\frac {\abs {z - z_0}}{R'}} < 1$, on sait que la série de terme général $\frac {\abs {z - z_0}}{R'}$ converge et donc de terme
			général $\norm {(z - z_0)^na_n}_Y$ converge aussi.

			Soit maintenant $z \in \C \tq \abs {z - z_0} > R$. Il existe $R' > 0$ tel que $\abs {z - z_0} > R' > R$ et $\abs {z - z_0}^{-1} < (R')^{-1} + R^{-1}$.
			Soit $\varphi: \N \to \N$ strictement croissante telle que~:
			\[\forall n \in \N : \frac 1{R'} \leq \norm {a_{\varphi(n)}}_Y^{\frac 1{\varphi(n)}}.\]

			On en déduit~:
			\[\norm {a_{\varphi(n)}(z - z_0)^{\varphi(n)}}_Y = \abs {z - z_0}^{\varphi(n)}\norm {a_{\varphi(n)}}_Y
				\geq \left(\frac {\abs {z - z_0}}{R'}\right)^{\varphi(n)} \xrightarrow[n \to \pinfty]{} \pinfty.\]

			Dès lors, $\sum_{n \geq 0}a_n(z - z_0)^n$ diverge grossièrement.
			\end{proof}

			\begin{thm}\label{thm:cvnsurrayondeconvergence} Soit $a_n(z - z_0)^n$, le terme général d'une série de puissance. Alors~:
			\begin{itemize}
				\item lorsque $0 < R < \pinfty, \forall r \in (0, R) :$ la série de série de terme général~: $z \mapsto a_n(z - z_0)^n$ converge normalement
				sur $B(z_0, r]$~;
				\item lorsque $R = \pinfty$, la série de fonctions de terme général $z \mapsto a_n(z - z_0)^n$ converge normalement sur $B(z_0, r]$ pour tout $r$.
			\end{itemize}
			\end{thm}

			\begin{proof} Si $0 < r < R < \pinfty$, observons que $\abs {z_0 + r - z_0} < R$. Ainsi, avec le Théorème~\ref{thm:rayondeconvergence}, la série
			de terme général $a_n(z_0 + r)$ converge absolument. Or~:
			\[\norm {a_n(z_0 + r)}_Y = \norm {a_n}_Y\abs {z_0 + r - z_0}^n = \norm {a_n}_Yr^n.\]
			Donc la série de terme général $\norm {a_n}_Yr^n$ converge. Observons que~:
			\[\forall n \in \N : \forall z \in B(z_0, r] : \norm {u_n(z)}_Y = \norm {a_n}_Y\abs {z - z_0}^n \leq \norm {a_n}_Yr^n.\]

			Ainsi $\norm {u_n}_{\infty, B(z_0, r]} \leq \norm {a_n}_Yr^n$. Or $\norm {a_n}_Yr^n$ est le terme général d'une série qui converge. Par le critère
			de Weierstrass, la série de terme général $u_n$ converge normalement $B(z_0, r]$.

			Si maintenant $R = \pinfty$, on prend $r \in \Rp_0$, $\abs {z_0 + r - z_0} = r < R = \pinfty$. Avec le Théorème~\ref{thm:rayondeconvergence}, on a~:
			que $\sum_{n \geq 0}u_n(z_0 + r)$ converge absolument. Or $\norm {u_n(z_0 + r)}_Y = \norm {a_n}_Rr^n$. Donc la série de terme général
			$\norm {a_n}_Yr^n$ converge. Puisque l'on a toujours~:
			\[\norm {u_n}_{\infty, B(z_0, r]} \leq \norm {a_n}_Yr^n,\]
			on a donc $\sum_{n \geq 0}u_n$ converge normalement sur $B(z_0, r]$ par le critère de Weierstrass.
			\end{proof}

			\begin{cor} Soit $a_n(z - z_0)^n$ une série de puissance dans $Y$ complet et $R$ le rayon associé. Lorsque $R \gneqq 0$, la série converge normalement
			sur tout compact de $B(0, r[$.
			\end{cor}

			\begin{proof} Si $0 < R < \pinfty$, soit $K \subset B(z_0, R[$ un compact. Il existe $r \in (0, R)$ tel que $K \subset B(z_0, r] \subset B(z_0, R[$.
			La convergence normale sur $B(z_0, r]$ implique la convergence normale sur $K$.

			Si $R = \pinfty$, on a $B(z_0, R[ = \C$ Soit $K$, un compact de $\C$. Il existe $r > 0$ tel que $K \subset B(z_0, r]$, et donc la convergence
			normale sur $B(z_0, r]$ implique la convergence normale sur $K$.
			\end{proof}

			\begin{cor} Lorsque $R > 0$, la fonction $S(z) = \sum_{k \geq 0}a_k(z - z_0)^k$ est une fonction continue sur $B(z_0, R[$.
			\end{cor}

			\begin{proof} Les fonctions $u_n : B(z_0, R[ \to Y : z \mapsto a_n(z - z_0)^n$ sont continues sur l'ouvert $B(z_0, R[ \subset \C$, et il y a
			convergence normale (et donc uniforme) de $\sum_{n \geq 0}u_n$ sur les compacts de $B(z_0, R[$. Par le Théorème~\ref{thm:cvnsurrayondeconvergence},
			on sait que $S \in C^0(B(z_0, R[, Y)$.
			\end{proof}
		\subsection{Étude sur le cercle de convergence}
			\begin{déf} On définit le cercle centré en $z_0 \in \C$ et de rayon $R > 0$ par~:
			\[\mathcal C(z_0, R] = \{z \in \C \tq \abs {z - z_0} = R\}.\]
			\end{déf}

			\begin{thm}Lorsque $0 < R < \pinfty$, s'il existe $z \in \mathcal C(z_0, R]$ tel que $\sum_{n \geq 0}a_n(z - z_0)^n$ converge absolument,alors la
			série de fonctions~: $u_n(z) = a_n(z - z_0)^n$ converge normalement sur $B(z_0, R]$.
			\end{thm}

			\begin{proof} Soit $z \in \mathcal C(z_0, R]$ tel que $\sum_{n \geq 0}a_n(z - z_0)^n$ converge absolument. On a~:
			\[\norm {a_n(z - z_0)^n}_Y = \abs {z - z_0}^n\norm {a_n}_Y = R^n\norm {a_n}_Y.\]
			Puisque $\forall z \in B(z_0, R] : \forall n \in \N : \norm {u_n(z)}_Y = \abs {z - z_0}\norm {a_n}_Y \leq R^n\norm {a_n}_Y,$
			il vient que~:
			\[\forall n \geq 0 : \norm {u_n}_{\infty, B(z_0, R]} \leq R^n\norm {a_n}_Y.\]
			Et donc $\sum_{n \geq 0}u_n$ converge normalement sur $B(z_0, R]$ par le critère de Weierstrass.
			\end{proof}

			\begin{ex} $Y = \C, \sum_{n \geq 1}\frac {z^n}{n^2}$. On a alors $a_n = \frac 1{n^2}$, donc~:
			\[\abs {a_n}^{\frac 1n} = n^{\frac {-2}n} = \exp\left(-2\frac {\ln n}n\right) \xrightarrow[n \to \pinfty]{} 1,\]
			d'où $R = 1$, et il y a convergence en $z = 1$, donc il y a convergence absolue de la série~:
			\[\sum_{n \geq 1}\frac {\exp(in\theta)}{n^2} \; \forall \theta \in \R,\]
			et la convergence de $\sum_{n \geq 1}\frac {z^n}{n^2}$ est normale sur $B(0, 1]$.
			\end{ex}

			\begin{thm}[Théorème d'Abel]\label{thm:cvgsurcercleimpliquecvusursegment} Si $R \in (0, \pinfty)$ et
			$\exists z \in \mathcal C(z_0, R] \tq \sum_{n \geq 0} a_n(z - z_0)^n$ converge, alors la série de fonctions de terme général
			$z \mapsto a_n(z - z_0)^n$ converge uniformément sur le segment reliant $z_0$ à $z$.
			\end{thm}

			\begin{proof} Prenons $z_0 = 0$ et $z \in \Rp_0$. Prenons $x \in [0, z], n, p \in \Ns$. Écrivons~:
			\[\sum_{k=n}^{n+p}a_kx^k = \sum_{n=0}^{n+p}a_kz^k\left(\frac xz\right)^k.\]
			Notons alors $S_m \coloneqq \sum_{k=0}^ma_kz^k$, pour tout $m$. On obtient alors~:
			\begin{align*}
				\sum_{k=n}^{n+p}a_kx^k &= \sum_{k=n}^{n+p}(S_k - S_{k-1})\left(\frac xz\right)^k
					= \sum_{k=n}^{n+p}(S_k - S_{n-1})\left(\frac xz\right)^k - \sum_{k=n}^{n+p}(S_{k-1} - S_{n-1})\left(\frac xz\right)^k \\
				&= \sum_{k=n}^{n+p}(S_k-S_{n-1})\left(\frac xz\right)^k - \sum_{k=n-1}^{n+p-1}(S_k-S_{n-1})\left(\frac xz\right)^{k+1} \\
				&= -(S_{n-1}-S_{n-1})\left(\frac xz\right)^n + \sum_{k=n}^{n+p-1}(S_k-S_{n-1})\left(\left(\frac xz\right)^k - \left(\frac xz\right)^{k+1}\right)
					+ (S_{n+p}-S_{n-1})\left(\frac xz\right)^{n+p}.
			\end{align*}

			Puisque la série de terme général $z \mapsto a_k\abs {z-z_0}^k$ converge, la suite $(S_m)_n$ est de Cauchy dans $Y$. Soit $\varepsilon > 0$. On sait
			qu'il existe $N \in \N \tq$~:
			\[\forall k, n > N : \norm {S_k - S_{n-1}}_Y \leq \varepsilon.\]

			Soit un $n \geq N$, et $p \in \Ns$. Prenons $x \in [0, z]$. On a~:
			\begin{align*}
				\norm {\sum_{k=n}^{n+p}a_kx^k}_Y &\leq \sum_{k=n}^{n+p-1}\norm {(S_k-S_{n-1})\left(\left(\frac xz\right)^{k+1} - \left(\frac xz\right)^k\right)}_Y
					+ \norm {(S_{n+p}-S_{n-1}\left(\frac xz\right)^{n+p}} \\
				&\leq \sum_{k=n}^{n+p-1}\norm {S_k - S_{n-1}}\left(\left(\frac xz\right)^k - \left(\frac xz\right)^{k+1}\right)
					+ \norm {S_{n+p}-S_{n-1}}\left(\frac xz\right)^{n+p} \\
				&\leq \varepsilon\sum_{k=n}^{n+p-1}\left(\left(\frac xz\right)^k - \left(\frac xz\right)^{k+1}\right) + \varepsilon\left(\frac xz\right)^{n+p} \\
				&\leq \varepsilon\left(\left(\frac xz\right)^n - \left(\frac xz\right)^{n+p}\right) + \varepsilon\left(\frac xz\right)^{n+p} \\
				&\leq \varepsilon\left(\frac xz\right)^{n}.
			\end{align*}

			Par la suite, on peut dire que pour $n \geq N, p \in \Ns$~:
			\[\norm {\sum_{k=n}^{n+p}a_k \cdot^k}_{\infty, [0, z]} \leq \varepsilon.\]

			On en déduit que la série de terme général $x \mapsto a_kx^k$ est de Cauchy dans $B([0, z], Y)$, et donc, par complétude de $Y$, convergente.
			\end{proof}

			\begin{rmq} Soient $(a_n), (b_n) \subset \C$. On appelle la \textit{suite de Cauchy} de $(a_n)$ et $(b_n)$ la suite de terme général~:
			\[c_n \coloneqq \sum_{k=0}^na_kb_{n-k}.\]
			\end{rmq}

			\begin{thm}[Théorème de Cauchy, version \CDII]\label{thm:CauchyCDI1} Si $\sum_{n \geq 0}a_n$ et $\sum_{n \geq 0}b_n$ convergent absolument,
			alors $\sum_{n \geq 0}c_n$ converge absolument, et on a~:
			\[\left(\sum_{n \geq 0}a_n\right)\left(\sum_{n \geq 0}b_n\right) = \sum_{n \geq 0}c_n.\]
			\end{thm}

			\begin{thm}[Théorème de Cauchy, version \CDIII] Si $\sum_{n \geq 0}a_n$, $\sum_{n \geq 0}b_n$, et $\sum_{n \geq 0}c_n$ convergent, alors~:
			\[\left(\sum_{n \geq 0}a_n\right)\left(\sum_{n \geq 0}b_n\right) = \sum_{n \geq 0}c_n.\]
			\end{thm}

			\begin{proof} Par hypothèse de convergence des séries, on a~:
			\[R_a \coloneqq R\left(\sum_{n \geq 0}a_nz^n\right), R_b \coloneqq R\left(\sum_{n \geq 0}b_nz^n\right), R_c \coloneqq R\left(\sum_{n \geq 0}c_nz^n\right)
				\geq 1.\]
			Posons~:
			\begin{align*}
				&A : [0, 1] \to \R : x \mapsto \sum_{n \geq 0}a_nx^n, \\
				&B : [0, 1] \to \R : x \mapsto \sum_{n \geq 0}b_nx^n, \\
				&C : [0, 1] \to \R : x \mapsto \sum_{n \geq 0}c_nx^n.
			\end{align*}

			Si les $R_\cdot$ sont $> 1$, alors $[0, 1]$ est un compact de $B(0, R[$ et donc la somme de la série de terme général $\cdot_nz^n$ est $C^0$ sur
			$[0, 1]$, et si $R=1$, alors la série de puissance converge en $1 \in \mathcal C(0, 1]$ et donc la série de terme général $\cdot_nz^n$ converge
			uniformément sur $[0, 1]$.

			Puisque $z \mapsto a_nz^n$ (pareil pour $b_n$, $c_n$) est $C^0$ sur $[0, 1]$, il vient que $A, B, C \in C^0([0, 1], \C)$.

			Pour $x \in [0, 1)$, les séries $\sum_{n \geq 0}\cdot_n$ convergent \textbf{absolument}. De plus~:
			\[\sum_{k=0}^na_kx^k\cdot b_{n-k}x^{n-k} = x^n\sum_{n=0}^na_kb_{n-k} = x^nc_n.\]

			Par le Théorème~\ref{thm:CauchyCDI1}, on a~:
			\[\forall x \in [0, 1) : A(x)B(x) = C(x).\]
			De même, en passant à la limite (continuité) $x \to 1$, il vient~:
			\[\left(\sum_{n \geq 0}a_n\right)\left(\sum_{n \geq 0}b_n\right) = A(1)B(1) = C(1) = \sum_{n\geq 0}c_n.\]
			\end{proof}

		\subsection{Fonctions réelles analytiques}
			On considère la série de puissances $u_n(x) = a_n(x - x_0)^n$, avec $x, x_0 \in \R$ et $x_0$ fixé.

			\begin{déf} On appelle \textit{série dérivée formelle} de $u_n$ la série de terme général~:
			\[u_n'(x) = na_n(x-x_0)^{n-1}, \qquad n \geq 1\]
			\end{déf}

			\begin{rmq} La série dérivée formelle est toujours une série de puissances.
			\end{rmq}

			\begin{prp} Soient~:
			\begin{align*}
				&R_1 \coloneqq R\left(\sum_{n \geq 0}a_n(x-x_0)^n\right), \\
				&R_2 \coloneqq R\left(\sum_{n \geq 1}na_n(x-x_0)^{n-1}\right).
			\end{align*}

			Alors $R_1 = R_2$.
			\end{prp}

			\begin{proof} On observe aisément que~:
			\[R_1^{-1} = \limsup_{n \to \pinfty}\norm {a_n}_Y^{\frac 1n},\]
			et donc~:
			\[R_2^{-1} = \limsup_{n \to \pinfty}\norm {na_n}_Y^{\frac 1n} = \limsup_{n \to \pinfty}n^{\frac 1n}\norm {a_n}_Y^{\frac 1n}
				= \limsup_{n \to \pinfty}\norm {a_n}_Y^{\frac 1n} = R_1^{-1},\]
			car $n^{\frac 1n} \xrightarrow[n \to \pinfty]{} 1$.
			\end{proof}

			\begin{prp}\label{prp:formuledérivéepsdp} Soit $x_0 \in \R$. Supposons $R \gneqq 0$, et notons~:
			\[f : (x_0-R, x_0+R) \to Y : x \mapsto \sum_{n \geq 0}a_n(x-x_0)^n.\]

			Alors la fonction $f$ est continue sur $(x_0 \pm R)$, et on a~:
			\[\forall p \in \N : \forall x \in (x_0 \pm R) : f^{(p)}(x) = \sum_{n \geq p}\left(n(n-1)(n-2)\ldots(n-p+1)\right)a_n(x-x_0)^{n-p}
				= \sum_{n \geq p}\frac {n!}{(n-p)!}a_n(x-x_0)^{n-p}.\]
			\end{prp}

			\begin{proof} On observe que le terme général $u_n(x) = a_n(x-x_0)^n$ est de classe $C^\infty$ sur $(x_0 \pm R)$. La série
			$u_n'(x) = na_n(x-x_0)^{n-1}$ converge normalement sur les compacts de $(x_0 \pm R)$ par l'égalité des rayons. Donc $f \in C^1\left((x_0 \pm R)\right)$
			et $f'(x) = \sum_{n \geq 1}na_n(x-x_0)^{-1}$.

			Par récurrence, on obtient le résultat désiré.
			\end{proof}

			\begin{cor} Si $f$ est une somme d'une série de puissances $\sum_{n \geq 0}a_n(x-x_0)^n$ de rayon $R \gneqq 0$ sur $(x_0 \pm R)$, alors~:
			\[\forall n \in \N : a_n = \frac {f^{(n)}(x_0)}{n!}.\]
			\end{cor}

			\begin{proof} Si $f$ est somme de la série de puissance de terme général $a_n(x-x_0)^n$, alors $f \in C^\infty$ sur $(x_0 \pm R)$. Par la
			Proposition~\ref{prp:formuledérivéepsdp}, on trouve~:
			\[\forall p \in \N : f^{(p)}(x_0) = \sum_{n \geq p}\frac {n!}{(n-)!}a_n(x_0-x_0)^{n-p} = \frac {p!}{0!}a_p(x_0-x_0)^{p-p} + 0 = p!a_p1 = p!a_p,\]
			et donc $a_p = \frac {f^{(p)}(x_0)}{p!}$.
			\end{proof}

			\begin{rmq} Les notations suivantes sont dues à Landau~:
			\begin{align*}
				&u_n \sim v_n \iff \forall \varepsilon > 0 : \exists N \in \N \tq \forall n \geq N : \abs {u_n - v_n} < \varepsilon \abs{u_n} \\
				&u_n = o(v_n) \iff \forall \varepsilon > 0 : \exists N \in \N \tq \forall n \geq N : \abs {u_n} < \varepsilon \abs {v_n} \\
				&u_n = O(v_n) \iff \exists N \in \N \tq \forall M \gneqq 0 : \forall n \geq N : u_n < M \abs {v_n}
			\end{align*}
			\end{rmq}

			\begin{déf} Soit $U \subset \R$, un ouvert. Une fonction $f : U \to \R$ est dite \textit{réelle analytique} lorsque~:
			\[\forall x_0 \in U : \exists \varepsilon > 0, (a_n) \subset \R \tq (x_0 \pm \varepsilon) \subset U \text{ et } \sum_{k=0}^na_k(x-x_0)^k
			\text{ converge simplement sur } (x_0 \pm \varepsilon).\]
			\end{déf}

			\begin{déf}[Définition équivalente] $f : U \subset U \to \R$ est dite \textit{réelle analytique} lorsque $f$ est somme de sa série de Taylor sur un
			voisinage de chaque point de $U$.
			\end{déf}

			\begin{déf} Pour $\emptyset \neq U \subset \R$, on pose $\mathcal A(U) \coloneqq \{f : U \to \R \tq f \text{ est réelle analytique sur } U\}$.
			\end{déf}

			\begin{prp} Soit $\emptyset \neq U \subset \R$. Alors $\mathcal A(U) \subsetneqq C^\infty(U, \R)$.
			\end{prp}

			\begin{proof} Montrons d'abord l'inclusion. Soit $x_0 \in U$ et soit $\varepsilon > 0$ tel que~:
			\[f(x) = \sum_{k \geq 0}\frac {f^{(k)}(x_0)}{k!}(x-x_0)^k \text{ sur } (x_0 \pm \varepsilon).\]
			On a donc $\restr f {(x_0 \pm \varepsilon)} \in C^\infty\left((x_0 \pm \varepsilon), \R\right)$.

			Pour montrer l'inclusion stricte, soit~:
			\[f : \R \to \R : x \mapsto \begin{cases}\exp(-x^{-1}) &\text{ si } x > 0 \\0 &\text{ sinon}\end{cases}.\]
			On sait que $f \in C^\infty(\R, \R)$, et $\forall k \in \N : f^{(k)}(0) = 0$. Donc $f$ n'est somme de sa série de Taylor sur aucun voisinage de $0$.
			On a donc $f \not \in \mathcal A(\R)$.
			\end{proof}

			\begin{rmq} $f \in \mathcal A(\R)$ peut avoir, en certains points, un rayon fini. Par exemple $f(x) = \frac 1{1 + x^2}$. Pour $\abs x < 1$, on a~:
			\[f(x) = \frac 1{1 - (-x^2)} = \sum_{k \geq 0}(-1)^kx^{2k},\]
			et $R\left(\sum_{k \geq 0}(-1)^kx^{2k}\right) = \left(\limsup_{n \to \pinfty}((-1)^n)^{\frac 1n}\right)^{-1} = 1$.
			\end{rmq}

\chapter{Intégration}
	\section{Intégrales absolument convergentes}
		\subsection{Rappels concernant l'intégrale de Riemann}
			\begin{déf} On se place sur un segment $[a, b] \subset \R$. On note~:
			\[\El {[a, b]}\R \coloneqq \left\{\varphi : [a, b] \to \R \tq \varphi \text{ est en escaliers sur} [a, b]\right\}.\]
			\end{déf}

			\begin{rmq} $\int$ est bien définie sur $\El {[a, b]}\R$.
			\end{rmq}

			\begin{déf} La fonction $f : [a, b] \to \R$ est \textit{R-int} (\textit{Riemann intégrable}, ou encore \textit{intégrable au sens de Riemann})
			lorsque~:
			\begin{align*}
				\forall \varepsilon > 0 : &\exists \varphi, \psi \in \El {[a, b]}\R \tq \\
				&(i) \quad \varphi \leq f \leq \psi \\
				&(ii) \quad \int(\psi-\varphi) < \varepsilon
			\end{align*}
			\end{déf}

			\begin{prp} De manière équivalente, $f : [a, b] \to \R$ est R-int sur $[a, b]$ lorsque~:
			\[\overline \int f \coloneqq \inf_{f \leq \psi \in \El {[a, b]}\R}\int \psi
				= \sup_{f \geq \varphi \in \El {[a, b]}\R}\int \varphi \eqqcolon \underline \int f.\]
			\end{prp}

			\begin{déf} On note dans ce cas~:
			\[\int_a^b f(x)\dif x = \overline {\int_a^b} f(x)\dif x = \underline {\int_a^b} f(x)\dif x.\]
			\end{déf}

			\begin{prp} Si $f : [a, b] \to \R$ est R-int sur $[a, b]$, alors $f$ est bornée sur $[a, b]$.
			\end{prp}

			\begin{prp} Soient $f, g$ R-int, et $\lambda, \mu \in \R$. Alors les fonctions suivantes sont R-int~:
			\begin{align*}
				&\lambda f + \mu g \\
				&\min(f, g) \\
				&\max(f, g) \\
				&\abs f
			\end{align*}
			Et on a~:
			\begin{itemize}
				\item[$(i)$]  \[\abs {\int_a^b f(x)\dif x} \leq \int_a^b\abs {f(x)}\dif x~;\]
				\item[$(ii)$] \[\int_a^b\left(\lambda f + \mu g\right)(x)\dif x = \lambda \int_a^b f(x)\dif x + \mu \int_a^b g(x)\dif x.\]
			\end{itemize}
			\end{prp}

			\begin{proof} montrons que $\min(f, g)$ est R-int sur $[a, b]$.

			Fixons $\varepsilon > 0$. Soient $\varphi_f, \varphi_g, \psi_f, \psi_g \in \El {[a, b]}\R$ tels que~:
			\begin{align*}
				&\varphi_f \leq f \leq \psi_f, \qquad\qquad \int_a^b(\psi_f - \varphi_f) < \varepsilon \\
				&\varphi_g \leq g \leq \psi_g, \qquad\qquad \int_a^b(\psi_g - \varphi_g) < \varepsilon.
			\end{align*}

			Prenons $x \in [a, b]$, et remarquons que~:
			\[\min(\varphi_f, \varphi_g) \leq f\qquad\qquad\min(\varphi_f, \varphi_g) \leq g,\]
			et donc $\min(\varphi_f, \varphi_g) \leq \min(f, g)$.

			Posons $\El {[a, b]}\R \ni \widetilde \varphi \coloneqq \min(\varphi_f, \varphi_g), \widetilde \psi \coloneq \min(\psi_f, \psi_g)$. On remarque alors~:
			\[\widetilde \varphi \leq \min(f, g) \leq \widetilde \psi.\]

			Prenons $x \in [a, b]$. On remarque~:
			\begin{itemize}
				\item si $\varphi_f(x) \leq \varphi_g(x)$, on a~:
				\[\widetilde \psi(x) - \widetilde \varphi(x) \leq \psi_f(x) - \varphi_f(x)~;\]
				\item si $\varphi_g(x) < \varphi_f(x)$, on a~:
				\[\widetilde \psi(x) - \widetilde \varphi(x) \leq \psi_g(x) - \varphi_g(x).\]
			\end{itemize}

			Ainsi, en séparant les intégrales en un nombre fini où on a soit $(i)$, soit $(ii)$, on a~:
			\[\int_a^b (\widetilde \psi - \widetilde \varphi) \leq \int_a^b (\psi_f - \varphi_f) + \int_a^b (\psi_g - \varphi_g) \leq 2\varepsilon.\]
			\end{proof}

			\begin{cor} $\abs {\int_a^b (\lambda f + \mu g)(x)\dif x} \leq \abs \lambda \int_a^b \abs {f(x)}\dif x + \abs \mu \int_a^b\abs {g(x)}\dif x$.
			\end{cor}
		\subsection{Fonctions absolument intégrables sur un intervalle}
			\begin{déf} Soit $I \neq \emptyset$, un intervalle de $\R$, et $f : I \to \R$. On dit que $f$ est \textit{abs-int} (\textit{absolument intégrable})
			sur $I$ lorsque~:
			\begin{itemize}
				\item[$(i)$] $\forall [a, b] \subset U : \restr f{[a, b]}$ est R-int sur $[a, b]$~;
				\item[$(ii)$] $\sup_{[a, b] \subset I} \int_a^b \abs f \leq \pinfty$.
			\end{itemize}
			\end{déf}

			\begin{rmq} La condition $(ii)$ revient à dire que $\exists M > 0 \tq \forall [a, b] \subset U : \int_a^b \abs f \leq M$.
			\end{rmq}

			\begin{déf} Soit $I \subset \R$, un intervalle. On appelle \textit{suite exhaustive de segments de $I$} toute suite $([a_n, b_n])_{n \in \N}$ de
			segments de $I$ tels que~:
			\begin{itemize}
				\item[$(i)$]  la suite est croissante (c-à-d $\forall n \in \N : [a_{n+1}, b_{n+1}] \supseteq [a_n, b_n]$)~;
				\item[$(ii)$] $\bigcup_{n \in \N}[a_n, b_n] = I$.
			\end{itemize}
			\end{déf}

			\begin{prp} Soit $I \neq \emptyset$, un intervalle de $\R$. $I$ admet une suite exhaustive.
			\end{prp}

			\begin{proof} Si $I$ est un fermé, prenons $a, b \in \R$ tels que $I = [a, b]$. La suite $([a_n, b_n])_n = ([a, b])_n$ est exhaustive.

			Si $I$ est un ouvert, prenons $a, b \in \R$ tels que $I = (a, b)$. La suite $([a_n, b_n])_n = ([a + \frac 1n, b - \frac 1n])_n$ est exhaustive.

			Si $I$ est ouvert d'un côté, et fermé de l'autre, les suites exhaustives $([a, b-\frac 1n])_n$ et $([a + \frac 1n, b])_n$ sont exhaustives.
			\end{proof}

			\begin{prp} Soit $I \neq \emptyset$ un intervalle de $\R$. Soit $f : I \to \R$ abs-int sur $I$. Soit $([a_n, b_n])_n$ une suite exhaustive de
			segments de $I$. Alors~:
			\begin{itemize}
				\item[$(i)$]  la suite définie par~:
				\[\left(\int_{a_n}^{b_n}f(x)\dif x\right)_n \subset \R\]
				est convergente~;
				\item[$(ii)$] la limite de cette suite ne dépend pas de la suite exhaustive de segments de $I$ choisie.
			\end{itemize}
			\end{prp}

			\begin{déf} On appelle \textit{intégrale de $f$ sur $I$} cette valeur, et on la note~:
			\[\int_I f(x)\dif x.\]
			\end{déf}

			\begin{proof} Soit $([a_n, b_n])$ une suite exhaustive de segments de $I$. Posons pour $n \in \N$~: $\alpha_n = \int_{a_n}^{b_n}\abs f$.
			La suite $(\alpha_n)_n$ est croissante et majorée donc $(\alpha_n)$ converge vers un certain $\ell \in \Rp$. En particulier, $(\alpha_n)$ est de
			Cauchy dans $\R$. Considérons maintenant $(\beta_n)_n$, où $\beta_n \coloneqq \int_{a_n}^{b_n}f$. Observons que pour $p, n \in \N$~:
			\[\beta_{n+p} - \beta_n = \int_{a_{n+p}}^{b_{n+p}}f - \int_{a_n}^{b_n}f
				= \int_{a_{n+p}}^{a_n}f + \int_{a_n}^{b_n}f + \int_{b_n}^{b_{n+p}}f - \int_{a_n}^{b_n}f = \int_{a_{n+p}}^{a_n}f + \int_{b_n}^{b_{n+p}}f.\]

			Ainsi~:
			\[\abs {\beta_{n+p}-\beta_n} \leq \int_{a_{n+p}}^{a_n}\abs f + \int_{b_n}^{b_{n+p}} \abs f
				\leq \int_{a_{n+p}}^{a_n}\abs f + \int_{a_b}^{b_n} \abs f + \int_{b_n}^{b_{n+p}} \abs f - \int_{a_n}^{b_n}\abs f
				= \alpha_{n+p} - \alpha_n.\]

			La suite $(\beta_n)_n$ est donc bornée par une suite de Cauchy (et est donc de Cauchy) dans $\R$. Par complétude de $\R$, $(\beta_n)_n$ converge
			dans $\R$.

			Montrons maintenant que cette limite ne dépend pas de la suite exhaustive. Soit $[\widetilde a_n, \widetilde b_n]$ une suite exhaustive de $I$. On
			sait que $\widetilde \beta_n = \int_{\widetilde a_n}^{\widetilde b_n} f$ converge. On veut montrer que $\widetilde \beta_n$ a la même limite que
			$\beta_n$. On construit donc une nouvelle suite exhaustive de $I$. On choisit $[\bar a_0, \bar b_0] = [a_0, b_0]$. Il existe
			$N_1 \gneqq 0 \tq \forall n \geq N_1 : [a_0, b_0] \subset [\widetilde a_n, \widetilde b_n]$. On pose ensuite
			$[\bar a_1, \bar b_1] = [\widetilde a_{N_1}, \widetilde b_{N_1}]$. Il existe
			$N_2 \gneqq N_1 \tq \forall n \geq N_2 : [\bar a_1, \bar b_1] \subset [a_n, b_n]$. On pose donc $[\bar a_2, \bar b_2] = [a_{N_2}, b_{N_2}]$.

			On construit donc $\varphi : \N \to \N$ strictement croissante telle que pour tout $p$~:
			\begin{align*}
				&[\bar a_{2p}, \bar b_{2p}] = [a_{\varphi(2p)}, b_{\varphi(2p)}], \\
				&[\bar a_{2p+1}, \bar b_{2p+1}] = [\widetilde a_{\varphi(2p+1}, \widetilde b_{2p+1}].
			\end{align*}

			Donc la suite $([\bar a_p, \bar b_p])_p$ est exhaustive. La suite $\left(\int_{\bar a_p}^{\bar b_p}f\right)_p$ converge vers $\bar \beta$ dans $\R$.

			Puisque~:
			\begin{align*}
				&\int_{\bar a_{2p}}^{\bar b_{2p}}f = \int_{a_{\varphi(2p)}}^{b_{\varphi(2p)}}f = \beta_{\varphi(2p)} \xrightarrow[p \to \pinfty]{} \beta = \bar \beta \\
				&\int_{\bar a_{2p+1}}^{\bar b_{2p+1}} f = \int_{\widetilde a_{\varphi(2p+1)}}^{\widetilde b_{\varphi(2p+1)}} f
					= \widetilde \beta_{\varphi(2p+1)} \xrightarrow[p \to \pinfty]{} \widetilde \beta = \bar \beta,
			\end{align*}
			on déduit $\beta = \bar \beta = \widetilde \beta$. Les limites sont donc les mêmes, peu importe les suites exhaustives choisies.
			\end{proof}

			\begin{prp} Soit $f : [a, b] \to \R$ R-int sur $[a, b]$. Alors $f$ est abs-int sur $[a, b]$, et on a~:
			\[\int_{[a, b]} f = \int_a^b f.\]
			\end{prp}

			\begin{proof} $f$ est R-int, et donc est R-int sur tout segment de $[a, b]$. Soit $([a_n, b_n])_n$, une suit exhaustive de segments de $[a, b]$. Il existe
			$N \in \N \tq \forall n \geq N : [a_n, b_n] = [a, b]$. Ainsi, pour $n \geq N$, on a~:
			\[\int_{a_n}^{b_n} f = \int_a^b f.\]
			En passant à la limite pour $n \to \pinfty$, on a~:
			\[\int_{[a, b]} f = \int_a^b f.\]
			\end{proof}

			\begin{prp} L'ensemble $L^1(I) \coloneqq \{f : I \to \R \tq f \text{ est abs-int sur } I\}$ est un $\R-ev$. De plus, l'application~:
			\[\int : L^1(I) \to \R : f \mapsto \int_I f\]
			est une forme linéaire sur $L^1(I)$.
			\end{prp}

			\begin{proof} EXERCICE.
			\end{proof}

		\subsection{Fonctions absolument intégrables vues comme fonction des bornes}
			\begin{prp} Soit $I \subset \R$, un intervalle non-vide de $\R$. Si la fonction $f : I \to \R$ est abs-int sur $I$, alors elle l'est sur
			$I \cap (\minfty, a]$ et $[a, \pinfty)$ pour tout $a \in \R$, et on a~:
			\[\int_I f = \int_{I \cap (\minfty, a]} f + \int_{I \cap [a, \pinfty)} f.\]
			\end{prp}

			\begin{proof} Soit $[\alpha, \beta] \subset [a, \pinfty) \cap I$. $[\alpha, \beta]$ est un segment de $I$ et $f$ est abs-int sur $I$. $f$ est donc abs-int
			sur tout segment de $I$, en particulier sur $[\alpha, \beta]$. De plus, il existe $M \gneqq 0$ tel que pour tout segment $[u, v]$ de $I$, on a~:
			\[\int_u^v \abs f \leq M.\]

			Ainsi~:
			\[\int_\alpha^\beta \abs f \leq M.\]
			$f$ est donc abs-int sur $I \cap [a, \pinfty)$. On raisonne de manière similaire pour $(\minfty, a]$.

			Montrons maintenant l'égalité. Soit $[\alpha_n, \beta_n]$, une suite de segments de $I$. Il existe $N \in \N$ tel que~:
			\[\forall n \geq N : \alpha_n \leq a \leq \beta_n.\]
			Il vient alors que $([\alpha_n, a])_n$ est une suite exhaustive de $I \cap (\minfty, a]$, et $([a, \beta_n])_n$ est une suite exhaustive de
			$I \cap [a, \pinfty)$. Pour $n \geq N$, on a alors~:
			\[\int_{\alpha_n}^{\beta_n} f = \int_{\alpha_n}^a f + \int_a^{\beta_n} f.\]
			En passant à la limite pour $n \to \pinfty$, on trouve~:
			\[\int_I f= \int_{I \cap (\minfty, a]} f + \int_{I \cap [a, \pinfty)} f.\]
			\end{proof}

			\begin{prp} Soient $I \subset \R$, $a \in I$, et $f : I \to \R$. Si $f$ est abs-int sur $I \cap (\minfty, a]$ et sur $I \cap [a, \pinfty)$, alors $f$
			est abs-int sur $I$, et on a~:
			\[\int_I f = \int_{I \cap (\minfty, a]} f + \int_{I \cap [a, \pinfty)} f.\]
			\end{prp}

			\begin{proof} Soit $[\alpha, \beta]$ un segment de $I$. Si $a < \alpha$, ou $a > \beta$, c'est trivial.

			Supposons alors $\alpha \leq a \leq \beta$. $f$ est R-int sur $[\alpha, a]$ et sur $[a, \beta]$. $f$ est donc R-int sur $[\alpha, \beta]$. De plus, il existe
			$M^+, M^- > 0$ tels que~:
			\[\sum_{[u, v] \subset (\minfty, a] \cap I}\int_u^v f \leq M^-\qquad\qquad\text{ et }\qquad\qquad\sup_{[u, v] \subset I \cap [a, \pinfty)}\int_u^v\abs f
				\leq M^+.\]
			On peut donc dire que $\int_\alpha^\beta\abs f \leq M^+ + M^-$. On a alors $f$ abs-int sur $I$ et on peut appliquer la proposition précédente pour~:
			\[\int_I f = \int_{I \cap (\minfty, a]} f + \int_{I \cap [a, \pinfty)} f.\]
			\end{proof}

			\begin{prp} Soient $I \subset \R$, un intervalle non-vide, et $f : I \to \R$ abs-int. La fonction $F : I \to \R : x \to \int_{I \cap (-\minfty, x]} f$ est
			localement lipschitizenne.
			\end{prp}

			\begin{proof} Soit $x_0 \in I$. Supposons que $x_0$ n'est pas un bord de $I$ (sinon EXERCICE). Supposons qu'il existe
			$\delta > 0 \tq (x_0 \pm \delta) \subset I$. La fonction $f$ est R-int sur $\left[x_0 \pm \frac \delta2\right]$ et donc sa valeur absolue est bornée sur
			ce segment par $M(x_0, \delta)$. Pour $x, y \in \left[x_0 \pm \frac \delta2\right]$, avec $x < y$, on déduit~:
			\[F(y) - F(x) = \int_{I \cap (\minfty, y]} f - \int_{I \cap (-\infty, x]} f
				= \int_{I \cap (\minfty, x]} f + \int_x^y f - \int_{I \cap (\minfty, x]} f = \int_x^y f.\]

			D'où~:
			\[\abs {F(y) - F(x)} = \int_x^y\abs f \leq M(x_0, \delta)(y-x).\]
			\end{proof}

			\begin{cor} Si $f$ est abs-int sur $I$, alors $F$ est continue sur $I$.
			\end{cor}

			\begin{prp} Si $f$ est abs-int sur $I$, et continue en $x_0 \in I$, alors $F$ est dérivable en $x_0$ et on a~:
			\[F'(x_0) = f(x_0).\]
			\end{prp}

			\begin{cor} Si $f$ est abs-int sur $I$ et de classe $C^k$ sur un voisinage de $x_0 \in I$, alors $F$ est de classe $C^{k+1}$ sur un voisinage de
			$x_0$ et on a, sur ce voisinage~:
			\[\forall p \in \{0, \ldots, k\} : F^{(p+1)}(x) = f^{(p)}(x).\]
			\end{cor}

			\begin{rmq} Si le voisinage est ouvert pour $f$, alors on a le même voisinage pour $F$.
			\end{rmq}

			\begin{proof} $F(x) = F(x_0) + \int_{x_0}^x f(t)\dif t$.
			\end{proof}

			\begin{rmq} C'est donc le théorème fondamental du calcul différentiel et intégral qui est revu ici.
			\end{rmq}

		\subsection{Critères d'intégration absolue}
			\begin{prp}[Critère de comparaison]\label{prp:critèredecomparaison} Soit $I \subset \R$ un intervalle non-vide et $f, g : I \to \R$ avec~:
			\begin{itemize}
				\item $\forall x \in X : \abs {f(x)} \leq g(x)$~;
				\item $f, g$ R-int sur tout segment de $I$.
			\end{itemize}

			Si $g$ est abs-int sur $I$, alors $f$ l'est aussi, et on a~:
			\[\int_I\abs f \leq \int_I g.\]
			\end{prp}

			\begin{proof} Il existe $M_g \gneqq 0 \tq$~:
			\[\forall [u, v] \subset I : \int_u^vg \leq M_g.\]
			Ainsi, si $[a, b] \subset I$ est un segment, on a $f$ R-int sur $[a, b]$ et~:
			\[\int_a^b\abs f \leq \int_a^b g \leq M_g,\]
			avec $M_g$ donc indépendant de $[a, b]$. Ceci montre que $f$ est abs-int sur $I$ et que~:
			\[\int_I \abs f \leq \int_I g.\]
			\end{proof}

			\begin{rmq} Soient $f, g : [a, b) \to \R$. On dit que $f$ est \textit{équivalent} à $g$ en $b^-$ lorsque~:
			\[\forall \varepsilon > 0 : \exists \eta > 0 \tq \forall x \in [b-\eta, b) : \abs {f(x)-g(x)} \leq \varepsilon \abs {f(x)}.\]
			\end{rmq}

			\begin{prp} Soit $I = [a, b)$, et soit $f, g : I \to \R$, R-int sur tout segment de $I$. Alors~:
			\begin{enumerate}
				\item si $f \underset {b^-}\sim g(x)$, alors $f$ est abs-int sur $I$ si et seulement si $g$ l'est~;
				\item dans le cas abs-int, on a~:
				\[\int_x^b\abs f \underset {b^-}\sim \int_x^b g.\]
				Dans le cas non-abs-int, on a~:
				\[\int_a^x\abs f \underset {b^-}\sim \int_a^x g.\]
			\end{enumerate}
			\end{prp}

			\begin{proof}~
			\begin{itemize}
				\item Supposons $f$ abs-int. Pour $\varepsilon = 1$, il existe $\eta > 0$ tel que~:
				\[\forall x \in [b - \eta, b) : \abs {\abs {f(x)} - g(x)} \leq \varepsilon \abs {f(x)} = \abs {f(x)}.\]
				On en déduit $(0 \leq g(x) \leq 2\abs {f(x)}$ sur $[b-\eta, b)$. Ainsi, par le critère de comparaison, $g$ est abs-int sur $[b-\eta, b)$. De plus,
				$g$ est abs-int sur $[a, b-\eta]$ pour tout $\eta$, et donc $g$ est abs-int sur $[a, b)$. On montre que si $g$ est abs-int, alors $f$ est abs-int, de la
				même manière (critère de comparaison).
				\item Dans le cas abs-int, fixons $\varepsilon > 0$. Il existe $\eta > 0$ tel que pour $x \in [b-\eta, b)$, on a
				$\abs {\abs {f(x)}-g(x)} \leq \varepsilon g(x)$. Pour $x > b-\eta$, il vient~:
				\[\abs {\int_x^b\abs f - \int_x^b g} \leq \int_x^b\abs {\abs f - g},\]
				d'où $\int_x^b\abs {f(t)}\dif t$ abs-int.

				Dans le cas non-abs-int, fixons $\varepsilon > 0$. Il existe $\eta_1$ tel que pour $x \in [b-\eta_1, b)$, on a~:
				\[\abs {\abs {f(x)} - g(x)} \leq \varepsilon g(x).\]
				Pour $X \geq b-\eta_1$, on a~:
				\[\abs {\int_a^x \abs f - \int_a^x g} \leq \int_a^{b- \eta}\abs {\abs {f(t)} - g(t)}\dif t + \int_{b-\eta}^b\abs {\abs {f(t)} - g(t)}\dif t.\]
				Puisque $g$ n'est pas abs-int sur $[a, b)$, il existe $\eta_2 \in (b, b+\eta_1)$ tel que pour $x \geq b-\eta_2$, on a~:
				\[\frac {\int_a^{b-\eta_1}\abs {\abs f - g}}{\int_a^x g} \leq \varepsilon.\]
				Par suite, on a pour $x \geq b - \eta_2$~:
				\[\abs {\int_a^x \abs f - \int_a^x g} \leq \varepsilon \int_a^xg + \varepsilon\int_{b-\eta_1}^x g \leq 2\varepsilon \int_a^x g.\]
			\end{itemize}
			\end{proof}

		\subsection{Fonctions de référence de Riemann}
			\begin{prp} Soit $\alpha \in \R$. $x \mapsto x^{-\alpha}$ est abs-int sur $[1, \pinfty)$ si et seulement si $\alpha > 1$.
			\end{prp}

			\begin{proof} Remarquons que $x \mapsto x$ est continue sur $[1, \pinfty)$, et donc R-int sur tout segment de $[1, \pinfty)$. De plus, elle est positive sur
			$[1, \pinfty)$. Pour $X \gneqq 1$, on a~:
			\[\int_1^X\abs {\frac 1{x^\alpha}}\dif x = \int_1^X \frac {\dif x}{x^\alpha} = \int_1^Xx^{-\alpha}\dif x.\]
			\begin{itemize}
				\item si $\alpha \neq 1$, alors~:
				\[\int_1^Xx^{-\alpha}\dif x = \frac 1{1-\alpha}\left[x^{1-\alpha}\right]_1^X = \frac {X^{1-\alpha}}{1-\alpha} = \frac 1{1-\alpha}~;\]
				\item si $\alpha \gneqq 1$, alors~:
				\[\int_1^X\frac {\dif x}{x^\alpha} \xrightarrow[X \to \pinfty]{} \frac 1{1-\alpha},\]
				et~:
				\[\int_1^X\abs {x^{-\alpha}}\dif x \leq \frac 1{1-\alpha}.\]
				Donc l'intégrale de $x \mapsto x^{-\alpha}$ sur les segments de $[1, \pinfty)$ est majorée indépendamment du segment, donc cette fonction est abs-int sur
				$[1, \pinfty)$.
				\item si $\alpha \lneqq 1$, alors~:
				\[\int_1^X \frac {\dif x}{x^\alpha} \xrightarrow[X \to \pinfty]{} \pinfty.\]
				Donc l'intégrale de $x \mapsto x^{-\alpha}$ sur les segments de $[1, \pinfty)$ n'est pas majorée indépendamment du segment, donc cette fonction n'est pas
				abs-int sur $[1, \pinfty)$.
			\end{itemize}

			Finalement, si $\alpha = 1$, alors~:
			\[\int_1^X\frac {\dif x}x = \left[\ln x\right]_1^X = \ln X \xrightarrow[X \to \pinfty]{} \pinfty.\]
			À nouveau, l'intégrale n'est pas bornée sur les segments de $[1, \pinfty)$, indépendamment du segment, et donc $x \mapsto x^{-1}$ n'est pas abs-int sur
			$[1, \pinfty)$.
			\end{proof}

			\begin{prp} Soit $\alpha \in \R$. $x \mapsto x^{-\alpha}$ est abs-int sur $(0, 1]$ si et seulement si $a \lneqq 1$.
			\end{prp}

			\begin{proof} EXERCICE.
			\end{proof}

			\begin{ex} La fonction $x \mapsto \frac 1{\sqrt x} = x^{-\frac 12}$ est absolument intégrable sur $(0, 1]$.
			\end{ex}

		\subsection{Théorème du changement de variable}
			\begin{thm} Soient $I, J$, deux intervalles non-vides de $\R$ et non réduits à un point. Soit $\varphi : I \to J$ bijective et strictement croissante de
			classe $C^1$ sur $I$. Soit $f : J \to \R$ R-int sur tout segment de $J$. La fonction $f$ est abs-int sur $J$ si et seulement si
			$(f \circ \varphi) \cdot \varphi' : I \to \R$ est abs-int sur $I$, et on a~:
			\[\int_I\left((f \circ \varphi)\varphi'\right)(x)\dif x = \int_Jf(y)\dif y.\]
			\end{thm}

			\begin{proof} Soit $([a_n, b_n])_n$ une suite exhaustive de segments de $I$. La suite $([\varphi(a_n), \varphi(b_n)])_n$ est une suite exhaustive de
			segments de $J$ (car $\varphi$ est bijective). Puisque~:
			\[\forall n \in \N : \int_{a_n}^{b_n}\abs {(f \circ \varphi)\varphi'} = \int_{a_n}^{b_n}\abs {(f \circ \varphi)}\varphi'
				= \int_{\varphi(a_n)}^{\varphi(b_n)}\abs {f},\]
				par \CDII, on conclut que $(f \circ \varphi)\varphi'$ est abs-int sur $I$ si $f$ l'est sur $J$.

				On raisonne de manière similaire avec $\varphi^{-1}$ (qui existe car $\varphi$ est une bijection) pour montrer que $f$ est abs-int sur $J$ si
				$(f \circ \varphi)\varphi\prime$ l'est sur $I$.

				Dans ce cas, si $([a_n, b_n])_n$ est une suite exhaustive de segments de $I$, on a~:
				\[\forall n \geq 0 : \int_{a_n}^{b_n}(f \circ \varphi)\varphi\prime = \int_{\varphi(a_n)}^{\varphi(b_n)}f.\]
				En passant à la limite pour $n \to \pinfty$, on obtient~:
				\[\int_I(f \circ \varphi)\varphi\prime = \int_J f,\]
				car $([\varphi(a_n), \varphi(b_n)])_n$ est une suite exhaustive de $J$.
			\end{proof}

	\section{Intégrales convergentes}
		\subsection{Définitions et exemples}
			\begin{déf} Soit $I \subset \R$, un intervalle non-vide, et soit $f : I \to \R$ R-int sur tous les segments de $I$. On dit que l'intégrale de $f$ sur $I$
			converge lorsque~:
			\begin{itemize}
				\item[$(i)$]  $\forall ([a_n, b_n])_n$ exhaustive de $I$ : $\left(\int_{a_n}^{b_n}f\right)_n$ converge dans $\R$~;
				\item[$(ii)$] la limite ne dépend pas de la suit exhaustive choisie.
			\end{itemize}

			On note cette limite $\int_I f$.
			\end{déf}

			\begin{prp} Si $f$ est abs-int sur $I$, alors son intégrale sur $I$ converge et on a~:
			\[\int_I f(x)\dif x = \int_I f(x)\dif x,\]
			c-à-d, les deux notions ont le même sens pour la même notation.
			\end{prp}

			\begin{proof} Par le résultat X % TODO: trouver le résultat associé
			\end{proof}

			\begin{ex} La fonction $\mapsto \frac {sin x}x$ a une intégrale convergente sur $[1, \pinfty)$ mais n'est pas abs-int sur $[1, \pinfty)$.

			On remarque que $\frac {\sin x}x$ est continue sur $[1, \pinfty)$ et donc R-int sur tout segment de $I$. Soit $([a_n, b_n])_n$, une suite exhaustive de
			segments de $[1, \pinfty)$. Pour $n \in \N$, écrivons~:
			\[\int_{a_n}^{b_n}\frac {\sin x}x\dif x = \left[\frac{-\cos x}x\right]_{a_n}^{b_n} + \int_{a_n}^{b_n}\frac{\cos x}{x^2}\dif x.\]
			On sait que $\abs {\frac{\cos x}{x^2}} \leq \frac 1{x^2}$ sur $[1, \pinfty)$. Par le critère de comparaison, puisque $x \mapsto \frac 1{x^2}$ est abs-int
			sur $[1, \pinfty)$, on sait que $x \mapsto \frac{\cos x}{x^2}$ l'est également. Ainsi, la suite~:
			\[\left(\int_{a_n}^{b_n}\frac{\cos x}{x^2}\dif x\right)_n\]
			converge dans $\R$ vers une limite qui ne dépend pas de la suite $([a_n, b_n])_n$ choisie. Par ailleurs~:
			\[\left[-\frac {\cos x}x\right]_{a_n}^{b_n} = \frac{-\cos b_n}{b_n} + \frac{\cos a_n}{a_n} \xrightarrow[{[a_n, b_n] \to [1, \pinfty)}]{} 0 + \cos 1.\]
			Donc la suite $\left(\int_{a_n}^{b_n}\frac{\sin x}x\dif x\right)_n$ converge vers une limite indépendante de la suite exhaustive de segments choisie.
			Donc l'intégrale de $x \mapsto \frac{\sin x}x$ converge dans $[1, \pinfty)$.

			Montrons maintenant que la fonction n'est pas abs-int. Soit $n \in \Ns$. On sait~:
			\[\int_\pi^{n\pi}\abs {\frac{\sin x}x}\dif x = \sum_{k=1}^{n-1}\int_{k\pi}^{(k+1)\pi}\abs {\frac{\sin x}x}\dif x
				\geq \sum_{k=1}^{n-1}\int_{k\pi}^{(k+1)\pi}\frac {\abs {\sin x}}{(k+1)\pi}\dif x \geq \sum_{k=1}^{n-1}\frac {\int_0^\pi\abs {\sin x}}{(k+1)\pi}
				= \frac {\int_0^\pi\abs {\sin x}}{\pi}\sum_{k=1}^{n-1} \frac 1{k+1}\xrightarrow[n \to \pinfty]{} \pinfty.\]

			On a donc bien $x \mapsto \frac{\sin x}x$ non-abs-int sur $[1, \pinfty)$.
			\end{ex}

			\begin{ex} $\sign : x \mapsto \begin{cases}1 &\text{ si } x > 0 \\0 &\text{ si }x = 0\\-1 &\text{ si } x < 0\end{cases}$ n'admet pas d'intégrale convergente
			dans $\R$. Par exemple~:
			\[\int_{-n}^{n^2}\sign(x)\dif x = n^2 - n \xrightarrow[n \to \pinfty]{} \pinfty.\]
			\end{ex}

			\begin{prp} Soient $I \subset \R$, un intervalle non-vide, $f : I \to \R$, R-int sur tout segment de $I$. L'intégrale de $f$ converge sur $I$ si et seulement
			si pour toute suite exhaustive de segments $([a_n, b_n])_n$ de $I$, la suite $\left(\int_{a_n}^{b_n}f(x)\dif x\right)_n$ est de Cauchy.
			\end{prp}

			\begin{proof} TODO
			\end{proof}

		\subsection{Rappel : deuxième formule de la moyenne}
			Pour rappel, la première formule de la moyenne et donnée par~:

			Soient $f, g : [a, b] \to \R$, de classe $C^0$ sur $[a, b]$, avec $g \geq 0$. Il existe $c \in [a, b]$ tel que~:
			\[\int_a^b(fg)(t)\dif t = f(c)\int_a^bg(t)\dif t.\]

			\begin{prp} Soit $[a, b]$, un segment de $\R$, et soient $f, g : [a, b] \to \R$, avec $f$ R-int sur $[a, b]$, et $g \geq $, décroissante sur $[a, b]$.
			Alors il existe $c \in [a, b]$ tel que~:
			\[\int_a^b(fg)(t)\dif t = g(a)\int_a^cf(t)\dif t.\]
			\end{prp}

			\begin{proof} On fixe $N \in \Ns$, et on pose $t_n \coloneqq a + n\frac {b-a}N$ pour $0 \leq n \leq N$. Écrivons~:
			\[I_N \coloneqq \sum_{k=0}^{N-1}\int_{t_k}^{t_{k+1}}f(t)g(t_k)\dif t.\]
			On observe alors~:
			\[I_N - \int_a^b(fg)(t)\dif t = \sum_{k=0}^{N-1}f(t)(g(t_k) - g(t)).\]
			On trouve donc~:
			\begin{align*}
				\abs {I_N - \int_a^b(fg)(t)\dif t} &\leq \sum_{k=0}^{N-1} \int_{t_k}^{t_{k+1}}\abs {f(t)}\abs {g(t_k) - g(t)}\dif t
					= \sum_{k=0}^{N-1}\int_{t_k}^{t_{k+1}}\abs {f(t)}(g(t_k) - g(t))\dif t \\
				&\leq \sum_{k=0}^{N-1}\int_{t_k}^{t_{k+1}}\abs {f(t)}(g(t_k)-g(t_{k+1}))\dif t.
			\end{align*}

			Rappelons que la fonction $K : [a, b] \to \R : x \mapsto \int_a^x\abs {f(t)}\dif t$ est lipschitzienne de constante $\norm f_{\infty, [a, b]} \eqqcolon M$.
			Ainsi~:
			\begin{align*}
				\abs {I_N - \int_a^b(fg)(t)\dif t} &\leq \sum_{k=0}^{N-1}\abs {K(t_{k+1}) - K(t_k)}(g(t_k)-g(t_{k+1}))
					\leq M\sum_{k=0}^{N-1}(t_{k+1}-t_k)(g(t_k)-g(t_{k+1})) \\
				&= \frac {M(b-a)}N\sum_{k=0}^{N-1}(g(t_k) - g(t_{k+1})) \leq \frac {M(b-a)}N(g(a)-g(b)) \xrightarrow[N \to \pinfty]{} 0.
			\end{align*}

			On en déduit que $(I_N)_{N > 1}$ converge, et~:
			\[\lim_{N \to \pinfty}I_N = \int_a^b(fg)(t)\dif t.\]

			Par ailleurs, pour $N \geq 1$, on a~:
			\[I_N = \sum_{k=0}^{N-1}\int_{t_k}^{t_{k+1}}f(x)\dif xg(t_k).\]

			Posons ensuite~:
			\[F : [a, b] \to \R : x \mapsto \int_a^xf(t)\dif t.\]
			On sait que $F$ est continue sur le segment $[a, b]$, donc minorée par $m$ et majorée par $M$. En appliquant une transformation d'Abel, on trouve~:
			\begin{align*}
				I_N &= \sum_{k=0}^{N-1}\left(F(t_{k+1}) - F(t_k)\right)g(t_k) = \sum_{k=0}^{N-1}F(t_{k+1})g(t_k) - \sum_{k=0}^{N-1}F(t_k)g(t_k) \\
					&= \sum_{k=1}^NF(t_k)g(t_{k-1}) - \sum_{k=0}^{N-1}F(t_k)g(t_k) \\
					&= -F(t_0)g(t_0) + \sum_{k=1}^{N-1}F(t_k)\left(g(t_{k-1})-g(t_k)\right) + F(t_N)g(t_{N-1}).
			\end{align*}

			Par suite, on sait que $F(t_0) = F(a) = \int_a^a f = 0$, on peut donc exprimer~:
			\[m\sum_{k=1}^{N-1}\left(g(t_k-1)-g(t_k)\right)g(t_k) + mg(t_{N-1}) \leq I_N \leq M\sum_{k=1}^{N-1}\left(g(t_{k-1}) - g(t_k)\right) + Mg(t_{N-1}).\]

			En développant les sommes, on trouve~:
			\[mg(a) \leq I_N \leq Mg(a).\]

			En passant à la limite pour $N \to \pinfty$, on trouve~:
			\[mg(a) \leq \int_a^b(fg)(t)\dif t \leq Mg(a).\]

			Distinguons alors deux cas~:
			\begin{itemize}
				\item si $g(a) = 0$, alors $g \equiv 0$ sur $[a, b]$, et donc tout $c \in [a, b]$ convient~;
				\item si $g(a) \neq 0$, alors~:
				\[m \leq \frac 1{g(a)}\int_a^b(fg)(t)\dif t \leq M.\]

				La fonction $F$ étant continue sur le segment $[a, b]$, par le théorème des valeurs intermédiaires, il existe $c \in [a, b]$ tel que~:
				\[F(c) = \frac 1{g(a)}\int_a^b(fg)(t)\dif t,\]
				et donc en remultipliant par $g(a)$ de par et d'autre, on obtient~:
				\[g(a)F(c) = g(a)\int_a^cf(t)\dif t = \int_a^b(fg)(t)\dif t.\]
			\end{itemize}
			\end{proof}

		\subsection{Critère d'Abel}
			\begin{prp}[Critère d'Abel pour la convergence des intégrales] Soient $\minfty < a < b \leq \pinfty$, $f, b : [a, b] \to \R$ telles que~:
			\begin{itemize}
				\item $f$ est R-int sur tout segment de $[a, b]$ et il existe $M \gneqq 0$ tel que~:
				\[\forall x \in [a, b] : \abs {\int_a^x f(t)\dif t} \leq M~;\]
				\item $g$ est positive et décroissante vers $0$ en $b^-$ sur $[a, b]$.
			\end{itemize}

			Alors l'intégrale de $fg$ converge sur $I$.
			\end{prp}

			\begin{proof} Soit $([a_n, b_n])_n$ une suite exhaustive de segments de $[a, b)$. Posons, pour $n \in \N$~:
			\[\alpha_n \coloneqq \int_{a_n}^{b_n}(fg)(t)\dif t.\]
			Observons pour $n, p \in \N$~:
			\[\alpha_{n+p} - \alpha_n = \int_{a_{n+p}}^{b_{n+p}}(fg)(t)\dif t - \int_{a_n}^{b_n}(fg)(t)\dif t.\]

			Puisque $a_n = a$ à partir d'un certain $N \in \N$, on peut écrire~:
			\[\alpha_{n+p} - \alpha_n = \int_{b_n}^{b_{n+p}}(fg)(t)\dif t = g(b_n)\int_a^{c_{n+p}}f(t)\dif t,\]
			pour un certain $c_{n+p} \in [b_n, b_{n+p}]$ par la deuxième formule de la moyenne. On trouve finalement~:
			\[\abs {\alpha_{n+p} - \alpha_n} \leq g(b_n) \leq \abs {\int_a^{c_{n+p}}f(t)\dif t - \int_a^{b_n}f(t)\dif t} \leq 2Mg(b_n) \xrightarrow[n \to \pinfty]{} 0,\]
			par décroissance de $g$ vers $0$.

			La suite $(\alpha_n)$ est donc une suite de Cauchy, ce qui implique que l'intégrale de $(fg)$ converge sur $[a, b)$, par le critère de Cauchy.
			\end{proof}

			\begin{ex} Prenons $\beta \in (0, 1)$. La fonction $x \mapsto \frac {\sin x}{x^\beta}$ est d'intégrale convergente sur $[1, \pinfty)$ car~:
			\begin{itemize}
				\item $f : [1, \pinfty) : x \mapsto \sin x$ est R-int sur tous les segments de $[1, \pinfty)$, et pour $x \geq 1$, on a~:
				\[\abs {\int_1^x\sin t\dif t} \leq 2~;\]
				\item $g$ est positive et décroissante vers $0$ en $\pinfty$.
			\end{itemize}

			La convergence est assurée par le critère d'Abel.
			\end{ex}

			\begin{ex}Les fonctions $x \mapsto \sin(x^2)$ et $x \mapsto \cos(x^2)$ sont d'intégrale convergente sur $\Rp$. Soit $([\alpha_n, \beta_n])_n$, une suite
			exhaustive de segments de $\Rp$. Pour $n \geq 0$, écrivons~:
			\[\int_{\alpha_n}^{\beta_n}\sin(x^2)\dif x = \int_{\alpha_n^2}^{\beta_n^2}\sin t\frac {\dif t}{\sqrt t}\]
			pour $t = x^2, \dif t = 2x\dif x$. On a donc~:
			\[\frac 12\int_{\alpha_n^2}^{\beta_n^2}\sin t\frac {\dif t}{\sqrt t}
				= \frac 12\int_{\alpha_n^2}^{\beta_n^2}\sin t \frac {\dif t}{\sqrt t} + \frac 12\int_{\alpha_n^2}^{\beta_n^2}\sin t\frac {\dif t}{\sqrt t}.\]

			La fonction $t \mapsto \frac {\sin t}{\sqrt t}$ est $C^0$ sur $(0, 1]$ et prolongeable en $0$ par continuité. Elle est donc abs-int sur $(0, 1]$. Donc
			$\int_{\alpha_n^2}^1\sin t \frac {\dif t}{\sqrt t}$ converge et la limite ne dépend pas de la suite $\alpha_n \to 0$ choisie.
			La fonction $t \mapsto \sin t$ est R-int sur tout segment de $[1, \pinfty)$, avec~:
			\[\abs {\int_1^x\sin t\dif t} \leq 2.\]
			La fonction $t \mapsto \frac 1{\sqrt t}$ est décroissante vers $0$ en $\pinfty$. Alors par le critère d'Abel,
			$\int_1^{\beta_n^2}\sin t\frac {\dif t}{\sqrt t}$ converge et la limite ne dépend pas de la suite $\beta \to \pinfty$ choisie.

			On en déduit que $x \mapsto \sin(x^2)$ est d'intégrale convergente sur $\Rp$. On raisonne de manière similaire pour $x \mapsto \cos(x^2)$.
			\end{ex}

\chapter{Intégrales à paramètres}
	\section{Fonctions définies par une intégrale sur un segment fixe}
		\subsection{Un résultat de continuité}
			\begin{déf} L'ensemble $X$ est dit \textit{localement} compact lorsque~:
			\[\forall x \in X : \forall O \text{ ouvert } : x \in O \Rightarrow \exists V \in \mathcal V(x) \tq O \subset V.\]
			\end{déf}

			\begin{prp}\label{prp:intparamcontinuesidefsurcpct} Soit $[a, b]$ un segment de $\R$, et $(X, d)$ un espace métrique localement compact.
			Si $f : X \times [a, b] \to \R : (x, t) \mapsto f(x, t)$ est continue sur $X \times [a, b]$, alors~:
			\[F : X \to \R : x \mapsto \int_a^bf(x, t)\dif t\]
			est définie, et continue sur $X$.
			\end{prp}

			\begin{proof} Soit $x \in X$. $t \mapsto f(x, t)$ est continue sur $[a, b]$, donc R-int sur $[a, b]$. La fonction $F$ est donc en effet définie.

			Soit $x \in X$ et soit $V \in \mathcal V(x)$ compact dans $X$. La fonction~:
			\[V \times [a, b] \to \R : (x, t) \mapsto f(x, t)\]
			est continue sur $X \times [a, b]$. En particulier, par le théorème de Heine, elle est uniformément continue sur $V \times [a, b]$, car $V \times [a, b]$
			est compact. Soit $\varepsilon > 0$ et soit $x_0 \in X$. Il existe $\eta > 0$ et $\delta > 0$ tels que~: $\forall x, y \in X : \forall t, t' \in [a, b]$,
			si $d(x, y) < \eta$ et $\abs {t'-t} < \delta$, et $B(x_0, \eta[ \subset V$, alors $\abs {f(x, t) - f(y, t')} \leq \varepsilon$.

			En particulier, pour $x \in B(x_0, \eta[$ et $t \in [a, b]$, on a~:
			\[\abs {f(x, t) - f(x_0, t)} < \varepsilon.\]

			Par intégration, on trouve~:
			\[\abs {F(x) - F(x_0)} \leq \int_a^b\abs {f(x, t) - f(x_0, t)}\dif t \leq \varepsilon (b-a).\]
			\end{proof}

			\begin{rmq} Cette proposition est encore vraie pour un compact $\prod_{i=1}^n[a_i, b_i]$, au lieu de $[a, b]$.
			\end{rmq}

			\begin{ex} Que dire de $\lim_{x \to 0^+} \int_0^1\sin(\exp(-xt) - 1)\dif t$~?

			$f : [0, 1] \times [0, 1]  \to \R : (x, t) \mapsto \sin(\exp(-xt) - 1)$ est continue sur $[0, 1] \times [0, 1]$, d'où $F(x) = \int_0^1f(x, t)\dif t$
			est de classe $C^0$ sur $[0, 1]$, avec la proposition précédente. Donc $F(x) \xrightarrow[x \to 0^+]{} 0$.
			\end{ex}

		\subsection{Un résultat de dérivabilité}
			\begin{prp}\label{prp:dérivabilitésegmentfixe} Soient $X \subset \R^d$, un ouvert non-vide, $[a, b] \subset \R$, un segment, et
			$f : X \times [a, b] \to \R$, continue sur $X \times [a, b]$ admettant une dérivée partielle par rapport à tout $x_i$ en tout point de $X$ tel que~:
			\[\forall i \in \intint 1d : X \times [a, b] \to \R : \pd f{x_i}(x, t) \in C^0(X \times [a, b], \R).\]
			Alors la fonction $F : X \to \R : x \mapsto \int_a^b f(x, t)\dif t$ est de classe $C^1$ sur $X \times [a, b]$, et on a~:
			\[\forall i \in \intint 1d : \pd F{x_i}(x) = \int_a^b \pd f{x_i}(x, t)\dif t.\]
			\end{prp}

			\begin{proof} Pour $x_0 \in X, \delta > 0 \tq B(x_0, \delta[ \subset X$, puisque $x \mapsto f(x, t)$ est de classe $C^1$ sur $B(x_0, \delta[$,
			pour $t \in [a, b]$, on peut écrire~:
			\[f(x_0 + he_i, t) - f(x_0, t) = \int_0^h \pd f{x_i}(x_0 + se_i, t)\dif s.\]

			Ces fonctions étant continues, elles sont R-int, et on a~:
			\[\int_a^b\left(f(x_0 + he_i, t) - f(x_0, t)\right)\dif t = \int_a^b\int_0^h \pd f{x_i}(x_0 + se_i, t)\dif s\dif t
				= \int_a^b h\int_0^1\pd f{x_i}(x_0 + hse_i, t)\dif s\dif t.\]

			Pour $h \in \left[-\frac \delta2, \frac \delta2\right] \setminus \{0\}$, et en posant~:
			\[g = \left[-\frac \delta2, \frac \delta2\right] \times \left([0, 1] \times [a, b]\right) : (h, (s, t)) \mapsto \pd f{x_i}(x_0 + hse_i, t),\]
			on a~:
			\[\frac 1h\int_a^b \left(f(x_0 + he_i, t) - f(x_0, t)\right)\dif t = \int_a^b\int_0^1g(h, (s, t))\dif s\dif t.\]

			Or la fonction $g$ est continue sur son compact de définition, par continuité de $f$. Par la Proposition~\ref{prp:intparamcontinuesidefsurcpct}, on
			sait que la fonction~:
			\[h \mapsto \int_a^b\int_0^1g(h, (s, t))\dif s\dif t \in C^0([-\frac \delta2, \frac \delta2], \R).\]
			Par cette continuité, on déduit que la fonction $h \mapsto \frac 1h\left(F(x_0 + he_i) - F(x_0)\right)$ admet une limite finie en $h=0$ qui est
			$\int_a^b\int_0^1g(0, (s, t))\dif s\dif t$. On en déduit que $f$ admet une dérivée partielle par rapport à $x_i$ en $x_0$, et on a~:
			\[\pd F{x_i} = \int_a^b\int_0^1\pd f{x_i}(x_0 + 0, t)\dif s\dif t = \int_a^b\pd f{x_i}(x_0, t)\int_0^1\dif s\dif t = \int_a^b\pd f{x_i}(x_0, t)\dif t.\]

			À nouveau, par la Proposition~\ref{prp:intparamcontinuesidefsurcpct} appliquée à $(x, t) \mapsto \pd f{x_i}(x, t)$, on obtient
			$\pd F{x_i} \in C^0(X, \R)$, ce qui implique $F \in C^1(X, \R)$, et on a bien la formule ci-dessus.
			\end{proof}

	\section{Fonction définies par des intégrales sur un segment variable}
		\subsection{Un résultat de continuité}
			\begin{thm}\label{thm:continuitésegmentvariable} Soit $f : [\alpha, \beta] \times [a, b] \tocont \R$. La fonction
			$F : [\alpha, \beta] \times [a, b] \to \R : (x, T) \mapsto \int_a^Tf(x, t)\dif t$ est continue sur $[\alpha, \beta] \times [a, b]$.
			\end{thm}

			\begin{proof} Soient $(x, T) \in [\alpha, \beta] \times [a, b]$, $(\Delta x, \Delta T) \in \R^2$ tels que~:
			\[(x + \Delta x, T + \Delta T) \in [\alpha, \beta] \times [a, b].\]
			Écrivons alors~:
			\begin{align*}
				F(x + \Delta x, T + \Delta T) - F(x, T) &= \int_a^{T+\Delta T}f(x+\Delta x, t)\dif t - \int_a^Tf(x, t)\dif t \\
				&= \int_a^Tf(x+\Delta x, t)\dif t + \int_T^{T+\Delta T}f(x +\Delta x, t)\dif t - \int_a^Tf(x, t)\dif t \\
				&= \int_a^T\left(f(x+\Delta x, t) - f(x, t)\right)\dif t + \int_T^{T + \Delta T}f(x+\Delta x, t)\dif t.
			\end{align*}

			Par continuité de $f$ sur le compact $[\alpha, \beta] \times [a, b]$ et le théorème de Heine, on peut dire que $f$ est uniformément continue sur
			ce compact. On a alors pour $\varepsilon > 0$, il existe $\eta > 0$ tel que si $\abs {\Delta x} \lneqq \eta$, alors~:
			\[\forall t \in [a, b] : \abs {f(x+\Delta x, t) - f(x, t)} < \frac \varepsilon{b-a},\]
			et donc~:
			\[\abs {\int_a^T\left(f(x+\Delta x, t) - f(x, t)\right)\dif t} \leq (T-a)\max_{t \in [a, b]}\abs {f(x+\Delta x, t) - f(x, t)} \leq \varepsilon.\]

			Par ailleurs, la fonction $f$ est bornée sur son compact de définition. Donc il existe $M > 0$ tel que
			$\forall (y, t) \in [\alpha, \beta] \times [a, b] : \abs {f(y, t)} \leq M$. Si $\abs {\Delta T} < \frac \varepsilon M$ , on observe~:
			\[\abs {\int_T^{T + \Delta T}f(x + \Delta x, t)\dif t} \leq M\abs {\Delta T} < M.\]

			Dès lors, pour $\abs {\Delta x} < \eta$ et $\abs {\Delta T} < \frac \varepsilon M$, on a~:
			\[\abs {F(x+\Delta x, T) - F(x, T)} < \varepsilon.\]

			On a en effet trouvé un voisinage de $(x, T)$ qui est envoyé sur un voisinage de $F(x, T)$. La fonction $F$ est donc continue.
			\end{proof}

			\begin{cor} Soit $f : [\alpha, \beta] \times [a, b] \to \R$ continue. Soient $\phi, \psi = [\alpha, \beta] \to [a, b]$ continues sur $[\alpha, \beta]$.
			La fonction $F : [\alpha, \beta] \to \R : x \mapsto \int_{\phi(x)}^{\psi(x)}f(x, t)\dif t$ est continue sur $[\alpha, \beta]$.
			\end{cor}

			\begin{proof} Posons $G : [\alpha, \beta] \times [a, b] \to \R : (x, T) \mapsto \int_a^T f(x, t)\dif t$. Par le théorème précédent, on peut dire
			$G \in C^0([\alpha, \beta] \times [a, b], \R)$. De plus, pour $x \in [a, b]$, on peut écrire~:
			\[F(x) = \int_a^{\psi(x)}f(x, t)\dif t - \int_a^{\phi(x)}f(x, t)\dif t = G(x, \psi(x)) - G(x, \psi(x)).\]

			Par continuité des fonctions $G, \psi, \phi$, on sait que $x \mapsto G(x, \psi(x))$ et $x \mapsto G(x, \phi(x))$ sont continues sur $[\alpha, \beta]$
			par composition de fonctions continues. Ensuite, on peut dire que $F$ est continue sur $[\alpha, \beta]$ par différence de fonctions continues.
			\end{proof}

		\subsection{Un résultat de dérivabilité}
			\begin{thm}\label{thm:dérivabilitésegmentvariable} Soit $f : [\alpha, \beta] \times [a, b] \to \R$ continue sur $[\alpha, \beta] \times [a, b]$
			telle que $\pd fx$ existe en tout point de $[\alpha, \beta] \times [a, b]$ et $(x, t) \mapsto \pd fx(x, t)$ est continue sur
			$[\alpha, \beta] \times [a, b]$. Alors la fonction $F : [\alpha, \beta] \times [a, b] \to \R : (x, T) \mapsto \int_a^Tf(x, t)\dif t$ est de classe
			$C^1$ sur $[\alpha, \beta] \times [a, b]$ avec~:
			\[\pd Fx(x, t) = \int_a^T\pd fx(x, t)\dif t \qquad\qquad\text{ et }\qquad\qquad \pd FT(x, T) = f(x, T).\]
			\end{thm}

			\begin{proof} Avec le résultat de dérivabilité sur segment fixe (Proposition~\ref{prp:dérivabilitésegmentfixe}), on sait que $\pd Fx(x, T)$ existe
			en tout point et vaut $\pd Fx(x, T) = \int_a^T\pd fx(x, t)\dif t$, avec $\pd fx(x, T) \in C^0([\alpha, \beta] \times [a, b], \R)$ par le
			Théorème~\ref{thm:continuitésegmentvariable}.

			De plus, par \CDII, on sait que $\pd FT(x, T)$ existe et vaut $f(x, T)$ (continue par hypothèse) car $f(x, \cdot) \in C^0([a, b], \R)$. On sait
			également que $T \mapsto \int_a^T \pd fT(x, t)\dif t \in C^1([\alpha, \beta] \times [a, b], \R)$.

			On a donc bien $F \in C^1([\alpha, \beta] \times [a, b], \R)$.
			\end{proof}

			\begin{prp} Soit $f : [\alpha, \beta] \times [a, b] \tocont \R$ telle que $\pd fx$ existe et est continue en tout point du compact de définition de
			$f$. Soient $\psi, \phi : [\alpha, \beta] \toC1 [a, b]$. La fonction $F : [\alpha, \beta] \to \R : x \mapsto \int_{\phi(x)}^{\psi(x)}f(x, t)\dif t$
			est de classe $C^1$ sur $[\alpha, \beta]$ et on a~:
			\[\forall x \in [\alpha, \beta] : F'(x) = \psi'(x)f(x, \psi(x)) - \phi'(x)f(x, \phi(x)) + \int_{\phi(x)}^{\psi(x)}\pd fx(x, t)\dif t.\]
			\end{prp}

			\begin{proof} La fonction $G : [\alpha, \beta] \times [a, b] \to \R : (x, T) \to \int_a^Tf(x, t)\dif t$ est de classe $C^1$ par le
			Théorème~\ref{thm:dérivabilitésegmentvariable}, et on a~:
			\[\pd Gx(x, T) = \int_a^T\pd Gx(x, t)\dif t\ \qquad\qquad\text{ et }\qquad\qquad \pd GT(x, T) = f(x, T).\]

			Par composition de fonctions de classe $C^1$, on sait que $x \mapsto G(x, \phi(x))$ et $x \mapsto G(x, \psi(x))$ sont de classe $C^1$ sur
			$[\alpha, \beta]$. Par ailleurs, pour $x \in [\alpha, \beta]$, on a~:
			\[F(x) = G(x, \psi(x)) - G(x, \phi(x)).\]

			Par différence, on trouve donc $F \in C^1([\alpha, \beta], \R)$, et pour $x \in [\alpha, \beta]$, on trouve~:
			\begin{align*}
				F'(x) &= \pd Gx(x, \psi(x)) + \pd GT(x, \psi(x))\psi'(x) - \pd Gx(x, \phi(x)) - \pd GT(x, \phi(x))\phi'(x) \\
				&= \int_a^{\psi(x)}\pd fx(x, t)\dif t + \psi'(x)f(x, \psi(x)) - \int_a^{\phi(x)}\pd fx(x, t)\dif t - \phi'(x)f(x, \phi(x)) \\
				&= \int_{\phi(x)}^{\psi(x)}\pd fx(x, t)\dif t + \psi'(x)f(x, \psi(x)) - \phi'(x)f(x, \phi(x)).
			\end{align*}
			\end{proof}

	\section{Fonctions définies par des intégrales convergentes}
		\subsection{Exemple}\label{subsec:exempleintconv}
			Soit $f : \Rp \times \Rp \to \Rp : (x, t) \mapsto x\exp(-xt)$. Que dire de $F(x) = \int_0^\pinfty f(x, t)\dif t$ ?

			Fixons $x \in \Rp$. La fonction $t \mapsto x\exp(-xt)$est R-int sur tout segment de $\Rp$. De plus, $\abs {f(x, t)}t^2 \xrightarrow[t \to \pinfty]{} 0$
			si $x > 0$.Donc il existe $A_n \gneqq 0$ tel que~:
			\[\forall t \geq A_n : \abs {f(x, t)} \leq \frac 1{t^2}.\]

			Par le critère de comparaison, la fonction $t \mapsto f(\cdot, t)$ est abs-int sur $[A_n, \pinfty)$. Si la fonction est abs-int sur $[0, A_n]$, alors
			elle l'est sur $[0, \pinfty)$. Lorsque $x = 0$, alors la fonction $t \mapsto f(x, t) = 0$, donc $F(0) = 0$ est bien défini.

			Pour tout $x \gneqq 0$, on trouve~:
			\[F(x) = \lim_{T \to \pinfty}-\int_0^Tx\exp(-xt)\dif t = \lim_{T \to \pinfty}-\left[\exp(-xt)\right]_0^T
				= \lim_{T \to \pinfty} -\left(\exp(-xT) - 1\right) = 1.\]

			On en déduit que la fonction $F$ est discontinue en $0$. La fonction $f$ est en fait de classe $C^\infty$, mais
			$F(x) \coloneqq \int_0^\pinfty f(x, t)\dif t$ admet un point de discontinuité en $x = 0$.

		\subsection{Notion d'intégrales uniformément convergentes}
			\begin{déf} Soient $X \neq \emptyset, I \subset \R$, un intervalle non-vide. Soit $f : X \times I \to \R$ telle que~:
			\[\forall x \in X : t \mapsto f(x, t) \text{ est d'intégrale convergente sur } I,\]
			à savoir~:
			\[\forall x \in X : \forall \varepsilon > 0 : \exists K_{\varepsilon, x} \subset I \text{ segment } \tq
				\forall \widetilde K \subset I \text{ segment } :
					\left[K_{\varepsilon, x} \subset \widetilde K \Rightarrow \abs {\int_{\widetilde K}f(x, t)\dif t - \int_If(x, t)\dif t} < \varepsilon.\right]\]

			On dit que l'intégrale de $f$ sur $I$ converge uniformément sur $X$ lorsque $K_{\varepsilon, x}$ ne dépend pas de $x$, c'est-à-dire lorsque~:
			\[\forall \varepsilon > 0 : \exists K_\varepsilon \subset I \text{ segment } \tq \forall \widetilde K \subset I \text{ segment } :
				\left[K_\varepsilon \subset \widetilde K \Rightarrow
					\forall x \in X : \abs {\int_{\widetilde K}f(x, t)\dif t - \int_I f(x, t)\dif t} < \varepsilon\right].\]
			\end{déf}

			\begin{rmq} Lorsque $I = [a, \pinfty)$, cela revient à avoir~:
			\[\forall \varepsilon > 0 : \exists Y > 0 \tq \forall x \in X : \abs {\int_Y^\pinfty f(x, t)\dif t} < \varepsilon.\]

			Lorsque $I = [a, b]$, avec $a < b < \pinfty$, cela revient à avoir~:
			\[\forall \varepsilon > 0 : \exists \delta \in (0, b-a) \tq \forall x \in X : \abs {\int_{b-\delta}^bf(x, t)\dif t} < \varepsilon.\]

			Dans l'exemple~\ref{subsec:exempleintconv}, $f(x, t) = x\exp(-xt)$, $X = I = \Rp$, on pouvait dire~:
			\[\int_Y^\pinfty f(x, t)\dif t = \begin{cases}-\exp(-xt) &\text{ si } x > 0, \\0 &\text{ sinon}.\end{cases}\]

			On en déduit~:
			\[\sup_{x \in X}\abs {\int_Y^\pinfty f(x, t)\dif t} = 1.\]
			On en déduit que l'intégrale de $t \mapsto x\exp(-xt)$ n'est pas convergente uniformément sur $\Rp$.
			\end{rmq}

			\begin{thm} Soient $(X, d)$ un espace métrique, $I \subset \R$, un intervalle non-vide Soit $f : X \times I \tocont \R$. On suppose que l'intégrale
			de $t \mapsto f(x, t)$ converge sur $I$ uniformément sur $X$. Alors la fonction $F : X \to \R : x \mapsto \int_I f(x, t)\dif t$ est continue sur $X$.
			\end{thm}

			\begin{proof} Soit $([a_n, b_n])_n$, une suite exhaustive de segments de $I$. Pour tout $n \in \N$, on pose~:
			\[F_n : X \to \R : x \mapsto \int_{a_n}^{b_n}f(x, t)\dif t.\]
			On observe que ces $F_n$ sont sont continues par le Théorème~\ref{prp:intparamcontinuesidefsurcpct} car $[a_n, b_n]$ est un segment fixe (compact)
			et $f \in C^0(X \times I, \R)$ par hypothèse.

			Prenons, $n, p \in \N, x \in X$. Calculons~:
			\begin{align*}
				F_{n+p}(x) - F_n(x) &= \int_{a_{n+p}}^{b_{n+p}}f(x, t)\dif t - \int_{a_n}^{b_n}f(x, t)\dif t \\
				&= \int_{a_{n+p}}^{b_{n+p}}f(x, t)\dif t - \int_If(x, t)\dif t + \int_If(x, t)\dif t - \int_{a_n}^{b_n}f(x, t)\dif t.
			\end{align*}

			Pour $\varepsilon > 0$, il existe $N_\varepsilon \in \N$ tel que pour $n, p \in \N$ et $x \in X$, par continuité des $F_n$ et puisque
			$[a_n, b_n]~\xrightarrow[n \to \pinfty]{}~I$, on peut dire~:
			\[\abs {F_{n+p}(x) - F_n(x)}
				\leq \abs {\int_{a_{n+p}}^{b_{n+p}}f(x, t)\dif t - \int_If(x, t)\dif t} + \abs {\int_If(x, t)\dif t - \int_{a_n}^{b_n}f(x, t)\dif t}
				\leq 2\varepsilon.\]

			La suite $(F_n)_n$ est donc uniformément de Cauchy, on en déduit qu'elle converge uniformément sur $X$. Sa limite simple (limite de convergence
			simple) étant $F$, il vient que $f \in C^0(X, \R)$.
			\end{proof}

			\begin{thm} Soient $X \subset \R^d$, un ouvert non-vide, , $I \subset \R$, un intervalle non-vide, et $f : X \times I \tocont \R$ telle que pour
			tout $i \in \intint 1d$, $f$ admet une dérivée partielle continue par rapport à $x_i$ pour tout point de $X \times I$. Si l'intégrale sur $I$ de
			$t \mapsto f(x, t)$ converge uniformément sur $X$ et si pour tout $i \in \intint 1d$, l'intégrale sur $I$ de $t \mapsto \pd f{x_i}(x, t)$ converge
			uniformément sur $X$, alors la fonction définie par~:
			\[F : X \times \R : x \mapsto \int_If(x, t)\dif t\]
			est de classe $C^1$ sur $X$, et on a~:
			\[\pd F{x_i}(x) = \int_I\pd f{x_i}(x, t)\dif t.\]
			\end{thm}

			\begin{proof} EXERCICE.
			\end{proof}

		\subsection{Théorème de Fubini}
			\begin{thm}[Théorème de Fubini, version \CDII] Soit $f : [\alpha, \beta] \times [a, b] \tocont \R$. Les fonctions~:
			\[
				\begin{cases}
					&\displaystyle F : [\alpha, \beta] \to \R : x \mapsto \int_a^bf(x, t)\dif t \\
					&\displaystyle G : [a, b] \to \R : t \mapsto \int_\alpha^\beta f(x, t)\dif x
				\end{cases}
			\]
			sont continues sur leur segment de définition, et on a~:
			\[\int_\alpha^\beta F(x)\dif x = \int_a^b G(t)\dif t.\]
			\end{thm}

			\begin{proof} Par la Proposition~\ref{prp:intparamcontinuesidefsurcpct}, on sait que $F, G$ sont continues sur leur segment de définition. On pose~:
			\[
				\begin{cases}
					&\displaystyle H_1 : [\alpha, \beta] \to \R : X \mapsto \int_\alpha^X F(x)\dif x \\
					&\displaystyle H_2 : [\alpha, \beta] \to \R : X \mapsto \int_a^b\int_\alpha^X f(x, t)\dif x\dif t
				\end{cases}
			\]
			Par \CDII, on sait que $H_1~\in~C^1([\alpha, \beta], \R)$ avec $H_1'(x) = F(x)$. Par la Proposition~\ref{prp:dérivabilitésegmentfixe}, on trouve
			$H_2~\in~C^1([\alpha, \beta], \R)$ avec $H_2'(X) = \int_a^b\pd {}{x_i}\int_\alpha^X f(x, t)\dif x\dif t = \int_a^b f(X, t)\dif t = F(X)$.

			On en déduit $H_1'(x) = H_2'(x)$, ou encore $H_1'(x)-H_2'(x) = 0$, ce qui indique que la fonction $H_1-H_2$ est constante sur le segment
			$[\alpha, \beta]$. De plus, on trouve~:
			\[H_1(\alpha) = \int_\alpha^\alpha F(x)\dif x = 0 = \int_a^b0\dif t = H_2(\alpha).\]
			On a donc $H_1-H_2 = 0$, ou encore $H_1=H_2$ sur $[\alpha, \beta]$. En particulier, $H_1(\beta) = H_2(\beta)$, ce qui est précisément~:
			\[\int_\alpha^\beta F(x) = H_1(\beta) = H_2(\beta) = \int_a^b\int_\alpha^\beta f(x, t)\dif x\dif t = \int_a^b G(t)\dif t.\]
			\end{proof}

			\begin{thm}[Théorème de Fubini, version \CDIII]\label{thm:FubiniCDI1} Soient $[\alpha, \beta]$, un segment, $I \subset \R$, un intervalle non-vide, et
			$f : [\alpha, \beta] \tocont \R$ telle que l'intégrale sur $I$ de $t \mapsto f(x, t)$ converge uniformément sur $[\alpha, \beta]$. Alors~:
			\begin{enumerate}
				\item la fonction $F : [\alpha, \beta] \to \R : x \mapsto \int_I f(x, t)\dif t$ est continue sur $[\alpha, \beta]$~;
				\item la fonction $G : I \to \R : t \mapsto \int_\alpha^\beta f(x, t)\dif x$ est continue sur $I$~;
				\item $G$ est d'intégrale convergente sur $I$.
			\end{enumerate}

			De plus, on a~:
			\[\int_\alpha^\beta F(x)\dif x = \int_I G(t)\dif t.\]
			\end{thm}

			\begin{proof} $F$ et $G$ sont continues sur $[\alpha, \beta]$ par la Proposition~\ref{prp:intparamcontinuesidefsurcpct}.Fixons $\varepsilon > 0$.
			Soit $([a_n, b_n])_n$ une suite exhaustive de segments de $I$. Par convergence sur $I$ uniforme sur $[\alpha, \beta]$ de l'intégrale de
			$t \mapsto f(x, t)$, il existe $N_\varepsilon \in \N$ tel que~:
			\[\forall n \geq N_\varepsilon : \forall x \in [\alpha, \beta] : \abs {\int_{a_n}^{b_n} f(x, t)\dif t - \int_I f(x, t)\dif t}
				\leq \frac \varepsilon{\beta-\alpha}.\]

			On en déduit~:
			\[\abs {\int_\alpha^\beta\int_{a_n}^{b_n} f(x, t)\dif t\dif x - \int_\alpha^\beta\int_I f(x, t)\dif t\dif x}
				\leq \int_\alpha^\beta\abs {\int_{a_n}^{b_n}f(x, t)\dif t - \int_I f(x, t)\dif t}\dif x
				\leq (\beta-\alpha)\frac \varepsilon{\beta-\alpha} = \varepsilon.\]

			Par le théorème~\ref{thm:FubiniCDI1}, on peut écrire~:
			\[\int_\alpha^\beta\int_{a_n}^{b_n}f(x, t)\dif t\dif x = \int_{a_n}^{b_n}\int_\alpha^\beta f(x, t)\dif x\dif t.\]

			Prenons alors $n \geq N_\varepsilon$, on observe~:
			\[\varepsilon \geq \abs {\int_\alpha^\beta\int_{a_n}^{b_n} f(x, t)\dif t\dif x - \int_\alpha^\beta\int_I f(x, t)\dif t\dif x}
				= \abs {\int_{a_n}^{b_n}\int_\alpha^\beta f(x, t)\dif x\dif t - \int_\alpha^\beta\int_I f(x, t)\dif t\dif x}
				= \abs {\int_{a_n}^{b_n}G(t)\dif t - \int_\alpha^\beta F(x)\dif x}.\]

			Cela fournit la convergence de l'intégrale de $G$ sur $I$, et le fait que~:
			\[\int_I G(t)\dif t = \int_\alpha^\beta F(x)\dif x.\]
			\end{proof}

		\subsection{Critères de convergence uniforme d'intégrales}
			\begin{thm}[Équivalent du critère de Weierstrass des séries sur les intégrales] Soient $X \neq \emptyset$, $I \subset \R$, un intervalle non-vide,
			et $f : X \times I \to \R$ telle que pour tout $x \in X$, on a $t \mapsto f(x, t)$ R-int sur tout segment de $I$. On suppose qu'il existe une
			fonction $\varphi : I \to \R$ abs-int sur $I$ telle que~:
			\[\forall (x, t) \in X \times I : \abs {f(x, t)} \leq \varphi(t).\]

			Alors l'intégrale de $t \mapsto f(x, t)$ converge sur $I$ uniformément sur $X$.
			\end{thm}

			\begin{proof} Fixons $x \in X$. La fonction $t \mapsto f(x, t)$ est abs-int sur $I$ par le critère de comparaison avec $\varphi$
			(Proposition~\ref{prp:critèredecomparaison}). Puisque $\varphi$ est abs-int sur $I$, pour $\varepsilon > 0$ fixé, il existe $K_\varepsilon \subset I$
			segment tel que~:
			\[\forall K \subset I \text{ segment } : \left(K_\varepsilon \subset K \Rightarrow \abs {\int_K f(x, t)\dif t - \int_I f(x, t)\dif t}
				\leq \varepsilon\right).\]

			Pour $x \in X, K \subset I$ segment $\tq K_\varepsilon \subset K$, écrivons~:
			\begin{align*}
				\int_{K_\varepsilon} f(x, t)\dif t - \int_I f(x, t)\dif t &= \abs {\int_{a_\varepsilon}^{b_\varepsilon} f(x, t)\dif t - \int_I f(x, t)\dif t}
					= \abs {\int_{\inf I}^{a_\varepsilon}f(x, t)\dif t + \int_{b_\varepsilon}^{\sup I}f(x, t)\dif t} \\
				&\leq \int_{\inf I}^{a_\varepsilon}\abs {f(x, t)}\dif t + \int_{b_\varepsilon}^{\sup I}\abs {f(x, t)\dif t}
					\leq \int_{\inf I}^{a_\varepsilon}\varphi(t)\dif t + \int_{b_\varepsilon}^{\sup I}\varphi(t)\dif t \\
				&= \abs {\int_I\varphi(t)\dif t - \int_{K_\varepsilon}\varphi(t)\dif t} \leq \varepsilon,
			\end{align*}
			par choix de $\K_\varepsilon$. On a donc bien la convergence sur $I$ uniforme sur $X$ de $t \mapsto f(x, t)$.
			\end{proof}

			\begin{thm}[Équivalent du critère d'Abel des séries sur les intégrales] Soit $I = [a, b)$, où $a < b \leq \pinfty$. Soient $X \neq \emptyset$, et
			$I \subset \R$, un intervalle non-vide, et $f, g : X \times I \to \R$ tels que~:
			\begin{itemize}
				\item $\forall x \in X : t \mapsto f(x, t)$ et $t \mapsto g(x, t)$ sont R-int sur tout segment de $I$~;
				\item $\exists M \gneqq 0, a \in I \tq \forall T \in I : \forall x \in X : \abs {\int_a^T f(x, t)\dif t} \leq M$~;
				\item $t \mapsto g(x, t)$ converge vers $0$ en décroissant en $b^-$ uniformément par rapport à $x$.
			\end{itemize}

			Alors $t \mapsto f(x, t)g(x, t)$ est d'intégrale convergente sur $I$ uniformément sur $X$.
			\end{thm}

			\begin{proof} Soit $([a_n, b_n])_n$ une suite exhaustive de segments de $I$. Puisque $I = [a, b)$, il existe $N \in \N$ tel que pour $n \geq N$, on
			a $a_n \equiv a$. Pour $x \in X, n, p \in \N$, écrivons~:
			\[\int_a^{b_{n+p}}f(x, t)g(x, t)\dif t - \int_a^{b_n}f(x, t)g(x, t)\dif t = \int_{b_n}^{b_{n+p}}f(x, t)g(x, t)\dif t
				= g(x, b_n)\int_{b_n}^{c_{n, p}(x)}f(x, t)\dif t,\]
			par la seconde formule de la moyenne. On en déduit alors~:
			\[\abs {\int_a^{b_{n+p}}f(x, t)g(x, t)\dif t - \int_a^{b_n}f(x, t)g(x, t)\dif t} \leq 2g(x, b_n)M.\]

			Par hypothèse, on sait que $g(\cdot, b_n)$ converge vers $0$ uniformément par rapport à $x$. On sait donc qu'il existe $N_\varepsilon \in \N$
			tel que pour $x \in X, n \geq N_\varepsilon$, on a $0 \leq g(x, b_n) \leq \frac \varepsilon{2M}$. Finalement, on en déduit~:
			\[\forall n \geq N_\varepsilon : \forall n, p \in \N : \forall x \in X : \abs {\int_a^{b_{n+p}}f(x, t)g(x, t)\dif t - \int_a^{b_n}f(x, t)g(x, t)\dif t}
				\leq \varepsilon.\]

			En faisant tendre $p \to \pinfty$, on obtient bien~:
			\[\forall n \geq N_\varepsilon : \forall x \in X : \abs {\int_If(x, t)g(x, t)\dif t - \int_a^{b_n}f(x, t)g(x, t)\dif t} \leq \varepsilon.\]

			On en déduit alors que $t \mapsto f(x, t)g(x, t)$ admet une intégrale convergente.
			\end{proof}

	\section{Application à la régularisation et à l'approximation à une dimension}
		\subsection{Fonctions à support compact}
			\begin{déf} Soient $\Omega \subset \R$ ouvert non-vide, $f : \Omega \to \R$. On appelle le \textit{support de $f$} l'ensemble~:
			\[\supp f \coloneqq \adh \left\{x \in \Omega \tq f(x) \neq 0\right\}\]
			\end{déf}

			\begin{rmq} Le support est le plus petit fermé contenant tous les points où $f$ ne s'annule pas. De même, $\Omega \setminus \supp f$ est le plus
			grand ouvert inclus dans l'ensemble dans l'ensemble des points de $\Omega$ où $f$ s'annule.
			\end{rmq}

			\begin{prp} Il existe une fonction $\varphi : \R \to \R$ de classe $C^\infty$ sur $\R$, définie positive sur $\R$, de support $[-1, 1]$ et telle que~:
			\[\int_R \varphi(x)\dif x = 1.\]
			\end{prp}

			\begin{proof} Soit la fonction $f$ définie par~:
			\[h : \R \to \R : x \mapsto \begin{cases}\exp\left(-x^{-2}\right) &\text{ si } x > 0 \\0 &\text{ sinon }\end{cases}.\]
			On observe que $h$ est de classe $C^\infty$ sur $\Rp_0$ et $\Rm_0$. Également, on a~:
			\[h^{(k)}(x) = \frac {P_k(x)}{x^{3k}}\exp(-x^{-2}),\]
			avec $P_k \in \R[x]$, et donc les dérivées sont telles que~:
			\[\forall k \geq 1 : h^{(k)} \xrightarrow[x \to 0^+]{} 0 = h^{(k)}(0^-)\]

			De plus, on a $\supp h = \Rp$. Posons alors~:
			\[\rho : \R \to \R : x \mapsto h(1-x)h(1+x).\]

			$\rho$ est toujours $C^\infty$ sur $\R$, et est de support $[-1, 1]$. Par positivité de $\rho$ et par minoration de $\rho$ par une fonction $\gneqq 0$
			sur un fermé contenu dans $[-1, 1]$, on peut dire que~:
			\[\alpha \coloneqq \int_{[-1, 1]}\rho(x)\dif x \gneqq 0.\]

			Il suffit ensuite de poser~:
			\[\varphi \coloneqq \frac \rho\alpha.\]
			\end{proof}

			\begin{cor}\label{cor:varphi_k}Soit $\alpha > 0$. La fonction $\varphi_\alpha$ définie par~:
			\[\varphi_\alpha : \R \to \R : x \mapsto \alpha\varphi(\alpha x)\]
			est positive, de support $\left[-\frac 1\alpha, \frac 1\alpha\right]$, de classe $C^\infty$, et d'intégrale valant $1$.
			\end{cor}

		\subsection{Produit de convolution}
			\begin{prp} Soient $f, g : \R \to \R$ telles que~:
			\begin{itemize}
				\item $f$ est R-int sur tout segment de $\R$~;
				\item $g$ est $C^0$ sur $\R$ et à support compact.
			\end{itemize}

			Alors, pour tout $x$ réel, les fonctions~:
			\[t \mapsto f(x-t)g(t)\qquad\text{ et }\qquad t \mapsto f(t)g(x-t)\]
			sont abs-int, et on a~:
			\[\int_\R f(x-t)g(t)\dif t = \int_\R f(t)g(x-t)\dif t.\]
			\end{prp}

			\begin{proof} La fonction $g$ est de support compact. Donc il existe un segment $[a, b]$ tel que~:
			\[\forall x \in \R \setminus [a, b] : g(x) = 0.\]
			La fonction $g$ est de plus continue sur un compact, donc bornée par $M \gneqq 0$. On peut alors écrire pour tout $x, t \in \R$~:
			\[\abs {f(x-t)g(t)} \leq M\abs {f(x-t)}I_{\left[a \leq t \leq b\right]}.\]

			Par comparaison, on en déduit que $\abs {g(t)f(x-t)}$ est R-int sur $\R$. On sait alors que $f(x-t)g(t)$ est abs-int sur $\R$, et par changement de
			variable, on trouve~:
			\[\int_\R f(x-t)g(t)\dif t = \int_\R f(t)g(x-t)\dif t\]

			\end{proof}

			\begin{déf} On appelle \textit{produit de convolution de $f$ par $g$} la fonction définie par~:
			\[f * g : \R \to \R : x \mapsto \int_\R f(x-t)g(t)\dif t = \int_\R f(t)g(x-t)\dif t.\]
			\end{déf}

			\begin{prp}\label{prp:(f*varphi)'=f*varphi'} Soient $k \in \Ns$ et $f : \R \toC0 \R$, R-int sur tout segment. La fonction $(f * \varphi_k)$ est
			de classe $C^\infty$ sur $\R$, et on a~:
			\[\forall n \in \N : (f * \varphi_k)^{(n)} = f * (\varphi_k)^{(n)}.\]
			\end{prp}

			\begin{proof} Fixons $[a, b]$ un segment de $\R$. Prenons $x \in [a, b]$ et $k \in \Ns$. On peut écrire~:
			\[(f * \varphi_k)(x) = \int_\R f(x-t)\varphi_k(t)\dif t = \int_\R f(t)\varphi_k(x-t)\dif t = \int_{a-\frac 1k}^{b+\frac 1k}f(t)\varphi_k(x-t)\dif t.\]

			On sait que $t \mapsto f(t)\varphi_k(x-t)$ est de classe $C^0$ car $f$ est $C^0$ par hypothèse, et $\varphi_k$ est de classe $C^\infty$. De plus, on
			sait que $t \mapsto f(t)\varphi_k(x-t)$ est dérivable en $x$, ce qui donne~:
			\[\od {}x(f(t)\varphi_k(x-t))\sVert[2]_x = f(t)\varphi_k'(x-t).\]
			Par la Proposition~\ref{prp:dérivabilitésegmentfixe}, on sait que $(f*\varphi_k)$ est de classe $C^1$, et on peut écrire~:
			\[\od {}x\left(\int_{a-\frac 1k}^{b+\frac 1k}f(t)\varphi(x-t)\dif t\right) = \int_{a-\frac 1k}^{b+\frac 1k}f(t)\varphi_k'(x-t)\dif t = (f * \varphi_k')(x).\]

			En appliquant le résultat par récurrence, on obtient $(f*\varphi_k)$ de classe $C^\infty$ et~:
			\[\left(f*\varphi_k\right)^{(n)}(x) = \left(f*\left(\varphi_k^{(n)}\right)\right)(x).\]
			\end{proof}

			\begin{prp}\label{prp:f*varphi_k CVUc f} Soit $f : \R \toC0 \R$. Alors~:
			\[f*\varphi_k \CVUc \R k\pinfty f.\]
			\end{prp}

			\begin{proof} Fixons $[a, b]$, un segment de $\R$. Prenons $x \in [a, b]$ et $k \geq 1$, et calculons~:
			\[(f*\varphi_k)(x)-f(x) = \int_\R f(x-t)\varphi_k(t)\dif t - f(x)\int_\R\varphi_k(t)\dif t,\]
			car $\varphi_k(t)$ est d'intégrale valant $1$ par le Corollaire~\ref{cor:varphi_k}. On sait donc~:
			\[(f*\varphi_k)(x) - f(x) = \int_\R \left(f(x-t)-f(x)\right)\varphi_k(t)\dif t.\]

			On sait que $f$ est $C^0$ sur $[a-1, b+1] \ni x-t$ par hypothèse. Par le théorème de Heine, on sait que $f$ est uniformément continue sur $[a-1, b+1]$.
			Soit $\varepsilon > 0$. Il existe $\eta > 0$ tel que~:
			\[\forall z_1, z_2 \in [a-1, b+1] : \abs {z_1-z_2} < \eta \Rightarrow \abs {f(z_1)-f(z_2)} < \varepsilon.\]

			On observe ensuite~:
			\[\abs {(f*\varphi_k)(x)-f(x)} = \abs {\int_{-\frac 1k}^{\frac 1k}\left(f(x-t)-f(x)\right)\varphi_k(t)\dif t}.\]

			Pour $k$ tel que $\frac 1k < \eta$, on a~:
			\[\forall t \in \left(-\frac 1k, \frac 1k\right) : \abs {f(x)-f(x-t)} < \varepsilon.\]

			Dès lors, pour de tels valeurs de $k$, on trouve~:
			\[\abs {(f*\varphi_k)(x)-f(x)} = \int_{-\frac 1k}^{\frac 1k}\abs {f(x, t)-f(x)}\varphi_k(t)\dif t
				\leq \varepsilon\int_{-\frac 1k}^{\frac 1k}\varphi_k(t)\dif t = \varepsilon.\]

			Ainsi, quel que soit $[a, b] \subset \R$, on sait~:
			\[\forall \varepsilon > 0 : \exists K_\varepsilon \in \N \tq \forall k \geq K_\varepsilon : \sup_{x \in [a, b]}\abs {(f*\varphi_k)(x)-f(x)} \leq \varepsilon.\]
			\end{proof}

			\begin{prp} Soit $f : \R \toC K \R$. Alors~:
			\[\forall s \in \intint 0K : \left(f*\varphi_k\right)^{(s)} \CVUc \R k\pinfty f^{(s)}.\]
			\end{prp}

			\begin{proof} Remarquons par un raisonnement similaire à la Proposition~\ref{prp:(f*varphi)'=f*varphi'} que $(f*\varphi_k)^{(s)} = f^{(s)}*\varphi_k$, et
			appliquons la Proposition~\ref{prp:f*varphi_k CVUc f}.
			\end{proof}

			\begin{thm} Soit $[a, b] \subseteq \R$, un segment et soit $f \in C^0([a, b], \R)$. Alors~:
			\[\forall \varepsilon > 0 : \exists P \in \R[x] \tq \sup_{x \in [a, b]}\abs {f(x)-P(x)} < \varepsilon.\]
			\end{thm}

			\begin{proof} Premièrement, on étend $f$ sur $[a-1, b+1]$ en y ajoutant les segments définis par les couples $\left((a-1, 0), (a, f(a))\right)$ et
			$\left((b, f(b)), (b+1, 0)\right)$. Ensuite, par translation et homothétie, on envoie $f$ sur le segment $\left[\pm \frac 12\right]$.

			Pour $k \geq 1$, on pose~:
			\[g_k : \R \to \R : x \mapsto \begin{cases}{(1-x^2)}^k &\text{ si } \abs x < 1 \\0 &\text{ sinon}\end{cases}.\]
			On remarque que $g_k \in C^0(\R, \R)$ à support compact et $\int_\R g_k(x)\dif x \eqqcolon \alpha_k \gneqq 0$.

			On peut alors définir~:
			\[h_k \coloneqq \frac {g_k}{\alpha_k}.\]

			$h_k$ est continue sur $\R$, à support compact et d'intégrale valant 1. Étant donné que pour $x \in [-1, 1]$, on a $x^2 \leq x$, et donc $-x^2 \geq -x$,
			on peut écrire~:
			\[\alpha_k = \int_{-1}^1(1-x^2)^k\dif x = 2\int_0^1(1-x^2)^k\dif x \geq 2\int_0^1(1-x)^k\dif x = \frac 2{k+1}.\]

			De plus~:
			\[\forall \delta \in (0, 1) : h_k \xrightarrow[{[-1, 1] \setminus [-\delta, \delta]}]{CVU} 0\]

			En effet, pour $\abs x \in [\delta, 1]$, on a~: $x^2 \in [\delta^2, 1^2] = [\delta^2, 1] \supset [\delta, 1]$, et donc $1-x^2 \in [0, 1-\delta^2]$.
			Et donc~:
			\[h_k(x) = \frac {(1-x^2)^k}{\alpha_k} \leq \frac {(1-\delta^2)^k}{\alpha_k} \leq \frac {k+1}2(1-\delta^2)^k \xrightarrow[k \to \pinfty]{} 0,\]
			avec le majorant $\frac {k+1}2(1-\delta^2)^k$ ne dépendant pas de $x$. La convergence est donc uniforme.

			Pour $x \in \R, k \in \Ns$, posons~:
			\[f_k(x) = f * h_k(x).\]

			Observons que si $x \in \left[\pm \frac 12\right]$, alors~:
			\[\forall t \in \left[\pm \frac 12\right] : (x-t) \in [-1, -1],\]
			et donc~:
			\[\forall t, x \in \left[\pm \frac 12\right] : h_k(x-t) = \frac {{(1-(x-t)^2)}^k}{\alpha_k} = \sum_{k=0}^{2p}a_{k\,p}(t)x^p,\]
			avec les $a_{k\,p}(t)$ venant des coefficients du binôme de Newton.

			Ainsi, $\restr {f_k}{\left[\pm\frac 12\right]}$ est une fonction polynômiale de degré inférieur ou égal à $2k$.

			$f$ est continue sur $\R$ et à support dans $\left[\pm \frac 12\right]$, donc elle est~:
			\begin{itemize}
				\item bornée par $M \gneqq 0$ sur $\R$~;
				\item uniformément continue sur $\R$\footnote{$\sim$ théorème de Heine.}.
			\end{itemize}

			Fixons $\varepsilon > 0$. Il existe $\eta > 0$ tel que~:
			\[\forall x, y \in \R : \abs {x-y} < \eta \Rightarrow \abs {f(x)-f(y)} \leq \varepsilon.\]

			Pour $x \in \left[\pm\frac 12\right]$ et $k \geq 1$, écrivons~:
			\[f_k(x)-f(x) = \int_\R f(x-t)h_k(t)\dif t - f(x)\int_\R h_k(t)\dif t = \int_\R \left(f(x-t)-f(x)\right)h_k(t)\dif t.\]

			En prenant la valeur absolue, on trouve~:
			\begin{align*}
				\abs {f_k(x)-f(x)}
					&\leq \int_\minfty^{-\eta}\abs {f(x-t)-f(x)}h_k(t)\dif t + \int_{-\eta}^{\eta}\abs {f(x-t)-f(x)}h_k(t)\dif t + \int_\eta^\pinfty\abs {f(x-t)-f(x)}h_k(t)\dif t \\
				&= \int_{-1}^{-\eta}\abs {f(x-t)-f(x)}h_k(t)\dif t + \int_{-\eta}^{\eta}\abs {f(x-t)-f(x)}h_k(t)\dif t + \int_\eta^1\abs {f(x-t)-f(x)}h_k(t)\dif t \\
				&\leq 2M\norm {h_k}_{\infty, [-1, -\eta]} + \varepsilon\int_{-\eta}^\eta h_k(t)\dif t + 2M\norm {h_k}_{\infty, [\eta, 1]} \\
				&\leq 4M\norm {h_k}_{\infty, [\eta, 1]} + \varepsilon,
			\end{align*}
			et le majorant ne dépend pas de $x \in \left[\pm\frac 12\right]$.

			Dès lors, en choisissant $k_\varepsilon$ tel que $\forall k \geq k_\varepsilon : \norm {h_k}_{\infty, [\eta, 1]} \leq \frac \varepsilon{4M}$, alors il vient que~:
			\[\forall k \geq k_\varepsilon : \sup_{x \in \left[-\frac 12, \frac 12\right]}\abs {f_k(x)-f(x)} \leq 2\varepsilon.\]
			\end{proof}

			% Exercice dans le cours

\chapter{Critère de compacité en dimension infinie~: le théorème d'Arzela-Ascoli}
	\section{Rappels de topologie métrique}
		\subsection{Densité et séparabilité}
			\begin{déf} Soit $(X, d)$ un espace métrique, et soit $A \subseteq X$. On appelle \textit{adhérence de $A$} l'ensemble~:
			\[\adh A \coloneqq \bigcap_{\overset {F \text{ fermé }}{F \supset A}} F.\]

			$\adh A$ est, par construction, le plus petit (au sens de l'inclusion) fermé de $X$ qui contient $A$.
			\end{déf}

			\begin{rmq}~
			\begin{itemize}
				\item $x \in X$ est dans $\adh A$ si et seulement si $\forall \varepsilon > 0 : B(x, \varepsilon[ \cap A \neq \emptyset$~;
				\item l'ensemble $\adh A$ peut également être défini par l'ensemble des limites de suites de $A$ qui convergent dans $X$.
			\end{itemize}
			\end{rmq}

			\begin{déf} Soient $X \neq \emptyset$ et $A \subseteq X$. On dit que $A$ est \textit{dense} dans $X$ lorsque $\adh A = X$.
			\end{déf}

			\begin{déf} L'ensemble $A$ est dit \textit{dénombrable} lorsqu'il existe $\varphi : \N \to A$ bijective.
			\end{déf}

			\begin{déf} Soit $(x_n)_n$ une suit de $X$. On dit que $x^*$ est une \textit{valeur d'adhérence de $(x_n)$} lorsqu'il existe une sous-suite
			$(x_{\psi(n)})_n$ de $(x_n)$ qui converge en $x^*$.
			\end{déf}

			\begin{déf}Une suite $(x_n)_n$ est dite \textit{dense dans $X$} lorsque l'ensemble de ses valeurs d'adhérence dans $X$ est $X$.
			\end{déf}

			\begin{déf} Un espace métrique $(X, d)$ est dit \textit{séparable} lorsqu'il possède une suite dense.
			\end{déf}

			\begin{prp} Soit $(X, d)$ un espace métrique. Il est séparable si et seulement si il admet une partie dense finie ou dénombrable
			\end{prp}

			\begin{proof} Soit $(x_n)_n$ une suite dense dans $X$. La partie $A$ définie par~:
			\[A \coloneqq \bigcup_{n \in \N}\{x_n\} = \left\{x_n \tq n \in \N\right\}\]
			est finie ou dénombrable, dense dans $X$ par définition.

			Soit maintenant $A$ dense dans $X$. Différencions les cas où $A$ est finie et où $A$ est dénombrable.
			\begin{itemize}
				\item si $A = \{x_1, \ldots, x_N\}$ est finie, alors $X = \{x_0, \ldots, x_N\} = A$, et la suite $(x_0, \ldots, x_N, x_0, \ldots, x_N, x_0, \ldots)$
				est dense dans $X$~;
				\item si $A = \{x_1, \ldots, x_N, \ldots\} = \bigcup_{n \in \N}\{x_n\}$ est dénombrable, alors la suite $(x_0, x_0, x_1, x_0, x_1, x_2, x_0, \ldots)$
				est dense dans $X$.
			\end{itemize}
			\end{proof}

			\begin{ex}~
			\begin{itemize}
				\item $A = \Q$ est dénombrable (et dense) dans $\R$, et donc $(\R, \abs .)$ est séparable~;
				\item $A = \Q^d$ est dénombrable (et dense) dans $\R^d$, et donc $(\R, \norm .)$ est séparable\footnote{La norme n'est pas précisée ici car dans
				$\R^n$, toutes les normes sont équivalentes.}.
			\end{itemize}
			\end{ex}

			\begin{déf} Soit $X$ dénombrable. On appelle \textit{énumération} toute bijection $\varphi : X \to \N$
			\end{déf}

			\begin{prp} Soit $A \subset \R^d$. Alors $A$ est séparable.
			\end{prp}

			\begin{proof} Montrons qu'il existe une partie dense dans $A$ finie ou dénombrable. Soit $(x_q)_{q \in \N}$, une énumération de $\Q^d$. Pour $n \geq 1$,
			on a~:
			\[A \subset \bigcup_{q \in \N}B(x_q, n^{-1}[ = \R^d,\]
			par densité de $\Q^d$ dans $\R^d$.

			Pour $n \geq 1$, notons
			\[C_n \coloneqq \left\{q \in \N \tq B(x_q, n^{-1}[ \, \cap A \neq 0\right\} \subseteq \N.\]
			On sait donc que $C_n$ est fini ou dénombrable. Pour tout $n \geq 1$, et $q \in C_n$, on peut choisir~:
			\[y_{n\,q} \in B(x_q, n^{-1}[ \, \cap A.\]

			Pour $n \geq 1$, on pose alors~:
			\[X_n \coloneqq \bigcup_{q \in C_n}\left\{y_{n\,q}\right\} \neq \emptyset,\]
			fini ou dénombrable, et donc~:
			\[X \coloneqq \bigcup_{n \in \N}X_n\]
			est non-nul, fini ou dénombrable.

			Il reste à montrer que $X$ est dense dans $A$.

			Soient $x \in A$ et $\varepsilon > 0$ fixés. Il existe $n_0 \in \Ns$ tel que $n_0 > \frac 2\varepsilon$. Ainsi~:
			\[x \in A \subset \bigcup_{q \in \N}B(x_q, {n_0}^{-1}[.\]

			Donc, il existe $q_0 \in \N \tq \norm {x-x_{q_0}} < \frac 1{n_0} < \frac \varepsilon2$. De plus, on peut dire que $y_{n_0\,q_0} \in X_n \subset X$.
			De plus, pour $y_{n\,q} \in X$~:
			\[\norm {x-y_{n\,q}} \leq \norm {x-x_{q_0}} + \norm {x_{q_0} - y_{n\,q}} < \frac \varepsilon2 + \frac 1{n_0} < \varepsilon.\]
			\end{proof}

	\section{L'espace $C_b^0(X, \R)$}
		\begin{déf} Soit $X \subset \R^d$ non-nul. On définit~:
		\[C^0_b(X, \R) \coloneqq \{f \in C^0(X, \R) \tq f \text{ est bornée}\}.\]
		\end{déf}

		\begin{prp}~
		\begin{enumerate}
			\item $\evnCb0X\R$ est un \evn~;
			\item $C^0_b(X, \R)$ est un fermé de $\left(B(X, \R), \norm \cdot_\infty\right)$~;
			\item $C^0_b(X, \R)$ est complet.
		\end{enumerate}
		\end{prp}

		\begin{proof}~
		\begin{enumerate}
			\item EXERCICE.
			\item Soit $f_n \in C^0_b(X, \R) \tq$~:
			\[\exists f \in B(X, \R) \tq f_n \xrightarrow[n \to \pinfty]{\norm \cdot_\infty} f.\]
			$f$ est limite sur $X$ d'une suite de fonctions continues sur $X$. Donc $f \in C^0_b(X, \R)$, et donc $C^0_b(X, \R)$ est fermé dans $B(X, \R)$.
			\item $C^0_b(X, \R)$ est fermé dans $\left(B(X, \R), \norm \cdot_\infty\right)$ qui est complet, donc $C^0_b(X, \R)$ est complet.
		\end{enumerate}
		\end{proof}

		\begin{prp} Soit $X \subset \R^d$. Si $X$ est compact, alors $C^0(X, \R) = C^0(X, \R)$.
		\end{prp}

		\begin{proof} On sait que $C^0_b(X, \R) \subseteq C^0(X, \R)$ pour tout ensemble $X$. Prenons $f \in C^0(X, \R)$. Une fonction continue sur un compact
		est bornée, du coup $f \in C^0_b(X, \R)$, et donc $C^0(X, \R) \subseteq C^0_b(X, \R)$.
		\end{proof}

		\begin{déf} On note $\mathcal P([a, b])$ l'ensemble des fonctions polynômiales définies sur $[a, b]$ à valeur dans $\R$.
		\end{déf}

		\begin{prp}~
		\begin{enumerate}
			\item $\mathcal P([a, b]) \subset C^0([a, b], \R) = C^0_b([a, b], \R)$~;
			\item $\mathcal P([a, b])$ est dense dans $\evnC0{[a, b]}\R$.
		\end{enumerate}
		\end{prp}

		\begin{proof}~
		\begin{enumerate}
			\item EXERCICE.
			\item Weierstrass.
		\end{enumerate}
		\end{proof}

		\begin{cor} $\evnC0{[a, b]}\R$ est séparable.
		\end{cor}

		\begin{proof} $\Q[x]$ est dénombrable et dense dans $\evnC0{[a, b]}\R$. En effet, si $f \in C^0([a, b], \R)$ et $\varepsilon > 0$ sont fixés, alors par
		Weierstrass, il existe $P \in \R[x]$ tel que~:
		\[\norm {f-P}_\infty < \frac \varepsilon2.\]

		On peut écrire $P$ sous la forme~:
		\[P = \sum_{k=0}^da_kx^k,\qquad\qquad a_k \in \R.\]

		Par densité de $\Q$ dans $\R$, il existe $b_0, \ldots, b_k \in \Q$ tels que~:
		\[\max_{i \in \intint 0d}\abs {a_i-b_i} \leq \frac \varepsilon{2\sum_{x \in [a, b]}\sum_{\gamma = 0}^d\abs x^k}.\]

		Posons~:
		\[Q \coloneqq \sum_{k=0}^db_kx^k,\]
		le polynôme associé à ces coefficients. On trouve alors~:
		\begin{align*}
			\norm {P-Q}_\infty &\leq \sum_{x \in [a, b]}\abs {a_k-b_k}\abs x^k
				\leq \sup_{x \in [a, b]}\sum_{k=0}^d\frac \varepsilon{2\sup_{x' \in [a, b]}\sum_{\gamma=0}^d\abs {x'}^\gamma}\abs {x}^k \\
			&= \frac \varepsilon{2\sup_{x \in [a, b]}\sum_{k=0}^d\abs x^k}\sup_{x \in [a, b]}\sum_{k=0}^d\abs x^k = \varepsilon.
		\end{align*}

		Et finalement, on a~:
		\[\norm {f-Q}_\infty \leq \norm {f-P}_\infty + \norm {Q-P}_\infty \leq \varepsilon.\]
		\end{proof}

	\section{Théorème d'Arzela-Ascoli}
		\subsection{Motivation}
			Soit $X \subset \R^d$ non-vide. $X$ est compact si et seulement si il est fermé et borné.

			Dans l'\evn $(E, \norm \cdot) = \evnC0{[a, b]}\R$, la suite~:
			\[f_k : [0, 1] \to \R : x \mapsto x^k\]
			est bornée car pour tout $k \in \N$, on a $\norm {f_k}_\infty \leq 1$. Cependant, elle n'a pas de sous-suite convergente dans $\evnC0{[a, b]}\R$.
			En effet, s'il existe $\varphi : \N \to \N$ strictement croissante, $f \in C^0$ telle que~:
			\[f_{\varphi(k)} \xrightarrow[k \to \pinfty]{\norm \cdot_\infty} f,\]
			alors $f : [0, 1] \to \R : x \mapsto I_{[x=1]} \not \in C^0([0, 1])$, ce qui est une contradiction.

			L'objectif du théorème d'Arzela-Ascoli est de donner un critère (condition suffisante) pour qu'une partie de $\evnC {0}{[0, 1]}{\R}$ soit d'adhérence
			compacte.

		\subsection{Énoncé et démonstration}
			\begin{déf} Soient $X \subset \R^d$ non-vide, $B \subset \mathcal F(X, \R)$, une partie de l'ensemble des fonctions $X \to \R$. On dit que $B$ est
			\textit{équicontinue} sur $X$ lorsque~:
			\[\forall \varepsilon > 0 : \exists \eta > 0 \tq \forall f \in B : \forall x, y \in X :
				\left(\norm {x-y} < \eta \Rightarrow \abs {f(x)-f(y)} < \varepsilon\right).\]
			\end{déf}

			\begin{rmq} Lorsque $X = [0, 1]$ et $B \subset \evnC1X\R$, si $\exists M \gneqq 0 \tq \forall f \in B : \norm {f'}_\infty < M$, alors $B$ est
			équicontinue sur $X$. En effet~:
			\[\forall f \in B : \forall x, y \in X : \abs {f(x)-f(y)} \leq M\abs {x-y},\]
			par le théorème des accroissements finis. Dès lors, $\eta = \frac \varepsilon M$ convient.
			\end{rmq}

			\begin{thm}[Théorème d'Arzela-Ascoli] Soient $A \subset \R^d$ compact et $B \subset \evnC0A\R$ non-nul. Si $B$ est bornée
			(pour $\norm \cdot_{\infty, A}$) et équicontinue, alors $B$ est d'adhérence compacte.
			\end{thm}

			\begin{rmq} Cela amène que pour toute suite de points de $B$, on peut extraire une sous-suite qui converge dans $\adh B \subset C^0(A, \R)$.
			\end{rmq}

			\begin{proof} $A \subset \R^d$ est compacte et donc séparable. Soit $C$ une partie dénombrable ou finie dense dans $A$.

			\begin{itemize}
				\item Si $C$ est finie, alors $C = \{x_1, \ldots, x_k\}$ pour $k \in \Ns$ et $A = C$. Soit $(f_n)_n \subset B$. La suite $(f_n(x_1))_n \subset \R$
				est bornée (car $B$ est bornée) et admet une sous-suite $(f_{\varphi_1(n)}(x_1))_n \subset \R$ convergente dans $\R$.

				La suite $(f_{\varphi_1(n)}(x_2))_n \subset \R$ est bornée donc admet une sous-suite $(f_{(\varphi_1 \circ \varphi_2)(n)}(x_2))$ convergente
				dans $\R$. En réitérant jusque $k$, on trouve $\varphi_1, \ldots, \varphi_k : \N \to \N$ strictement croissantes et il existe $f(x_1), \ldots,
				f(x_n) \in \R$ tels que~:
				\[\forall i \in \intint 1k : f_{(\varphi_1 \circ \ldots \circ \varphi_k)(n)}(x_i) \xrightarrow[n \to \pinfty]{} f(x_i).\]

				On a alors $f \in C^0(A, \R)$, et on a bien~:
				\[\norm {f_{(\varphi_1 \circ \ldots \circ \varphi_k)(n)} - f}_{\infty, A} =
					\max_{i \in \intint 1n}\abs {f_{(\varphi_1 \circ \ldots \circ \varphi_k)(n)}(x_i) - f(x_i)}
					\xrightarrow[n \to \pinfty]{} 0.\]
				\item Si $C$ est dénombrable, on pose $(x_n)$ une énumération de $C$. Soit $(f_n) \subset B$. La suite $(f_n(x_0))$ est bornée dans $\R$ car
				$B$ est bornée et donc admet une sous-suite convergente , que l'on note $(f^{(0)}_n(x_0))_n$. Cette sous-suite est réelle et bornée donc admet
				une sous-suite convergente que l'on note $(f^{(1)}_n(x_1))_n$. En réitérant, on trouve une suite d'extractions $(f^{(k)}_n)_k$ telle que
				$f^{(k)}_n = f^{(k-1)}_{\varphi_k(n)}$, avec $\varphi_i$ strictement croissante pour $i \geq 0$. Pour tout $k$ naturel, on pose~:
				\[g_k = f^{(k)}_k.\]
				$(g_k)_k$ est une extraction diagonale de Cantor. De plus, la suite $(g_k)_k$ est une suite extraite de $(f_n)_n$. Pour tout $p$ naturel, la
				suite $(g_k(x_p))_k$ converge donc vers $f(x_p)$ car~:
				\[\forall \ell \geq p : g_\ell(x_p) = f^{(\ell)}_\ell(x_p),\]
				et donc $(g_k(x_p))_k$ est extraite de $(f_k^{(p)}(x_p))_k$ avec~:
				\[f_k^{(p)}(x_p) \xrightarrow[k \to \pinfty]{} f(x_p).\]

				Montrons maintenant que la suite $(g_k)_k$ est uniformément de Cauchy sur $A$. Fixons $\varepsilon > 0$. Soit $\eta > 0$ le module d'équicontinuité
				de $B$ pour $\varepsilon$. Écrivons~:
				\[A \subset \bigcup_{y \in A}B\left(y, \frac \eta2\right[.\]

				Par compacité de $A$, on sait qu'il existe un recouvrement fini, et donc $q \in \N$ et $y_1, \ldots y_q \in A$ tels que~:
				\[A \subset \bigcup_{j=1}^qB\left(y_j, \frac \eta2\right[.\]

				Par définition de $C$ (séparabilité de $A$), on sait~:
				\[\forall j \in \intint 1q : \exists x_{p_j} \tq \norm {x_{p_j} - y_j} \leq \frac \eta2.\]

				Les suites $(g_k(x_{p_i}))_k$ convergent dans $\R$ pour $i \in \intint 1q$ et donc de Cauchy. Puisqu'elles sont en nombre fini, il existe
				$N \in \N$ tel que~:
				\[\forall m, n \geq N : \abs {g_m(x_{p_j}-g_n(x_{p_j})} \leq \varepsilon.\]

				Soit $x \in A$. Par compacité de $A$, il existe $j \in \intint 1q$ tel que $\norm {x-y_j} \leq \frac \eta2$, et~:
				\[\norm {x-x_{p_j}} \leq \norm {x - y_j} + \norm {y_j - x_{p_j}} \leq 2\frac \eta2 = \eta.\]

				Pour $m, n > N$, on trouve donc~:
				\[\abs {g_m(x)-g_n(x)} \leq \abs {g_m(x) - g_m(x_{p_j})} + \abs {g_m(x_{p_j}) - g_n(x_{p_j})} + \abs {g_n(x_{p_j}) - g_n(x)} \leq 3\varepsilon,\]
				par Cauchy et équicontinuité. On en déduit que la suite $(g_n)_n$ est de Cauchy dans $\evnC0A\R$.
			\end{itemize}
			\end{proof}

\part{Équations différentielles}
\chapter{Conditions suffisantes d'existence et d'unicité de solutions}
	\section{Équations différentielles - forme normale - réduction à l'ordre 1}
		\subsection{Généralités}
			\begin{déf} On appelle \textit{équation différentielle} toute relation de la forme~:
			\begin{equation}\label{eq:equadiff}\tag{*}
			F(t, y(t), y^{(1)}(t), \ldots, y^{(p)}(t)) = 0\qquad\qquad t \in I,
			\end{equation}
			où~:
			\begin{itemize}
				\item $I$ est un intervalle de $\R$~;
				\item $F : I \times \Omega_0 \times \Omega_1 \times \ldots \Omega_p \to \R$ est une fonction~;
				\item $\Omega_0, \Omega_1, \ldots, \Omega_p$ sont des ouverts de $\R^d$.
			\end{itemize}
			$y : J \subset I \to \R^d$ est une fonction inconnue définie sur un intervalle $J$ inconnu également et $p$ fois dérivable sur $J$, telle que~:
			\[\forall t \in J : \forall j \in \intint 0p : y^{(j)}(t) \in \Omega_j,\]
			et dont les dérivées sont liées par l'équation~(\ref{eq:equadiff}).
			\end{déf}

			\begin{déf} Une équation différentielle est dite \textit{résoluble} lorsqu'elle peut être mise de manière équivalente sous forme normale~:
			\begin{equation}\label{eq:equadiffnormale}\tag{\#}
			y^{(p)}(t) - f(t, y(t), \ldots, y^{(p-1)}(t)) = 0,
			\end{equation}
			où $f : I \times \Omega_0 \times \ldots \times \Omega_{p-1} \to \Omega_p$.
			\end{déf}

		\subsection{Réduction à l'ordre 1}
			\begin{rmq} Une équation sous forme normale~(\ref{eq:equadiffnormale}) est équivalente à l'équation d'ordre 1 $Y'(t) - G(t, Y(t)) = 0$, où~:
			\[Y(t) = \begin{bmatrix}y(t) \\y^{(1)}(t) \\ \vdots \\ y^{(p-1)}(t)\end{bmatrix} \qquad\qquad \text{ et } \qquad\qquad
			G(t, Y(t)) = \begin{bmatrix}Y_0(t) \\ Y_1(t) \\ \vdots \\ Y_{p-1}(t) \\ f(t, Y_0(t), \ldots, Y_{p-1}(t)\end{bmatrix}.\]
			\end{rmq}

			\begin{rmq} Toute équation différentielle résoluble étant équivalente à une équation différentielle d'ordre 1, on étudiera uniquement ces dernières,
			et cela permettra de résoudre les autres, sans perte de généralité.
			\end{rmq}

		\subsection{Problème de Cauchy}
			\begin{déf} On se donne un équation différentielle (ED) d'ordre 1 résoluble~:
			\[y'(t) = f(t, y(t)),\]
			avec~:
			\begin{itemize}
				\item $f : I \times \Omega \to \R^d$~;
				\item $I \subset \R$ un intervalle~;
				\item $\Omega \subset \R^d$, un ouvert.
			\end{itemize}

			On appelle \textit{donnée de Cauchy} tout couple $(t_0, y_0) \in I \times \Omega$.

			On appelle \textit{problème de Cauchy} le fait de chercher $J \subset I$ un intervalle et $y : J \to \R^d$ tels que~:
			\begin{equation}\label{eq:equadiffPC}\tag{PC}
			\left\{\begin{aligned}
				&\forall t \in J : y'(t) = f(t, y(t)) \\
				&y(t_0) = y_0
			\end{aligned}\right.
			\end{equation}
			\end{déf}

		\subsection{Formulation intégrale}
			\begin{prp} Si $f \in C^0(I \times \Omega, \R^d)$, alors $y : J \tocont \Omega$, avec $t_0 \in J$ est solution de~(\ref{eq:equadiffPC}) si et
			seulement si~:
			\begin{equation}\label{eq:prppcintégrale}
				\forall t \in J : y(t) = y_0 + \int_{t_0}^tf(s, y(s))\dif s.
			\end{equation}
			\end{prp}

			\begin{proof} Supposons d'abord $y$ solution de~(\ref{eq:equadiffPC}). Alors~:
			\[\forall t \in J : y'(t) = f(t, y(t)).\]
			Par dérivabilité de $y$ sur $J$, on sait que $y \in C^0(J)$. Puisque $y$ est à valeurs dans $\Omega$, on sait que $f \in C^0(I \times \Omega)$ avec
			$J \subset I$. La fonction $t \mapsto f(t, y(t))$ est donc continue sur $J$. Ainsi, $y'$ est continue sur $J$, et donc $y \in C^1(J, \R^d)$, et on a~:
			\[y(t) - y(t_0) = \int_{t_0}^ty'(t)\dif t,\]
			ou encore~:
			\[y(t) = y_0 + \int_{t_0}^t f(s, y(s))\dif s.\]

			Maintenant, supposons que $y$ vérifie~(\ref{eq:prppcintégrale}). Puisque $y \in C^0(J, \Omega)$, la fonction $s \mapsto f(s, y(s))$ est continue
			sur $J$. Elle est donc intégrable, et $t \mapsto \int_{t_0}^t f(s, y(s))\dif s$ est de classe $C^1$ sur $J$. On a alors~:
			\[\od {}t\int_{t_0}^tf(s, y(s))\dif s = f(t, y(t)).\]
			Par hypothèse, on a~:
			\[y(t) = y_0 + \int_{t_0}^tf(s, y(s))\dif s.\]
			Dès lors, en dérivant terme à terme, on trouve~:
			\[y'(t) = f(t, y(t)),\]
			et on a de plus~:
			\[y(t_0) = y_0 + \int_{t_0}^{t_0}f(s, y(s))\dif s = y_0 + 0 = y_0.\]
			$y$ est donc bien solution de~(\ref{eq:equadiffPC}).
			\end{proof}

	\section{Existence et unicité locales}
		\subsection{Théorème du point fixe de Banach}
			\begin{déf} Soient $(X, d_X)$ et $(Y, d_Y)$ deux espaces métriques. $f : X \to Y$ est dite \textit{contractante} lorsque~:
			\[\exists k \in [0, 1) \tq \forall x, y \in X : d_Y(f(x), f(y)) \leq kd_X(x, y).\]
			\end{déf}

			\begin{thm}[Théorème du point fixe de Banach] Soient $(X, d)$ un espace métrique, $A \subset X$ une partie complète non-vide et $f : A \to A$
			contractante sur $A$. Alors~:
			\begin{itemize}
				\item $f$ admet un unique point fixe $a^* \in A$~;
				\item $\forall x_0 \in A$, la suite $x_n = f(x_{n-1})$ converge dans $A$ en $a^*$.
			\end{itemize}
			\end{thm}

			\begin{proof}~
			\begin{itemize}
				\item Montrons d'abord l'existence de $a^*$. Fixons $x_0 \in A$.  La suite $x_n = f(x_{n-1})$ est bien définie dans $A$ (car $f(A) \subseteq A$).
				Observons que~:
				\[\forall n \in \N : x_n = f^n(x_0).\]

				Soient $n, p \in \N$. On calcule~:
				\begin{align*}
					d(x_{n+p}, x_n) &\leq d(x_{n+p}, x_{n+p-1}) + d(x_{n+p-1}, x_{n+p-2}) + \ldots + d(x_{n+1}, x_n) \\
					&\leq k^{p-1}d(x_{n+1}, x_n) + k^{p-2}d(x_{n+1}, x_n) + \ldots + d(x_{n+1}, x_n) \\
					&\leq \frac {1-k^p}{1-k}d(x_{n+1}, x_n) \leq \frac 1{1-k}d(x_{n+1}, x_n) \\
					&\leq \frac 1{1-k}k^nd(x_1, x_0) \xrightarrow[n \to \pinfty]{} 0,
				\end{align*}
				et ce, indépendamment de $p$. La suite $(x_n)_n$ est donc de Cauchy, et par complétude de $A$ (hypothèse), on sait que $(x_n)_n$ converge dans $A$.
				Appelons cette limite $a^*$. On a alors~:
				\[a^* = \lim_{n \to \pinfty} x_n = \lim_{n \to \pinfty}f(x_{n-1}) = f(a^*).\]
				Le point $a^*$ est donc un point fixe.

				Montrons ensuite l'unicité de ce point fixe. Soient $x, y \in A$ deux points fixes de $f$. On sait alors~:
				\[x = f(x) \qquad\qquad \text{ et } \qquad\qquad y = f(y).\]
				Or, puisque $f$ est contractante, on sait~:
				\[d(x, y) = d(f(x), f(y)) \leq kd(x, y),\]
				ou encore~:
				\[(1-k)d(x, y) \leq 0.\]

				Or on sait que $1-k \gneqq 0$. Donc on a $d(x, y) \leq 0$, et donc $d(x, y) = 0$, ce qui par séparabilité des points d'une métrique implique $x=y$.
				\item On a vu que $x_n = f(x_{n-1})$ était convergente pour toute valeur initiale de $x_0$. Or, on sait également que le point fixe de $f$ est
				unique, et donc pour tout $x_0$, la suite $x_n = f(x_{n-1})$ converge vers $a^*$ cet unique point fixe.
			\end{itemize}
			\end{proof}

			\begin{cor} Soit $A$ une partie non-vide et complète d'un espace métrique. Soit $f : A \to A$. Si $f$ admet une puissance contractante, alors $f$
			admet un unique point fixe $a^*$ dans $A$.
			\end{cor}

			\begin{proof} Soit $n \in \Ns$ tel que $f^n$ est contractante. Par le théorème de Banach, on sait que $f^n$ admet un unique point fixe $a^*$ sur $A$.
			On peut alors écrire $f^n(f(a^*)) = f(f^n(a^*)) = f(a^*)$. Donc $f(a^*)$ est un point fixe de $f^n$. Et par unicité, on sait que $f(a^*) = a^*$.

			Soit $a \in A$ un point fixe de $f$. Cela veut dire $a = f(a) = f(f(a)) = \ldots = f^n(a)$. Donc $a$ est un point fixe de $f^n$. À nouveau, par
			unicité, $a = a^*$.
			\end{proof}

		\subsection{Cylindres en espace-temps}
			\begin{déf} Soit $f : I \times \Omega \to \R^d$, où $I \subset \R$ est un intervalle et $\Omega \subset \R^d$ est un ouvert.

			On dit que $f$ est lipschitzienne en espace sur $I \times \Omega$ lorsqu'il existe $M \gneqq 0$ tel que~:
			\[\forall t \in I : \forall x, y \in \Omega : \norm {f(t, x) - f(t, y)} \leq M\norm {x-y}.\]

			On dit que $f$ est localement lipschitzienne en espace sur $I \times \Omega$ lorsque~:
			\[\forall J \times K \subset I \times \Omega \text{ compact }\exists M(J, K) \tq \forall t \in J :
				\forall x, y \in K : \norm {f(t, x) - f(t, y)} \leq M(J, K)\norm {x-y}.\]
			\end{déf}

			\begin{déf}[Définition équivalente de localement lipschitzien] $f : I \times \Omega \to \R^d$ est localement lipschitzienne en espace lorsque~:
			\[\forall (t, x) \in I \times \Omega : \exists M \gneqq 0, \widetilde I \times \widetilde \Omega \text{ compacts } \subset I \times \Omega \tq
				\forall t \in \widetilde I : \forall x, y \in \widetilde \Omega : \norm {f(t, x) - f(t, y)} \leq M\norm {x-y}.\]
			\end{déf}

			\begin{prp} Si $f \in C^1(I \times \Omega, \R)$, avec $I \subset \R$, et $\Omega \subset \R^d$, tous deux ouverts, alors $f$ est localement
			lipschitzienne par rapport à $x$ (en espace).
			\end{prp}

			\begin{proof} Soient $t \in I, x \in \Omega$. On choisit $\delta \gneqq 0$ tel que $(t-\delta, t+\delta) \subset I$ et $\varepsilon > 0$ tel que
			$B(x, \varepsilon[ \subset \Omega$. La fonction $(t, x) \mapsto \dif_xf(t, \cdot)$\footnote{La notation $\dif_xf(t, \cdot)$ correspond à la dérivée
			partielle de $f$ par rapport à sa variable d'espace, évaluée en $x$. Donc $\dif_{x_0}f(t, \cdot) = \pd fx(t, x_0)$.}est continue sur
			$\left[t-\frac \delta2, t+\frac \delta2\right] \times B\left(x, \frac \varepsilon2\right]$ compact car $f$ est $C^1$. En particulier, elle est bornée,
			donc il existe $M \gneqq 0$ tel que~:
			\[\norm {\dif_xf(t, \cdot)} \leq M.\]

			Soient $y_1, y_2 \in B\left(x, \frac \varepsilon2\right[$ deux valeurs en espace, et $t \in \left[t_0 \pm \frac \delta2\right]$ une valeur en temps.
			On a alors~:
			\[f(t, y_2) - f(t, y_1) = \int_{y_1}^{y_2}\pd fx(t, y)\dif y = \int_0^1\dif_{sy_2 + (1-s)y_1}f(t, \cdot)(y_2-y_1)\dif s,\]
			que l'on peut majorer en norme par~:
			\[\norm {f(t, y_2) - f(t, y_1)} \leq \int_0^1\norm {\dif_{sy_2 + (1-s)y_1}f(t, \cdot)(y_2-y_1)\dif s} \leq \int_0^1M\norm {y_2-y_1}\dif s = M\norm {y_2-y_1}.\]
			\end{proof}

			\begin{déf} Pour tout $t_0 \in \R, y_0 \in \R^d$, $\ell, r \gneqq 0$, on appelle \textit{cylindre (en espace-temps)} centré en $(t_0, y_0)$ de rayon
			$r$ et de demi-axe $\ell$ l'ensemble~:
			\[S(t_0, y_0, \ell, r) \coloneqq \left\{(t, y) \in \R \times \R^d \tq \abs {t-t_0} \leq r, \norm {y-y_0} \leq \ell\right\}.\]
			\end{déf}

			\begin{rmq} $S(t_0, y_0, \ell, r)$ est un compact convexe de $\R \times \R^d$.
			\end{rmq}

			\begin{prp} Soit $f : I \times \Omega \to \R^d$ localement lipschitzienne en espace. Soient $(t_0, y_0) \in I \times \Omega, \ell, r \gneqq 0 \tq$~:
			\[S(t_0, y_0, \ell, r) \subset I \times \Omega.\]
			Alors $f$ est localement lipschitzienne sur $S(t_0, y_0, \ell, r)$.
			\end{prp}

		\subsection{Théorème d'existence et d'unicité locales}
			\begin{prp} Soient $f : J \times \Omega \to \R^d$ localement lipschitzienne en espace, $(t_0, y_0) \in J \times \Omega$. Il existe $\ell, r \gneqq 0$
			tels que~:
			\begin{itemize}
				\item[$(i)$]  $S \coloneqq S(t_0, y_0, \ell, r) \subset J \times \Omega$~;
				\item[$(ii)$] $\ell\norm f_{\infty, S} \leq r$.
			\end{itemize}
			\end{prp}

			\begin{proof} Puisque $J \times \Omega$ est ouvert, il existe $\delta, \varepsilon \gneqq 0$ tels que
			$S(t_0, y_0, \delta, \varepsilon) \subset J \times \Omega$. Posons alors $\varepsilon \eqqcolon r$, et~:
			\[\ell \coloneqq \min\left(\delta, \frac \varepsilon{\norm f_{\infty, S(t_0, y_0, \delta, \varepsilon)}}\right).\]

			Alors $\ell > 0$, et on a donc~:
			\[\ell \leq \frac \varepsilon{\norm f_{\infty, S(t_0, y_0, \delta, \varepsilon)}} \leq \frac \varepsilon{\norm f_{\infty, S(t_0, y_0, \ell, r)}},\]
			car $\ell \leq \delta$.
			\end{proof}
\end{document}
