\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage[bottom]{footmisc}
% math packages
\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}
\usepackage{mathdots}
\usepackage{commath}
\usepackage{stmaryrd}

\usepackage{hyperref}

\makeatletter
\def\thm@space@setup{%
	\thm@preskip=.4cm%
	\thm@postskip=\thm@preskip%
}
\makeatother

  \newcommand{\N}{\mathbb N}
\renewcommand{\P}{\mathbb P}
  \newcommand{\Q}{\mathbb Q}
  \newcommand{\R}{\mathbb R}

\newcommand{\iintv}[2]{\left\llbracket#1, #2\right\rrbracket}

\DeclareMathOperator{\tq}{t.q.}
\DeclareMathOperator{\Erf}{Erf}

% amsthm
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\renewcommand{\proofname}{\it{Démonstration}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}

\author{R. Petit}
\title{MATHF-105 : Probabilités \\ Résumé}
\date{Année académique 2015 - 2016}

\begin{document}

\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}

\section{Espaces de probabilités}
	\subsection{Rappel sur les séries}
		Les fonctions logarithmique et exponentielle ont un développement de Taylor exact. Pour la fonction logarithmique, on a, pour $x \in (-1, 1)$~:
		\[\log(1-x) = -\sum_{k \geq 1}\frac {x^k}k.\]

		Si on pose $S_n \coloneqq \sum_{k = 1}^nu_k$, on a $(S_n)_{n \in \N}$, la suite des sommes partielles, et $n \mapsto S_n$, une application croissante si
		$(u_n)$ est une suite positive. Il y a donc deux situations distinctes possibles~:

		\begin{itemize}
			\item $(S_n)$ est une suite bornée ($\exists M \in \R \tq \forall n \in \N : S_n \leq M$) et donc converge vers $S \in \R$~;
			\item $(S_n)$ n'est pas bornée ($\forall M \in \R : \exists n \in \N \tq S_n > M$) et donc diverge vers $+\infty$.
		\end{itemize}

		\subsubsection{Exemple sur les séries}
		Prenons $u_n \coloneqq x^n$, avec $x > 0$.

		\begin{itemize}
			\item Si $x = 1$, on a $n \to +\infty \Rightarrow S_n \to +\infty$~;
			\item si $x \neq 1$, on a $(1-x)S_n = x-x^{n+1}$, et donc~:
			      \[S_n \coloneqq x\frac {1-x^n}{1-x}.\]

			      \begin{itemize}
			      	\item Si $x < 1$, alors $x^n \to 0$ pour $n \to +\infty$, et donc $S_n \to \frac x{1-x}$~;
					\item si $x > 1$, alors $x^n \to +\infty$ pour $n \to +\infty$, et donc $S_n \to +\infty$.
			      \end{itemize}
		\end{itemize}

		\subsubsection{Conclusion de la suite géométrique}
		On voit alors~:
		\[\sum_{n \geq 1}x^n = \begin{cases}\frac x{1-x} &\text{ si } x \in [0, 1) \\ +\infty & \text{ sinon }\end{cases}.\]

		Si la suite commene à l'indice 0, on a~:
		\[\sum_{n \geq 0}x^n = 1 + \sum_{n \geq 1}x^n = \begin{cases}1 + \frac x{1-x} = \frac 1{1-x} &\text { si } x \in [0, 1) \\ +\infty &\text{ sinon}\end{cases}.\]

	\subsection{Définition}
		\begin{déf} L'ensemble $\Omega$ est l'\textbf{espace des chances}, l'ensemble des résultats possibles d'un phénomène aléatoire. \end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item $\Omega$ peut être fini (dénombrable) ou infini~;
			\item $\Omega = \left\{0, 1\right\}^\N$ est l'ensemble des suites à valeur dans $\{0, 1\}$~;
			\item $\Omega$ peut être un espace dit \textit{fonctionnel} quand le résultat d'une expérience est une fonction.
		\end{itemize}
		\end{rmq}

		\begin{déf} Un événement $E$ est un ensemble de réalisations possibles à une expérience tel que $E \subseteq \Omega$. \end{déf}

		\begin{rmq} L'ensemble $\mathcal P(\Omega)$ n'est pas toujours dénombrable. Et donc l'ensemble $\mathcal P(\Omega)$ est-il le bon ensemble pour décrire
		les événements~?
		
		\begin{itemize}
			\item Si $\abs \Omega \in \N$~: oui~;
			\item si $\abs \Omega \not \in \N$~: non.
		\end{itemize}
		\end{rmq}

		\begin{déf} $\mathcal F$ est la \textbf{classe des événements}. On mesure la \textit{probabilité d'occurrence} d'un événement $A \in \mathcal F$.
		On introduit une fonction d'ensemble $\P$ où~:
		\[\P : \mathcal F \to [0, 1] : A \mapsto \P(A).\]

		On impose~:
		\begin{itemize}
			\item[$(i)$] $\P(\emptyset) = 0$~;
			\item[$(ii)$] $\P(\Omega) = 1$~;
			\item[$(iii)$] $\forall A, B \in \mathcal F : A \cap B = \emptyset \Rightarrow \P(A \cup B) = \P(A) + \P(B)$.
		\end{itemize}
		\end{déf}

		\begin{prp} Soient $A_1, \dotsc, A_n \in \mathcal F$. On a~:
		\[\P\left(\bigcup_{i=1}^n A_i\right) = \sum_{i=1}^n(-1)^{i-1}\sum_{1 \leq k_1 < \dotsb < k_i \leq n}\P\left(\bigcap_{\gamma=1}^iA_{k_\gamma}\right).\]
		\end{prp}

		\subsubsection{Loi uniforme sur un ensemble fini (ou dénombrable)}
		\begin{déf} Soient $m < n \in \N$. On définit l'\textbf{intervalle entier} $\iintv mn$ par~:
		\[\iintv mn : \{x \in \N \tq m \leq x \leq n\}.\] \end{déf}
		
		\begin{déf} Soit $\Omega = \iintv 1n$. Soit $A \subseteq \Omega$. La loi uniforme est donnée par~:
		\[\P(A) = \frac {\abs A}{\abs \Omega} = \frac {\abs A}n.\] \end{déf}

		\begin{rmq} Il arrive que $\abs A$ soit difficile à déterminer et qu'il faille aller chercher du côté de l'analyse combinatoire. \end{rmq}

		\subsubsection{Loi uniforme sur un ensemble infini (intervalle)}

		\begin{déf} Soit $\Omega = [0, 1]$ et soit $A = [a, b] \subseteq \Omega$. La loi uniforme est donnée par~:
		\[\P(A) = (b-a).\] \end{déf}

		\begin{rmq} La définition de loi uniforme sur un intervalle fait intervenir la notion de mesure et donc de mesurabilité. Or il existe des parties de
		$\Omega$ sur lesquelles la mesure n'a pas de sens. En général, $\mathcal P(\Omega)$ est \textit{trop grand}, et il faut donc remplacer l'utilisation
		de l'ensemble des parties par la notion de tribu. \end{rmq}

		\begin{déf} Soit $\Omega$ un ensemble de chances et $\mathcal F \subseteq \mathcal P(\Omega)$ une famille de parties de $\Omega$. On dit que
		$\mathcal F$ est une tribu s'il respecte les trois propriétés suivantes~:
		\begin{itemize}
			\item $\emptyset \in \mathcal F$~;
			\item $\forall A : A \in \mathcal F \Rightarrow A^\complement \in \mathcal F$~;
			\item $\forall A_1, \dotsc, A_n, \ldots : A_1, \dotsc, A_n, \ldots \in \mathcal F \Rightarrow \bigcup_{k \geq 1}A_k \in \mathcal F$.
		\end{itemize}

		Une autre appellation pour une tribu est une $\sigma$-algèbre.
		\end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item On remarque que $\mathcal P(\Omega)$ est une tribu, mais une tribu trop grande pour être intéressante~;
			\item Soit $A \in \mathcal P(\Omega)$. Alors $T \coloneqq \{\emptyset, A, A^\complement, \mathcal P(\Omega)\}$ est une tribu.
			      $T$ est la plus petite tribu contenant $A$, et on l'appelle la \textbf{tribu engendrée par $A$}, que l'on note $\sigma(A)$.
		\end{itemize}
		\end{rmq}

		\begin{déf} Soit $I$ une partie de $\mathcal P(\Omega)$. On appelle la \textit{tribu engendrée par $I$} la plus petite tribu contenant $I$ et on la
		note $\sigma(I)$.
		
		En prenant $I \coloneqq \{$ intervalles ouverts de $[0, 1]\}$, on obtient $\sigma(I)$ que l'on appelle \textbf{tribu des boréliens}.
		\footnote{Le nom de \textit{borélien} vient du mathématicien français Émile Borel suite à ses travaux sur la théorie de la mesure.} \end{déf}

		\begin{déf} Soit $\Omega$ un ensemble de chances et $\mathcal F \subset \mathcal P(\Omega)$ une tribu sur $\Omega$. Une probabilité sur
		$(\Omega, \mathcal F)$ est une fonction $\P$ définie par~:
		\[\P : \mathcal F \to [0, 1] : A \mapsto \P(A),\]
		où $\P$ satisfait~:

		\begin{itemize}
			\item[$(i)$] $\P(\emptyset) = 0$~;
			\item[$(ii)$] $\forall A \in \mathcal F : \P(aA) + \P(A^\complement) = 1$~;
			\item[$(iii)$] $\forall A_1, \dotsc, A_n, \ldots$ disjoints deux à deux, on a~:
			               \[\P\left(\bigcup_{k \geq 1}A_k\right) = \sum_{k \geq 1}\P(A_k).\]
		\end{itemize}
		\end{déf}

		\begin{déf} On appelle $(\Omega, \mathcal F, \P)$ un espace de probabilités. \end{déf}

		\begin{rmq} Probabiliser un expérience revient à déterminer~:
		\begin{itemize}
			\item $\Omega$, l'espace des chances~;
			\item $\mathcal F$, la classe des événements~;
			\item $\P$, la fonction d'ensembles sur $\mathcal F$.
		\end{itemize}
		\end{rmq}
	
	\subsection{Modèles}
		\subsubsection{Modèles discrets}
		\begin{rmq} On prend $\Omega$ un ensemble fini ou dénombrable. On prend également $\mathcal F = \mathcal P(\Omega)$.

		Si $\Omega$ est fini, on parle de tirages, et si $\Omega$ est infini dénombrable, on parle de populations.

		On pose~:
		\[\P : \{k\} \mapsto p_k \in [0, 1],\]
		où~:
		\[\sum_{k \in \Omega}p_k = 1\]
		et pour $A = \{k_1, \dotsc, k_n\} \in \mathcal F$~:
		\[\P(A) = \sum_{\gamma=1}^np_{k_\gamma}.\]
		\end{rmq}

		\begin{déf}[Modèle de Bernoulli] On prend $\Omega = \{0, 1\}$ où~:
		\[\begin{cases}p_0 &= 1-p \\p_1 &= p\end{cases}.\] \end{déf}

		\begin{rmq} Il est évident que $p + (1-p) = 1 = P(\Omega)$. \end{rmq}

		\begin{déf}[Modèle binomial] On prend $\Omega = \iintv 0N$ (et donc $\mathcal F = \mathcal P(\Omega)$) et $p \in [0, 1]$.
		Le modèle binomial est défini par $p_k = \binom nkp^k(1-p)^{N-k}$ pour tout $k \in \iintv 0N$. \end{déf}

		\begin{rmq} On remarque que $\sum_{k \geq 1}p_k = 1$ car les $p_k$ représentent les termes du binôme de Newton $(p + (1-p))^N = 1^N = 1$. \end{rmq}

		\begin{déf}[Modèle géométrique] On prend $\Omega = \N$, $\mathcal F = \mathcal F(\Omega) \simeq \R$, et $p \in (0, 1)$. Le modèle géométrique
		est défini par $p_k = (1-p)^{k-1}p$ pour tout $k \in \N$. \end{déf}

		\begin{rmq} On remarque que~:
		\[\sum_{k \geq 1}p_k = \sum_{k \geq 1}p(1-p)^{k-1} = p\sum_{k \geq 0}(1-p)^k = p\frac 1{1-(1-p)} = \frac pp = 1,\]
		où on utilise la formule de la somme des termes d'une suite géométrique $u$ définie par $u_n = u_{n-1}q$ pour $n \geq 1$ (avec $0 < q < 1$) qui donne~:
		\[\sum_{k=0}^Nu_k = u_0\frac {1 - q^{N+1}}{1-q},\]
		et pour la série, il suffit de passer à la limite~:
		\[\lim_{N \to +\infty}\sum_{k=0}^Nu_k = \lim_{N \to +\infty}u_0\frac {1 - q^{N+1}}{1-q} = u_0\frac 1{1-q}.\]
		\end{rmq}

		\begin{déf}[Modèle de Poisson] On prend $\Omega  =\N$, $\mathcal F = \mathcal P(\Omega)$, et un paramètre $\lambda \in \R_0^+$.
		Le modèle poissonien est défini par $p_k = \exp(-\lambda)\frac {\lambda^k}{k!}$ pour tout $k \in \N$. \end{déf}

		\begin{rmq} On remarque que $\P(\Omega) = 1$ en utilisant la formule de Taylor de l'exponentielle~:
		\[\exp(x) = \sum_{k \geq 0}\frac {x^k}{k!}.\]

		On a effectivement~:
		\[\P(\Omega) = \sum_{k \geq 0}\P(\{k\}) = \sum_{k \geq 0}p_k = \sum_{k \geq 0}\exp(-\lambda)\frac {\lambda^k}{k!} = \exp(-\lambda)\exp(\lambda) = 1.\]
		\end{rmq}

		\subsubsection{Modèles continus (à densité)}
		\begin{rmq} On prend $\Omega$ un intervalle (fini ou infini\footnote{On parle d'intervalle fini pour $[a, b]$, avec $a < b \in \R$ et d'intervalle
		semi-infini pour $(-\infty, b]$ ou $[a, +\infty)$ et d'intervalle infini pour $(-\infty, +\infty) = \R$.}) sur $\R$, et $\mathcal F = \mathcal B(I)$,
		la tribu des boréliens sur $I$\footnote{Ou encore la tribu engendrée par les intervalles de $I$.}. \end{rmq}

		\begin{déf} Soit $f : I \to \R^+$ une fonction intégrable telle que $\int_\R f(x)\dif x = 1$. Soit $A \in \mathcal F$, on pose
		$\P(A) = \int_Af(x)\dif x$. $f$ est appelée fonction de densité de modèle stochastique. \end{déf}

		\begin{déf}[Loi uniforme continue] On prend $I = [a, b]$ avec $a < b \i \R$. Le modèle uniforme est défini par $f$ constante~:
		\[f(x) = \begin{cases}0 &\text{ si }x \not \in [a, b] \\\frac 1{b-a} &\text{ si }x \in [a, b]\end{cases}.\] \end{déf}

		\begin{rmq} On remarque effectivement $\int_\R f(x)\dif x = 1$~:
		\[\int_\R f(x)\dif x = \int_{-\infty}^a f(x)\dif x + \int_a^b f(x)\dif x + \int_b^{+\infty} f(x)\dif x = 0 + \frac 1{b-a}\int_a^b\dif x + 0 = 1.\]
		\end{rmq}

		\begin{déf}[Modèle exponentiel]\footnote{Également appelé \textit{modèle des files d'attente}.}\label{modèleExponentiel} On prend $I = \R^+$ et
		$\lambda > 0$. Le modèle exponentiel est défini par~:
		\[f(x) = \begin{cases}\lambda\exp(-\lambda x) &\text{ si }x \geq 0 \\ 0 &\text{ sinon}\end{cases}.\]
		\end{déf}

		\begin{rmq} On peut calculer l'intégrale impropre comme suit~:
		\[\begin{aligned}
			\int_\R f(x)\dif x &= \int_{-\infty}^0f(x)\dif x + \int_0^{+\infty}f(x)\dif x = 0 + \lim_{M \to +\infty}\int_0^Mf(x)\dif x \\
			&= \lim_{M \to +\infty}\left[-\exp(-\lambda x)\right]_0^M = \lim_{M \to +\infty}\left(1 - \exp(-\lambda M)\right) = 1.
		\end{aligned}\]
		\end{rmq}

		\begin{déf}[Modèle gaussien]\footnote{Également appelé \textit{modèle des erreurs} ou encore \textit{modèle normal}.} On prend $I = \R$, et
		$(\mu, \sigma) \in \R \times \R^+_0$. Le modèle gaussien est défini par~:
		\[f(x) = \frac 1{\sigma\sqrt{2\pi}}\exp\left(-\frac {(x-\mu)^2}{2\sigma^2}\right).\]
		\end{déf}

		\begin{rmq} Pour que $\P$ soit une probabilité, il faut que $f$ soit définie positive. Or $f$ est une exponentielle multipliée par un coefficient
		positif. Il faut également $\int_\R f(x)\dif x = 1$, ce qui peut se vérifier par~:
		\[\int_\R f(x)\dif x,\]
		en posant $y \coloneqq x-\mu$, et donc $\dif y = \dif x$~:
		\[\int_\R \frac 1{\sigma \sqrt{2\pi}}\exp\left(-\frac {y^2}{2\sigma^2}\right) = \frac 1{\sigma\sqrt{2\pi}}\int_\R\exp\left(-\frac {y^2}{2\sigma^2}\right).\]
		En posant $z \coloneqq \frac y\sigma$ (et donc $\dif z = \frac {\dif x}\sigma$), on obtient~:
		\[\int_\R f(x)\dif x = \frac 1{\sqrt{2\pi}}\int_\R\exp\left(-\frac {z^2}2\right)\dif z.\]

		Une primitive de $\exp\left(-\frac {z^2}2\right)$ est~:
		\[\int_{-\infty}^z\exp\left(-\frac {x^2}2\right)\frac {\dif x}{\sqrt{2\pi}} = \Erf(z).\]

		On écrit alors~:
		\[\begin{aligned}
			\P(\Omega)^2 &= \left(\int_\R\exp\left(-\frac {x^2}2\right)\frac {\dif x}{\sqrt{2\pi}}\right)
			                \left(\int_\R\exp\left(-\frac {y^2}2\right)\frac {\dif y}{\sqrt{2\pi}}\right) \\
			             &= \iint_{\R^2}\exp\left(-\frac {x^2+y^2}2\right)\frac {\dif x\dif y}{2\pi}.
		\end{aligned}\]
		
		En passant en coordonnées polaires, on obtient~:
		\[\P(\Omega)^2 = \int_{-\pi}^{+\pi}\int_\R\exp\left(-\frac {r^2}2\right)\frac {r\dif r\dif \theta}{2\pi}
		= \int_{-\pi}^{+\pi}\frac {\dif \theta}{2\pi}\int_\R r\exp\left(-\frac {r^2}2\right)\dif r
		= \left[-\exp\left(-\frac {r^2}2\right)\right]_0^{+\infty} = 1.\]

		On en déduit alors $\P(\Omega) = 1$ également. $\P$ est donc bien une probabilité. \end{rmq}
		
		\begin{déf} On a défini une probabilité sur $\left(R^+, \mathcal(R^+)\right)$ via la fonction $f(r) = r\exp\left(-\frac {r^2}2\right)$.
		On l'appelle la \textit{probabilité de Rayleigh}. \end{déf}

		\subsubsection{Divergence sur la fonction Gamma d'Euler}

		\begin{déf}[Fonction Gamma d'Euler] La fonction Gamma d'Euler est définie comme suit~:
		\[\Gamma : \R_0^+ \to \R : x \mapsto \int_0^{+\infty}\exp(-x)x^{t-1}\dif x.\] \end{déf}
		
		\begin{rmq} On note $\gamma \coloneqq -\Gamma'(1) > 0$ la constante d'Euler-Mascheroni. La question $\gamma \stackrel{?}{\in} \Q$ est toujours ouverte.
		\end{rmq}

		\begin{prp}\label{GammaRecursif} $\forall t > 0 : \Gamma(t+1) = t\Gamma(t)$. \end{prp}

		\begin{proof} Soit $t > 0$. Par l'intégration par parties, on a~:
		\[\Gamma(t+1) = \int_0^{+\infty}\exp(-x)x^{t}\dif x = \left[-x^t\exp(-x)\right]_0^{+\infty} + t\int_0^{+\infty}\exp(-x)x^{t-1}\dif x = t\Gamma(t).\]
		\end{proof}

		\begin{rmq} Par la proposition~\ref{GammaRecursif}, on peut définir la factorielle de tout nombre naturel par~:
		\[\forall n \in \N^* : n! = \Gamma(n+1)\]
		\end{rmq}

		\begin{prp}[Formule des compléments] Soit $t \in (0, 1)$. Alors~:
		\[\Gamma(t)\Gamma(1-t) = \frac \pi{\sin(\pi t)}.\]
		\end{prp}

		\subsubsection{Retour aux modèles stochastiques}

		\begin{déf}[Modèle Gamma]\footnote{Le modèle $\Gamma$ est une généralisation du modèle exponentiel (définition~\ref{modèleExponentiel}).}
		On prend $\Omega = \R^+$. Le modèle Gamma est défini par~:
		\[f_t(x) \frac {x^t-\exp(-x)}{\Gamma(t)}.\]
		\end{déf}

	\subsection{Notion de variables aléatoires}

\end{document}
