\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage[bottom]{footmisc}
% math packages
\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}
\usepackage{mathdots}
\usepackage{commath}
\usepackage{stmaryrd}

\usepackage{hyperref}

\makeatletter
\def\thm@space@setup{%
	\thm@preskip=.4cm%
	\thm@postskip=\thm@preskip%
}
\makeatother

  \newcommand{\E}{\mathbb E}
  \newcommand{\N}{\mathbb N}
\renewcommand{\P}{\mathbb P}
  \newcommand{\Q}{\mathbb Q}
  \newcommand{\R}{\mathbb R}
  \newcommand{\Z}{\mathbb Z}

\newcommand{\Nms}{\mathcal N(\mu, \sigma^2)}
\newcommand{\Nzu}{\mathcal N(0, 1)}
\newcommand{\convl}{\stackrel{\mathcal D}\to}
\newcommand{\espproba}[3]{\left(#1, #2, #3\right)}
\newcommand{\Ofp}{\espproba \Omega{\mathcal F}\P}
\newcommand{\ofp}{\Ofp}

\newcommand{\iintv}[2]{\left\llbracket#1, #2\right\rrbracket}

\DeclareMathOperator{\tq}{t.q.}
\DeclareMathOperator{\Erf}{Erf}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\Bale}{\textup{Bâle}}

% amsthm
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\renewcommand{\proofname}{\it{Démonstration}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}

\author{R. Petit}
\title{MATHF-105 : Probabilités \\ Résumé}
\date{Année académique 2015 - 2016}

\begin{document}

\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}

\section{Rappels}
	\subsection{Rappel sur les séries}
		Les fonctions logarithmique et exponentielle ont un développement de Taylor exact. Pour la fonction logarithmique, on a, pour $x \in (-1, 1)$~:
		\[\log(1-x) = -\sum_{k \geq 1}\frac {x^k}k.\]

		Si on pose $S_n \coloneqq \sum_{k = 1}^nu_k$, on a $(S_n)_{n \in \N}$, la suite des sommes partielles, et $n \mapsto S_n$, une application croissante si
		$(u_n)$ est une suite positive. Il y a donc deux situations distinctes possibles~:

		\begin{itemize}
			\item $(S_n)$ est une suite bornée ($\exists M \in \R \tq \forall n \in \N : S_n \leq M$) et donc converge vers $S \in \R$~;
			\item $(S_n)$ n'est pas bornée ($\forall M \in \R : \exists n \in \N \tq S_n > M$) et donc diverge vers $+\infty$.
		\end{itemize}

		\subsubsection{Exemple sur les séries}
		Prenons $u_n \coloneqq x^n$, avec $x > 0$.

		\begin{itemize}
			\item Si $x = 1$, on a $n \to +\infty \Rightarrow S_n \to +\infty$~;
			\item si $x \neq 1$, on a $(1-x)S_n = x-x^{n+1}$, et donc~:
			      \[S_n \coloneqq x\frac {1-x^n}{1-x}.\]

			      \begin{itemize}
			      	\item Si $x < 1$, alors $x^n \to 0$ pour $n \to +\infty$, et donc $S_n \to \frac x{1-x}$~;
					\item si $x > 1$, alors $x^n \to +\infty$ pour $n \to +\infty$, et donc $S_n \to +\infty$.
			      \end{itemize}
		\end{itemize}

		\subsubsection{Conclusion de la suite géométrique}
		On voit alors~:
		\[\sum_{n \geq 1}x^n = \begin{cases}\frac x{1-x} &\text{ si } x \in [0, 1) \\ +\infty & \text{ sinon }\end{cases}.\]

		Si la suite commence à l'indice 0, on a~:
		\[\sum_{n \geq 0}x^n = 1 + \sum_{n \geq 1}x^n = \begin{cases}1 + \frac x{1-x} = \frac 1{1-x} &\text { si } x \in [0, 1) \\ +\infty &\text{ sinon}\end{cases}.\]
	
	\subsection{Rappels d'analyse}
		\begin{déf} Une fonction $f : X \to Y$ est dite mesurable si~:
		\[\forall A \subset \mathcal B(Y) : \{\omega \in \Omega \tq X(\omega) \in A\} \in \mathcal F,\]
		où $\mathcal B(Y)$ représente la tribu des boréliens (voir définition~\ref{boréliens}). \end{déf}

		\begin{thm}\label{convabssérie} Dans $\R$, toute série absolument convergente est convergente. \end{thm}
		
		\begin{thm}\label{convabsintégrale} Dans $\R$, toute intégrale impropre absolument convergente est convergente. \end{thm}

\section{Espaces de probabilités}
	\subsection{Définition}
		\begin{déf} L'ensemble $\Omega$ est l'\textbf{espace des chances}, l'ensemble des résultats possibles d'un phénomène aléatoire. \end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item $\Omega$ peut être fini (dénombrable) ou infini~;
			\item $\Omega = \left\{0, 1\right\}^\N$ est l'ensemble des suites à valeur dans $\{0, 1\}$~;
			\item $\Omega$ peut être un espace dit \textit{fonctionnel} quand le résultat d'une expérience est une fonction.
		\end{itemize}
		\end{rmq}

		\begin{déf} Un événement $E$ est un ensemble de réalisations possibles à une expérience tel que $E \subseteq \Omega$. \end{déf}

		\begin{rmq} L'ensemble $\mathcal P(\Omega)$ n'est pas toujours dénombrable. Et donc l'ensemble $\mathcal P(\Omega)$ est-il le bon ensemble pour décrire
		les événements~?
		
		\begin{itemize}
			\item Si $\abs \Omega \in \N$~: oui~;
			\item si $\abs \Omega \not \in \N$~: non.
		\end{itemize}
		\end{rmq}

		\begin{déf} $\mathcal F$ est la \textbf{classe des événements}. On mesure la \textit{probabilité d'occurrence} d'un événement $A \in \mathcal F$.
		On introduit une fonction d'ensemble $\P$ où~:
		\[\P : \mathcal F \to [0, 1] : A \mapsto \P(A).\]

		On impose~:
		\begin{itemize}
			\item[$(i)$] $\P(\emptyset) = 0$~;
			\item[$(ii)$] $\P(\Omega) = 1$~;
			\item[$(iii)$] $\forall A, B \in \mathcal F : A \cap B = \emptyset \Rightarrow \P(A \cup B) = \P(A) + \P(B)$.
		\end{itemize}
		\end{déf}

		\begin{prp} Soient $A_1, \dotsc, A_n \in \mathcal F$. On a~:
		\[\P\left(\bigcup_{i=1}^n A_i\right) = \sum_{i=1}^n(-1)^{i-1}\sum_{1 \leq k_1 < \dotsb < k_i \leq n}\P\left(\bigcap_{\gamma=1}^iA_{k_\gamma}\right).\]
		\end{prp}

		\subsubsection{Loi uniforme sur un ensemble fini (ou dénombrable)}
		\begin{déf} Soient $m < n \in \N$. On définit l'\textbf{intervalle entier} $\iintv mn$ par~:
		\[\iintv mn : \{x \in \N \tq m \leq x \leq n\}.\] \end{déf}
		
		\begin{déf} Soit $\Omega = \iintv 1n$. Soit $A \subseteq \Omega$. La loi uniforme est donnée par~:
		\[\P(A) = \frac {\abs A}{\abs \Omega} = \frac {\abs A}n.\] \end{déf}

		\begin{rmq} Il arrive que $\abs A$ soit difficile à déterminer et qu'il faille aller chercher du côté de l'analyse combinatoire. \end{rmq}

		\subsubsection{Loi uniforme sur un ensemble infini (intervalle)}

		\begin{déf} Soit $\Omega = [0, 1]$ et soit $A = [a, b] \subseteq \Omega$. La loi uniforme est donnée par~:
		\[\P(A) = (b-a).\] \end{déf}

		\begin{rmq} La définition de loi uniforme sur un intervalle fait intervenir la notion de mesure et donc de mesurabilité. Or il existe des parties de
		$\Omega$ sur lesquelles la mesure n'a pas de sens. En général, $\mathcal P(\Omega)$ est \textit{trop grand}, et il faut donc remplacer l'utilisation
		de l'ensemble des parties par la notion de tribu. \end{rmq}

		\begin{déf} Soit $\Omega$ un ensemble de chances et $\mathcal F \subseteq \mathcal P(\Omega)$ une famille de parties de $\Omega$. On dit que
		$\mathcal F$ est une tribu s'il respecte les trois propriétés suivantes~:
		\begin{itemize}
			\item $\emptyset \in \mathcal F$~;
			\item $\forall A : A \in \mathcal F \Rightarrow A^\complement \in \mathcal F$~;
			\item $\forall A_1, \dotsc, A_n, \ldots : A_1, \dotsc, A_n, \ldots \in \mathcal F \Rightarrow \bigcup_{k \geq 1}A_k \in \mathcal F$.
		\end{itemize}

		Une autre appellation pour une tribu est une $\sigma$-algèbre.
		\end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item On remarque que $\mathcal P(\Omega)$ est une tribu, mais une tribu trop grande pour être intéressante~;
			\item Soit $A \in \mathcal P(\Omega)$. Alors $T \coloneqq \{\emptyset, A, A^\complement, \mathcal P(\Omega)\}$ est une tribu.
			      $T$ est la plus petite tribu contenant $A$, et on l'appelle la \textbf{tribu engendrée par $A$}, que l'on note $\sigma(A)$.
		\end{itemize}
		\end{rmq}

		\begin{déf}\label{boréliens} Soit $I$ une partie de $\mathcal P(\Omega)$. On appelle la \textit{tribu engendrée par $I$} la plus petite tribu contenant
		$I$ et on la note $\sigma(I)$.
		
		En prenant $I \coloneqq \{$ intervalles ouverts de $[0, 1]\}$, on obtient $\sigma(I)$ que l'on appelle \textbf{tribu des boréliens}.
		\footnote{Le nom de \textit{borélien} vient du mathématicien français Émile Borel suite à ses travaux sur la théorie de la mesure.} \end{déf}

		\begin{déf} Soit $\Omega$ un ensemble de chances et $\mathcal F \subset \mathcal P(\Omega)$ une tribu sur $\Omega$. Une probabilité sur
		$\Ofp$ est une fonction $\P$ définie par~:
		\[\P : \mathcal F \to [0, 1] : A \mapsto \P(A),\]
		où $\P$ satisfait~:

		\begin{itemize}
			\item[$(i)$] $\P(\emptyset) = 0$~;
			\item[$(ii)$] $\forall A \in \mathcal F : \P(aA) + \P(A^\complement) = 1$~;
			\item[$(iii)$] $\forall A_1, \dotsc, A_n, \ldots$ disjoints deux à deux, on a~:
			               \[\P\left(\bigcup_{k \geq 1}A_k\right) = \sum_{k \geq 1}\P(A_k).\]
		\end{itemize}
		\end{déf}

		\begin{déf} On appelle $\Ofp$ un espace de probabilités. \end{déf}

		\begin{rmq} Probabiliser un expérience revient à déterminer~:
		\begin{itemize}
			\item $\Omega$, l'espace des chances~;
			\item $\mathcal F$, la classe des événements~;
			\item $\P$, la fonction d'ensembles sur $\mathcal F$.
		\end{itemize}
		\end{rmq}
	
	\subsection{Modèles}
		\subsubsection{Modèles discrets}
		\begin{rmq} On prend $\Omega$ un ensemble fini ou dénombrable. On prend également $\mathcal F = \mathcal P(\Omega)$.

		Si $\Omega$ est fini, on parle de tirages, et si $\Omega$ est infini dénombrable, on parle de populations.

		On pose~:
		\[\P : \{k\} \mapsto p_k \in [0, 1],\]
		où~:
		\[\sum_{k \in \Omega}p_k = 1\]
		et pour $A = \{k_1, \dotsc, k_n\} \in \mathcal F$~:
		\[\P(A) = \sum_{\gamma=1}^np_{k_\gamma}.\]
		\end{rmq}

		\begin{déf}[Modèle de Bernoulli] On prend $\Omega = \{0, 1\}$ où~:
		\[\begin{cases}p_0 &= 1-p \\p_1 &= p\end{cases}.\] \end{déf}

		\begin{rmq} Il est évident que $p + (1-p) = 1 = P(\Omega)$. \end{rmq}

		\begin{déf}[Modèle binomial] On prend $\Omega = \iintv 0N$ (et donc $\mathcal F = \mathcal P(\Omega)$) et $p \in [0, 1]$.
		Le modèle binomial est défini par $p_k = \binom nkp^k(1-p)^{N-k}$ pour tout $k \in \iintv 0N$. \end{déf}

		\begin{rmq} On remarque que $\sum_{k \geq 1}p_k = 1$ car les $p_k$ représentent les termes du binôme de Newton $(p + (1-p))^N = 1^N = 1$. \end{rmq}

		\begin{déf}[Modèle géométrique] On prend $\Omega = \N$, $\mathcal F = \mathcal F(\Omega) \simeq \R$, et $p \in (0, 1)$. Le modèle géométrique
		est défini par $p_k = (1-p)^{k-1}p$ pour tout $k \in \N$. \end{déf}

		\begin{rmq} On remarque que~:
		\[\sum_{k \geq 1}p_k = \sum_{k \geq 1}p(1-p)^{k-1} = p\sum_{k \geq 0}(1-p)^k = p\frac 1{1-(1-p)} = \frac pp = 1,\]
		où on utilise la formule de la somme des termes d'une suite géométrique $u$ définie par $u_n = u_{n-1}q$ pour $n \geq 1$ (avec $0 < q < 1$) qui donne~:
		\[\sum_{k=0}^Nu_k = u_0\frac {1 - q^{N+1}}{1-q},\]
		et pour la série, il suffit de passer à la limite~:
		\[\lim_{N \to +\infty}\sum_{k=0}^Nu_k = \lim_{N \to +\infty}u_0\frac {1 - q^{N+1}}{1-q} = u_0\frac 1{1-q}.\]
		\end{rmq}

		\begin{déf}[Modèle de Poisson] On prend $\Omega  =\N$, $\mathcal F = \mathcal P(\Omega)$, et un paramètre $\lambda \in \R_0^+$.
		Le modèle poissonien est défini par $p_k = \exp(-\lambda)\frac {\lambda^k}{k!}$ pour tout $k \in \N$. \end{déf}

		\begin{rmq} On remarque que $\P(\Omega) = 1$ en utilisant la formule de Taylor de l'exponentielle~:
		\[\exp(x) = \sum_{k \geq 0}\frac {x^k}{k!}.\]

		On a effectivement~:
		\[\P(\Omega) = \sum_{k \geq 0}\P(\{k\}) = \sum_{k \geq 0}p_k = \sum_{k \geq 0}\exp(-\lambda)\frac {\lambda^k}{k!} = \exp(-\lambda)\exp(\lambda) = 1.\]
		\end{rmq}

		\subsubsection{Modèles continus (à densité)}
		\begin{rmq} On prend $\Omega$ un intervalle (fini ou infini\footnote{On parle d'intervalle fini pour $[a, b]$, avec $a < b \in \R$ et d'intervalle
		semi-infini pour $(-\infty, b]$ ou $[a, +\infty)$ et d'intervalle infini pour $(-\infty, +\infty) = \R$.}) sur $\R$, et $\mathcal F = \mathcal B(I)$,
		la tribu des boréliens sur $I$\footnote{Ou encore la tribu engendrée par les intervalles de $I$.}. \end{rmq}

		\begin{déf} Soit $f : I \to \R^+$ une fonction intégrable telle que $\int_\R f(x)\dif x = 1$. Soit $A \in \mathcal F$, on pose
		$\P(A) = \int_Af(x)\dif x$. $f$ est appelée fonction de densité de modèle stochastique. \end{déf}

		\begin{déf}[Loi uniforme continue] On prend $I = [a, b]$ avec $a < b \i \R$. Le modèle uniforme est défini par $f$ constante~:
		\[f(x) = \begin{cases}0 &\text{ si }x \not \in [a, b] \\\frac 1{b-a} &\text{ si }x \in [a, b]\end{cases}.\] \end{déf}

		\begin{rmq} On remarque effectivement $\int_\R f(x)\dif x = 1$~:
		\[\int_\R f(x)\dif x = \int_{-\infty}^a f(x)\dif x + \int_a^b f(x)\dif x + \int_b^{+\infty} f(x)\dif x = 0 + \frac 1{b-a}\int_a^b\dif x + 0 = 1.\]
		\end{rmq}

		\begin{déf}[Modèle exponentiel]\footnote{Également appelé \textit{modèle des files d'attente}.}\label{modèleExponentiel} On prend $I = \R^+$ et
		$\lambda > 0$. Le modèle exponentiel est défini par~:
		\[f(x) = \begin{cases}\lambda\exp(-\lambda x) &\text{ si }x \geq 0 \\ 0 &\text{ sinon}\end{cases}.\]
		\end{déf}

		\begin{rmq} On peut calculer l'intégrale impropre comme suit~:
		\[\begin{aligned}
			\int_\R f(x)\dif x &= \int_{-\infty}^0f(x)\dif x + \int_0^{+\infty}f(x)\dif x = 0 + \lim_{M \to +\infty}\int_0^Mf(x)\dif x \\
			&= \lim_{M \to +\infty}\left[-\exp(-\lambda x)\right]_0^M = \lim_{M \to +\infty}\left(1 - \exp(-\lambda M)\right) = 1.
		\end{aligned}\]
		\end{rmq}

		\begin{déf}[Modèle gaussien]\footnote{Également appelé \textit{modèle des erreurs} ou encore \textit{modèle normal}.} On prend $I = \R$, et
		$(\mu, \sigma) \in \R \times \R^+_0$. Le modèle gaussien est défini par~:
		\[f(x) = \frac 1{\sigma\sqrt{2\pi}}\exp\left(-\frac {(x-\mu)^2}{2\sigma^2}\right).\]
		\end{déf}

		\begin{rmq} Pour que $\P$ soit une probabilité, il faut que $f$ soit définie positive. Or $f$ est une exponentielle multipliée par un coefficient
		positif. Il faut également $\int_\R f(x)\dif x = 1$, ce qui peut se vérifier par~:
		\[\int_\R f(x)\dif x,\]
		en posant $y \coloneqq x-\mu$, et donc $\dif y = \dif x$~:
		\[\int_\R \frac 1{\sigma \sqrt{2\pi}}\exp\left(-\frac {y^2}{2\sigma^2}\right) = \frac 1{\sigma\sqrt{2\pi}}\int_\R\exp\left(-\frac {y^2}{2\sigma^2}\right).\]
		En posant $z \coloneqq \frac y\sigma$ (et donc $\dif z = \frac {\dif x}\sigma$), on obtient~:
		\[\int_\R f(x)\dif x = \frac 1{\sqrt{2\pi}}\int_\R\exp\left(-\frac {z^2}2\right)\dif z.\]

		Une primitive de $\exp\left(-\frac {z^2}2\right)$ est~:
		\[\int_{-\infty}^z\exp\left(-\frac {x^2}2\right)\frac {\dif x}{\sqrt{2\pi}} = \Erf(z).\]

		On écrit alors~:
		\[\begin{aligned}
			\P(\Omega)^2 &= \left(\int_\R\exp\left(-\frac {x^2}2\right)\frac {\dif x}{\sqrt{2\pi}}\right)
			                \left(\int_\R\exp\left(-\frac {y^2}2\right)\frac {\dif y}{\sqrt{2\pi}}\right) \\
			             &= \iint_{\R^2}\exp\left(-\frac {x^2+y^2}2\right)\frac {\dif x\dif y}{2\pi}.
		\end{aligned}\]
		
		En passant en coordonnées polaires, on obtient~:
		\[\P(\Omega)^2 = \int_{-\pi}^{+\pi}\int_\R\exp\left(-\frac {r^2}2\right)\frac {r\dif r\dif \theta}{2\pi}
		= \int_{-\pi}^{+\pi}\frac {\dif \theta}{2\pi}\int_\R r\exp\left(-\frac {r^2}2\right)\dif r
		= \left[-\exp\left(-\frac {r^2}2\right)\right]_0^{+\infty} = 1.\]

		On en déduit alors $\P(\Omega) = 1$ également. $\P$ est donc bien une probabilité. \end{rmq}
		
		\begin{déf} On a défini une probabilité sur $\left(R^+, \mathcal(R^+)\right)$ via la fonction $f(r) = r\exp\left(-\frac {r^2}2\right)$.
		On l'appelle la \textit{probabilité de Rayleigh}. \end{déf}

		\subsubsection{Divergence sur la fonction Gamma d'Euler}

		\begin{déf}[Fonction Gamma d'Euler] La fonction Gamma d'Euler est définie comme suit~:
		\[\Gamma : \R_0^+ \to \R : x \mapsto \int_0^{+\infty}\exp(-x)x^{t-1}\dif x.\] \end{déf}
		
		\begin{rmq} On note $\gamma \coloneqq -\Gamma'(1) > 0$ la constante d'Euler-Mascheroni. La question $\gamma \stackrel{?}{\in} \Q$ est toujours ouverte.
		\end{rmq}

		\begin{prp}\label{GammaRecursif} $\forall t > 0 : \Gamma(t+1) = t\Gamma(t)$. \end{prp}

		\begin{proof} Soit $t > 0$. Par l'intégration par parties, on a~:
		\[\Gamma(t+1) = \int_0^{+\infty}\exp(-x)x^{t}\dif x = \left[-x^t\exp(-x)\right]_0^{+\infty} + t\int_0^{+\infty}\exp(-x)x^{t-1}\dif x = t\Gamma(t).\]
		\end{proof}

		\begin{rmq} Par la proposition~\ref{GammaRecursif}, on peut définir la factorielle de tout nombre naturel par~:
		\[\forall n \in \N^* : n! = \Gamma(n+1)\]
		\end{rmq}

		\begin{prp}[Formule des compléments] Soit $t \in (0, 1)$. Alors~:
		\[\Gamma(t)\Gamma(1-t) = \frac \pi{\sin(\pi t)}.\]
		\end{prp}

		\subsubsection{Retour aux modèles stochastiques}

		\begin{déf}[Modèle Gamma]\footnote{Le modèle $\Gamma$ est une généralisation du modèle exponentiel (définition~\ref{modèleExponentiel}).}
		On prend $\Omega = \R^+$. Le modèle Gamma est défini par~:
		\[f_t(x) \frac {x^t-\exp(-x)}{\Gamma(t)}.\]
		\end{déf}

	\subsection{Notion de variables aléatoires}
		\subsubsection{Cas discret}

		\begin{déf} Soit $\Ofp$ un espace de probabilité. Une variable aléatoire discrète\footnote{Souvent écrite v.a.d. ou V.A.-D.} est une application
		$X : \Omega \to E$ où $E$ est un ensemble fini ou infini dénombrable. On demande à cette application d'être mesurable. \end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item Bien souvent, on a $E = \Omega$, et $X(\omega) = \omega$. Dans ce cas, on \textit{identifie} l'espace des chances avec l'espace d'arrivée.
			      La probabilité $\P$ s'appelle alors la \textbf{loi} de la variable aléatoire $X$.
			\item Il arrive parfois que l'espace de probabilités soit plus gros que l'espace d'état.
		\end{itemize}
		\end{rmq}

		\begin{déf} Plus formellement, la \textbf{loi} d'une v.a.d. $X$ est l'ensemble~:
		\[\{\P(X = x) \tq x \in E\}.\]
		\end{déf}

		\begin{déf} Pour toute valeur $k \in E$ que peut prendre la variable aléatoire $X$, on note $\P(X = k)$ la probabilité que la variable $X$ prenne la
		valeur $k$. C'est équivalent à $\P\left(X(\omega) = k\right)$ pour $\omega \in \Omega$. \end{déf}

		\begin{déf} Lorsqu'une v.a.d. $X$ suit une certaine loi $\mathcal L$, on note $X \sim \mathcal L$.
		
		Par exemple, une variable $Y$ suivant une poisson de paramètre $\lambda$ se note $Y \sim \mathcal P(\lambda)$. \end{déf}
	
		\subsubsection{Cas absolument continu}

		\begin{déf} Soit $\Ofp$ un espace de probabilité. Une variable aléatoire absolument continue\footnote{Souvent écrite v.a.c. ou V.A.-C.} est une
		application $X : \Omega \to \R$ mesurable au sens où~:
		\[\forall A \in \mathcal B(\R) : \{\omega \in \Omega \tq X(\omega) \in A\} \in \mathcal F,\]
		et \textit{absolument continue} au sens où~:
		\[\exists f_X : \R \to \R^+\]
		mesurable et telle que~:
		\[\int_\R f_X(x)\dif x = 1,\]
		avec~:
		\begin{equation}\label{eq:loivad}
			\P(X \in A) = \int_A f_X(x)\dif x.
		\end{equation}
		\end{déf}

		\begin{déf} On appelle $f_X$ la \textbf{densité} de $X$. \end{déf}

		\begin{rmq} La \textit{loi} de $X$ est donnée par~\eqref{eq:loivad}. \end{rmq}

		\begin{déf} On note $F_X(t) = \P(X \leq t)$, ou encore $F_X(t) = \int_{-\infty}^tf(x)\dif x$ (en prenant $A = (-\infty, t]$). \end{déf}

		\begin{rmq} La fonction $t \mapsto F_X(t)$ est continue et est (presque) partout dérivable avec~:
		\[\pd{F_X}t(t) = f_X(t) \geq 0.\]
		Donc $F_X$ est croissante avec~:
		\[\lim_{t \to -\infty}F_X(t) = 0,\]
		et~:
		\[\lim_{t \to +\infty}F_X(t) = 1.\]
		\end{rmq}

		\begin{rmq} On peut associer une fonction de répartition $F_X$ à toute variable aléatoire $X$, même si $X$ est une v.a.d. Dans ce cas, on construit $F_X$
		constante par morceaux (et présente donc des points de discontinuité). \end{rmq}

		\begin{déf} Si $F_X$ est continue, on dit que $X$ est continue. \end{déf}

		\begin{rmq} Donc si $X$ est continue, alors $\P(X = x) = F_X(x) - \lim_{y \to x}F_X(y) = 0$. Ce résultat peut également être observé en utilisant le fait
		que $\P(X = x) = \int_x^x f(x)\dif x$, et une intégration sur un point est nulle. \end{rmq}

		\begin{rmq} Il existe des fonction continues nulle part dérivables. On peut donc avoir $F_X(t)$ continue mais pas sous la forme suivante~:
		\begin{equation}\label{eq:abscontinue}
			F_X(t) = \int_{-\infty}^tf(x)\dif x,
		\end{equation}
		pour une fonction $f_X$ donnée.
		\end{rmq}

		\begin{déf} On dit qu'une variable fonction $f : \R \to \R$ est \textbf{absolument continue} si elle admet une représentation intégrale de
		type~\eqref{eq:abscontinue}. \end{déf}

		\begin{déf} Soit $E$ un ensemble. La fonction $1_E$ est appelée \textbf{fonction indicatrice} est est définie telle que~:
		\[\forall x : 1_E(x) = \begin{cases}1 &\text{ si }x \in E \\0 &\text{ sinon}\end{cases}.\]
		\end{déf}

		\paragraph{Exemples}

		\begin{enumerate}
			\item Si $X_1 \sim U_{[a, b]}$ est une v.a.c. uniforme sur $[a, b]$, alors~:
			      \[F_{X_1}(t) = \begin{cases}0 &\text{ si }t \leq a \\t-a &\text{ si }a < t < b \\1 &\text{ si }t > b\end{cases}.\]

			\item Si $X_2 \sim \Exp(\lambda)$ est une v.a.c. exponentielle de paramètre $\lambda$, alors~:
			      \[F_{X_2}(t) = \int_{-\infty}^t\lambda\exp(-\lambda t)1_{(0, +\infty)}(t) = -\exp(-\lambda t)1_{(0, +\infty)}(t).\]

			\item Si $x_3 \sim \Nms$ est une v.a.c. normale de moyenne $\mu$ est de variance $\sigma^2$, alors~:
			      \[F_{X_3}(t) = \int_{-\infty}^tf(x)\dif x = \Erf\left(\frac {t-\mu}\sigma\right).\]

			\item Si $X_4 \sim \mathcal C$ est une v.a.c. de Cauchy de densité donnée par~:
			      \[f_{X_4}(x) = \frac 1{\pi(1+x^2)},\]
				  alors~:
				  \[F_{X_4}(t) = \frac 12 + \frac 1\pi\arctan(t).\]
		\end{enumerate}
	
	\subsection{Théorème de de Moivre-Laplace}
		Soient $p \in (0, 1)$ et $n \geq 1$. On pose $X_{n, p} \sim \mathcal B(n, p)$.

		Soit $Y_{n, p}$ défini par~: \[Y_{n, p} \coloneqq \frac {X_{n, p} - np}{\sqrt{np(1-p)}}.\]
		On remarque que $Y_{n, p}$ est une binomiale renormalisée.

		\begin{thm}[Théorème de de Moivre-Laplace] Si $t \in \R$, alors~:
		\[\P(Y_{n, p} \leq t) \stackrel{n \to +\infty}{\to}F_{\Nzu}(t).\]
		\end{thm}

		\begin{rmq} La signification de ce théorème est qu'une binomiale renormalisée se comporte comme une gaussienne $\Nzu$ lorsque $n \to +\infty$. \end{rmq}

		\begin{prp}[Formule de Stirling] \[n! \stackrel{n \to +\infty}\sim \sqrt{2\pi n}\left(\frac ne\right)^n.\] \end{prp}
	
	\subsection{Convergence en loi}
		\begin{déf}~
		\begin{itemize}
			\item Soit $Z$ une v.a.c. Soit $\{Z_n, n \geq 1\}$ une suite de v.a. quelconques. On dit que $Z_n$ \textit{converge en loi vers} $Z$ si~:
			      \[\forall x : F_{Z_n}(x) = \P(Z_n \leq x) \stackrel{n \to +\infty}\to F_Z(x).\]
			      On note cela~:
			      \[Z_n \convl Z.\]

			\item Soient $Z$ une v.a.d. et une $\{Z_n, n \geq 1\}$ une suite de variables aléatoires discrètes. On dit que $Z_n$ \textit{covnerge en loi vers}
			      $Z$ si~:
			      \[\forall x \in E : \P(Z_n = x) \stackrel{n \to +\infty}\to \P(Z = x).\]
			      On note cela~:
				  \[Z_n \convl Z.\]
		\end{itemize}
		\end{déf}

		\begin{rmq} Un exemple typique de convergence en loi de variables discrètes est~:
		\[\mathcal B\left(n, \frac \lambda{n}\right) \convl \mathcal P(\lambda).\]
		\end{rmq}

\section{Espérance}
	\subsection{Pari de pascal}
		Le terme \textit{espérance} vient de Blaise Pascal et de son traitement de la question «~Faut-il croire en Dieu~?~». On pose la variable $X$ qui
		décrit le résultat de l'existence de Dieu définie comme suit~:
		\[X = \begin{cases}0 &\text{ si Dieu n'existe pas} \\+\infty &\text{ sinon}\end{cases}.\]

		On a alors $\P(X = 0) = p$ et $\P(X = +\infty) = 1-p$. Prenons $p < 1$ (car si $p = 1$, on suppose que Dieu n'existe pas). Alors $\bar X$, la valeur
		moyenne de $X$ est donnée par~:
		\[\bar X = p \cdot 0 + (1-p) \cdot +\infty.\]

		Blaise Pascal a appelé cette valeur \textbf{espérance} et l'a noté $\E(X)$.
	
	\subsection{Espérance et variables aléatoires}
		\begin{rmq} Il existe plusieurs méthodes pour décrire le comportement d'une variable aléatoire. On s'intéresse ici aux \textbf{indicateurs de position}.
		Il existe d'autres types d'indicateurs dont les \textbf{indicateurs de répartition} qui seront vus plus loin. \end{rmq}

		\begin{déf} On considère $X$ une variable aléatoire sur un espace de probabilité $\ofp$.

		\begin{enumerate}
			\item \underline{Méthode de la médiane~:}

			      On évalue le nombre $\widetilde x$ tel que $\P(X \leq \widetilde x) = \P(X \geq \widetilde x) = \frac 12$.

			      Lorsque $X$ est continue, la médiane existe toujours. Si $X$ est discrète, la médiane n'existe pas obligatoirement et n'est pas forcément
			      unique.
			
			\item \underline{Méthode de l'espérance~:}

			      On évalue une \textit{moyenne pondérée} des valeurs que peut prendre $X$ par leur probabilité.
		\end{enumerate}
		\end{déf}

	\subsection{Définition de l'espérance}
		\subsubsection{Cas positif}
			
		\begin{déf}[Cas discret]\label{espposdisc} Soit $X$ une v.a.d. à valeurs positives. On note $p_k \coloneqq \P(X = x_k)$. On pose~:
		\[\E(X) = \sum_{k \geq 0}p_kx_k.\]
		\end{déf}

		\begin{rmq} Dans ce cas, l'espérance fait toujours sens et existe toujours mais peut valoir $+\infty$. \end{rmq}

		\begin{déf}[Cas absolument continu]\label{espposabscont} Soit $X$ une v.a.c. définie positive de densité $f_X$ et de répartition $F_X$. On note~:
		\[\left\{\begin{aligned}
			F_X(t) &= \P(X \leq t) \\
			f_X(t) &= \pd {}tF_X(t)
		\end{aligned}\right..\]

		On définit alors~:
		\[\E(X) = \int_0^{+\infty}xf(x)\dif x.\]
		\end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item L'intégrale démarre en $0$ car la variable aléatoire $X$ est définie positive~;
			\item à nouveau, l'espérance existe toujours mais peut valoir $+\infty$.
		\end{itemize}
		\end{rmq}

		\subsubsection{Cas général}
		
		\begin{déf}[Cas discret] Soit $X$ une v.a.d. à valeurs dans $E = \{x_0, \dotsc, x_n\} \subset \R$ fini ou infini dénombrable (typiquement $E = \Z$).
		On pose $p_n \coloneqq \P(X = x_n)$. On considère la série à termes positifs~:
		\[\sum_{x_n \in E}\abs {x_n}p_n.\]

		Si la série vaut $+\infty$, on dit que $X$ \textit{n'est pas intégrable} et on ne peut pas définir son espérance.

		Si la série est finie, alors le théorème~\ref{convabssérie} entraine que la série~:
		\[\sum_{x_n \in E}x_np_n\]
		converge également.

		On définit alors~:
		\begin{equation}
			\E(X) = \sum_{x_n \in E}x_np_n.
		\end{equation}
		\end{déf}

		\begin{déf}[Cas absolument continu (à densité)] Soit $X$ une v.a.c. de densité $f_X$ sur $\R$ telle que $\forall A \in \mathcal B(\R) :$
		\[\P(X \in A) = \int_Af(x)\dif x.\]

		On considère~:
		\begin{equation}
			I = \int_{-\infty}^{+\infty}\abs xf(x)\dif x.
		\end{equation}

		Si $I = +\infty$, on dit que $N$ \textit{n'est pas intégrable} et on ne peut pas définir son espérance.

		Si $E < +\infty$, le théorème~\ref{convabsintégrale} entraine que l'intégrale~:
		\[\int_{-\infty}^{+\infty}xf_X(x)\dif x\]
		converge également.

		On définit alors~:
		\begin{equation}
			\E(X) = \int_{-\infty}^{+\infty}xf(x)\dif x.
		\end{equation}
		\end{déf}

	\subsection{Exemples d'espérance}
		\begin{ex} (exemple de \ref{espposdisc}.) Soit $X \sim \mathcal B(n, p)$ une binomiale. Par définition, on évalue~:
		\[\begin{aligned}
			\E(X) &= \sum_{k=0}^n\binom nkp^k(1-p)^{n-k}k = \sum_{k=1}^n\binom nkp^k(1-p)^{n-k}k = np\sum_{k=1}^n\frac {(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k} \\
			      &= np\sum_{\gamma=0}^{n-1}\binom {n-1}\gamma p^\gamma(1-p)^{n-1-\gamma} = np(p + (1-p))^{n-1} = np.
		\end{aligned}\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposdisc}.) Soit $X \sim \mathcal P(\lambda)$ une poisson de paramètre $\lambda$. On évalue~:
		\[\begin{aligned}
			\E(X) &= \sum_{k \geq 0}\P(X = k)k = \sum_{k \geq 0}\exp(-\lambda)\frac {\lambda^k}{k!}k = \exp(-\lambda)\sum_{k \geq 1}\frac {\lambda^k}{k!}k \\
			      &= \exp(-\lambda)\lambda\sum_{k \geq 1}\frac {\lambda^{k-1}}{(k-1)!} = \lambda\exp(-\lambda)\sum_{\gamma \geq 0}\frac {\lambda^\gamma}{\gamma!}
				  = \lambda\exp(-\lambda)\exp(\lambda) = \lambda.
		\end{aligned}\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposdisc}.) Soit $X \sim \Bale$. La loi de $X$ est donnée par $\P(X = k) = \frac 6{(\pi k)^2}$ pour tout $k \geq 1$.
		On évalue~:
		\[\E(X) = \sum_{k \geq 1}\P(X = k)k  \sum_{k \geq 1}\frac 6{\pi^2}\sum_{k \geq 1}\frac 1{k^2}k = \frac 6{\pi^2}\sum_{k \geq 1}\frac 1k = +\infty.
		\footnote{La série $\sum_{k \geq 1}\frac 1k = +\infty$ se démontre en utilisant le fait que $\sum_{i=2^\alpha}^{2^{\alpha+1}}\frac 1i \gneqq \frac 12
		\forall \alpha \in \N$ et donc en faisant tendre $\alpha \to +\infty$, on obtient $+\infty$.}\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposabscont}.) Soit $X \sim \Exp(\lambda)$ une exponentielle négative\footnote{la notion d'exponentielle \textit{négative}
		vient du fait que le paramètre de la fonction exponentielle est négatif, mais la fonction exponentielle est définie positive.}. On sait~:
		\[f_X(t) = \lambda\exp(-\lambda t),\]
		et donc on calcule~:
		\[\E(X) = \int_0^{+\infty}xf_X(x)\dif x = \int_0^{+\infty}x\lambda\exp(-\lambda x)\dif x.\]
		On pose $y \coloneqq \lambda x$ (et donc $\dif y = \lambda \dif x$), et on obtient~:
		\[E(X) = \frac 1\lambda\int_0^{+\infty}y\exp(-y)\dif y = \frac 1\lambda.\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposabscont}.) Soit $X \sim U_{(a, b)}$ une uniforme sur $(a, b)$ où $0 \leq a < b \in \R$. On sait~:
		\[f_X(t) = \frac 1{b-a}1_{(a, b)}(t),\]
		et donc, on calcule~:
		\[\E(X) = \int_0^{+\infty}x f_X(x)\dif x = \int_a^b\frac x{b-a} = \left[\frac {x^2}{2(b-a)}\right]_a^b = \frac {b^2 - a^2}{2(b-a)} = \frac {a+b}2.\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposabscont}.) Soit $X \sim \frac 12\mathcal C$ une demi-Cauchy. On sait (pour $t \in [0, +\infty)$)~:
		\[f_X(t) = \frac 2{\pi(1+t^2)},\]
		et donc, on calcule~:
		\[\E(X) = \int_0^{+\infty}xf_X(x)\dif x = \int_0^{+\infty}\frac {2x}{(1+x^2)}\frac {\dif x}{\pi}= \frac 1\pi \left[\log(1+x^2)\right]_0^{+\infty} = +\infty\]
		\end{ex}

\end{document}
