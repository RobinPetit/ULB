\documentclass{article}

\usepackage{palatino,eulervm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage[bottom]{footmisc}
% math packages
\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}
\usepackage{mathdots}
\usepackage{commath}
\usepackage{stmaryrd}

\usepackage{hyperref}

\makeatletter
\def\thm@space@setup{%
	\thm@preskip=.4cm%
	\thm@postskip=\thm@preskip%
}
\makeatother

  \newcommand{\C}{\mathbb C}
  \newcommand{\E}{\mathbb E}
  \newcommand{\N}{\mathbb N}
\renewcommand{\P}{\mathbb P}
  \newcommand{\Q}{\mathbb Q}
  \newcommand{\R}{\mathbb R}
  \newcommand{\Z}{\mathbb Z}

\newcommand{\Nms}{\mathcal N(\mu, \sigma^2)}  % normale \mu, \sigma
\newcommand{\Nzu}{\mathcal N(0, 1)}  % normale 0, 1
\newcommand{\convl}{\stackrel{\mathcal D}\to}  % convergence en loi
\newcommand{\eql}{\stackrel{\mathcal D}=}  % égalité en loi
\newcommand{\espproba}[3]{\left(#1, #2, #3\right)}  % espace de probabilité
\newcommand{\Ofp}{\espproba \Omega{\mathcal F}\P}  % espace \Omega, F, P
\newcommand{\ofp}{\Ofp}
\newcommand{\Lu}{\mathcal L_1\Ofp}  % espace L_1 (espérance finie)
\newcommand{\Ld}{\mathcal L_2\Ofp}  % espace L_2 (variance finie)
\newcommand{\evpd}[2]{\pd {}{#1}\sVert[2]_{#1=#2}}  % évaluation de dérivée partielle
\newcommand{\evipd}[3][i]{\pd[i] {}{#2}\sVert[2]_{#2=#3}}  % évaluation de la i ème dérivée partielle

\newcommand{\iintv}[2]{\left\llbracket#1, #2\right\rrbracket}

\DeclareMathOperator{\tq}{t.q.}
\DeclareMathOperator{\Erf}{Erf}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\Bale}{\textup{Bâle}}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Leb}{Leb}

% amsthm
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\renewcommand{\proofname}{\it{Démonstration}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}

\author{R. Petit}
\title{MATHF-105 : Probabilités \\ Résumé}
\date{Année académique 2015 - 2016}

\begin{document}

\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}

\section{Rappels}
	\subsection{Rappel sur les séries}
		Les fonctions logarithmique et exponentielle ont un développement de Taylor exact. Pour la fonction logarithmique, on a, pour $x \in (-1, 1)$~:
		\[\log(1-x) = -\sum_{k \geq 1}\frac {x^k}k.\]

		Si on pose $S_n \coloneqq \sum_{k = 1}^nu_k$, on a $(S_n)_{n \in \N}$, la suite des sommes partielles, et $n \mapsto S_n$, une application croissante si
		$(u_n)$ est une suite positive. Il y a donc deux situations distinctes possibles~:

		\begin{itemize}
			\item $(S_n)$ est une suite bornée ($\exists M \in \R \tq \forall n \in \N : S_n \leq M$) et donc converge vers $S \in \R$~;
			\item $(S_n)$ n'est pas bornée ($\forall M \in \R : \exists n \in \N \tq S_n > M$) et donc diverge vers $+\infty$.
		\end{itemize}

		\subsubsection{Exemple sur les séries}
		Prenons $u_n \coloneqq x^n$, avec $x > 0$.

		\begin{itemize}
			\item Si $x = 1$, on a $n \to +\infty \Rightarrow S_n \to +\infty$~;
			\item si $x \neq 1$, on a $(1-x)S_n = x-x^{n+1}$, et donc~:
			      \[S_n \coloneqq x\frac {1-x^n}{1-x}.\]

			      \begin{itemize}
			      	\item Si $x < 1$, alors $x^n \to 0$ pour $n \to +\infty$, et donc $S_n \to \frac x{1-x}$~;
					\item si $x > 1$, alors $x^n \to +\infty$ pour $n \to +\infty$, et donc $S_n \to +\infty$.
			      \end{itemize}
		\end{itemize}

		\subsubsection{Conclusion de la suite géométrique}
		On voit alors~:
		\[\sum_{n \geq 1}x^n = \begin{cases}\frac x{1-x} &\text{ si } x \in [0, 1) \\ +\infty & \text{ sinon }\end{cases}.\]

		Si la suite commence à l'indice 0, on a~:
		\[\sum_{n \geq 0}x^n = 1 + \sum_{n \geq 1}x^n = \begin{cases}1 + \frac x{1-x} = \frac 1{1-x} &\text { si } x \in [0, 1) \\ +\infty &\text{ sinon}\end{cases}.\]
	
	\subsection{Rappels d'analyse}
		\begin{déf} Une fonction $f : X \to Y$ est dite mesurable si~:
		\[\forall A \subset \mathcal B(Y) : \{\omega \in \Omega \tq X(\omega) \in A\} \in \mathcal F,\]
		où $\mathcal B(Y)$ représente la tribu des boréliens (voir définition~\ref{boréliens}). \end{déf}

		\begin{thm}\label{convabssérie} Dans $\R$, toute série absolument convergente est convergente. \end{thm}
		
		\begin{thm}\label{convabsintégrale} Dans $\R$, toute intégrale impropre absolument convergente est convergente. \end{thm}

\newpage
\section{Espaces de probabilités}
	\subsection{Définition}
		\begin{déf} L'ensemble $\Omega$ est l'\textbf{espace des chances}, l'ensemble des résultats possibles d'un phénomène aléatoire. \end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item $\Omega$ peut être fini (dénombrable) ou infini~;
			\item $\Omega = \left\{0, 1\right\}^\N$ est l'ensemble des suites à valeur dans $\{0, 1\}$~;
			\item $\Omega$ peut être un espace dit \emph{fonctionnel} quand le résultat d'une expérience est une fonction.
		\end{itemize}
		\end{rmq}

		\begin{déf} Un événement $E$ est un ensemble de réalisations possibles à une expérience tel que $E \subseteq \Omega$. \end{déf}

		\begin{rmq} L'ensemble $\mathcal P(\Omega)$ n'est pas toujours dénombrable. Et donc l'ensemble $\mathcal P(\Omega)$ est-il le bon ensemble pour décrire
		les événements~?
		
		\begin{itemize}
			\item Si $\abs \Omega \in \N$~: oui~;
			\item si $\abs \Omega \not \in \N$~: non.
		\end{itemize}
		\end{rmq}

		\begin{déf} $\mathcal F$ est la \textbf{classe des événements}. On mesure la \emph{probabilité d'occurrence} d'un événement $A \in \mathcal F$.
		On introduit une fonction d'ensemble $\P$ où~:
		\[\P : \mathcal F \to [0, 1] : A \mapsto \P(A).\]

		On impose~:
		\begin{itemize}
			\item[$(i)$] $\P(\emptyset) = 0$~;
			\item[$(ii)$] $\P(\Omega) = 1$~;
			\item[$(iii)$] $\forall A, B \in \mathcal F : A \cap B = \emptyset \Rightarrow \P(A \cup B) = \P(A) + \P(B)$.
		\end{itemize}
		\end{déf}

		\begin{prp} Soient $A_1, \dotsc, A_n \in \mathcal F$. On a~:
		\[\P\left(\bigcup_{i=1}^n A_i\right) = \sum_{i=1}^n(-1)^{i-1}\sum_{1 \leq k_1 < \dotsb < k_i \leq n}\P\left(\bigcap_{\gamma=1}^iA_{k_\gamma}\right).\]
		\end{prp}

		\subsubsection{Loi uniforme sur un ensemble fini (ou dénombrable)}
		\begin{déf} Soient $m < n \in \N$. On définit l'\textbf{intervalle entier} $\iintv mn$ par~:
		\[\iintv mn : \{x \in \N \tq m \leq x \leq n\}.\] \end{déf}
		
		\begin{déf} Soit $\Omega = \iintv 1n$. Soit $A \subseteq \Omega$. La loi uniforme est donnée par~:
		\[\P(A) = \frac {\abs A}{\abs \Omega} = \frac {\abs A}n.\] \end{déf}

		\begin{rmq} Il arrive que $\abs A$ soit difficile à déterminer et qu'il faille aller chercher du côté de l'analyse combinatoire. \end{rmq}

		\subsubsection{Loi uniforme sur un ensemble infini (intervalle)}

		\begin{déf} Soit $\Omega = [0, 1]$ et soit $A = [a, b] \subseteq \Omega$. La loi uniforme est donnée par~:
		\[\P(A) = (b-a).\] \end{déf}

		\begin{rmq} La définition de loi uniforme sur un intervalle fait intervenir la notion de mesure et donc de mesurabilité. Or il existe des parties de
		$\Omega$ sur lesquelles la mesure n'a pas de sens. En général, $\mathcal P(\Omega)$ est \emph{trop grand}, et il faut donc remplacer l'utilisation
		de l'ensemble des parties par la notion de tribu. \end{rmq}

		\begin{déf} Soit $\Omega$ un ensemble de chances et $\mathcal F \subseteq \mathcal P(\Omega)$ une famille de parties de $\Omega$. On dit que
		$\mathcal F$ est une tribu s'il respecte les trois propriétés suivantes~:
		\begin{itemize}
			\item $\emptyset \in \mathcal F$~;
			\item $\forall A : A \in \mathcal F \Rightarrow A^\complement \in \mathcal F$~;
			\item $\forall A_1, \dotsc, A_n, \ldots : A_1, \dotsc, A_n, \ldots \in \mathcal F \Rightarrow \bigcup_{k \geq 1}A_k \in \mathcal F$.
		\end{itemize}

		Une autre appellation pour une tribu est une $\sigma$-algèbre.
		\end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item On remarque que $\mathcal P(\Omega)$ est une tribu, mais une tribu trop grande pour être intéressante~;
			\item Soit $A \in \mathcal P(\Omega)$. Alors $T \coloneqq \{\emptyset, A, A^\complement, \mathcal P(\Omega)\}$ est une tribu.
			      $T$ est la plus petite tribu contenant $A$, et on l'appelle la \textbf{tribu engendrée par $A$}, que l'on note $\sigma(A)$.
		\end{itemize}
		\end{rmq}

		\begin{déf}\label{boréliens} Soit $I$ une partie de $\mathcal P(\Omega)$. On appelle la \emph{tribu engendrée par $I$} la plus petite tribu contenant
		$I$ et on la note $\sigma(I)$.
		
		En prenant $I \coloneqq \{$ intervalles ouverts de $[0, 1]\}$, on obtient $\sigma(I)$ que l'on appelle \textbf{tribu des boréliens}.
		\footnote{Le nom de \emph{borélien} vient du mathématicien français Émile Borel suite à ses travaux sur la théorie de la mesure.} \end{déf}

		\begin{déf} Soit $\Omega$ un ensemble de chances et $\mathcal F \subset \mathcal P(\Omega)$ une tribu sur $\Omega$. Une probabilité sur
		$\Ofp$ est une fonction $\P$ définie par~:
		\[\P : \mathcal F \to [0, 1] : A \mapsto \P(A),\]
		où $\P$ satisfait~:

		\begin{itemize}
			\item[$(i)$] $\P(\emptyset) = 0$~;
			\item[$(ii)$] $\forall A \in \mathcal F : \P(aA) + \P(A^\complement) = 1$~;
			\item[$(iii)$] $\forall A_1, \dotsc, A_n, \ldots$ disjoints deux à deux, on a~:
			               \[\P\left(\bigcup_{k \geq 1}A_k\right) = \sum_{k \geq 1}\P(A_k).\]
		\end{itemize}
		\end{déf}

		\begin{déf} On appelle $\Ofp$ un espace de probabilités. \end{déf}

		\begin{rmq} Probabiliser un expérience revient à déterminer~:
		\begin{itemize}
			\item $\Omega$, l'espace des chances~;
			\item $\mathcal F$, la classe des événements~;
			\item $\P$, la fonction d'ensembles sur $\mathcal F$.
		\end{itemize}
		\end{rmq}
	
	\subsection{Modèles}
		\subsubsection{Modèles discrets}
		\begin{rmq} On prend $\Omega$ un ensemble fini ou dénombrable. On prend également $\mathcal F = \mathcal P(\Omega)$.

		Si $\Omega$ est fini, on parle de tirages, et si $\Omega$ est infini dénombrable, on parle de populations.

		On pose~:
		\[\P : \{k\} \mapsto p_k \in [0, 1],\]
		où~:
		\[\sum_{k \in \Omega}p_k = 1\]
		et pour $A = \{k_1, \dotsc, k_n\} \in \mathcal F$~:
		\[\P(A) = \sum_{\gamma=1}^np_{k_\gamma}.\]
		\end{rmq}

		\begin{déf}[Modèle de Bernoulli] On prend $\Omega = \{0, 1\}$ où~:
		\[\begin{cases}p_0 &= 1-p \\p_1 &= p\end{cases}.\] \end{déf}

		\begin{rmq} Il est évident que $p + (1-p) = 1 = P(\Omega)$. \end{rmq}

		\begin{déf}[Modèle binomial] On prend $\Omega = \iintv 0N$ (et donc $\mathcal F = \mathcal P(\Omega)$) et $p \in [0, 1]$.
		Le modèle binomial est défini par $p_k = \binom nkp^k(1-p)^{N-k}$ pour tout $k \in \iintv 0N$. \end{déf}

		\begin{rmq} On remarque que $\sum_{k \geq 1}p_k = 1$ car les $p_k$ représentent les termes du binôme de Newton $(p + (1-p))^N = 1^N = 1$. \end{rmq}

		\begin{déf}[Modèle géométrique] On prend $\Omega = \N$, $\mathcal F = \mathcal F(\Omega) \simeq \R$, et $p \in (0, 1)$. Le modèle géométrique
		est défini par $p_k = (1-p)^{k-1}p$ pour tout $k \in \N$. \end{déf}

		\begin{rmq} On remarque que~:
		\[\sum_{k \geq 1}p_k = \sum_{k \geq 1}p(1-p)^{k-1} = p\sum_{k \geq 0}(1-p)^k = p\frac 1{1-(1-p)} = \frac pp = 1,\]
		où on utilise la formule de la somme des termes d'une suite géométrique $u$ définie par $u_n = u_{n-1}q$ pour $n \geq 1$ (avec $0 < q < 1$) qui donne~:
		\[\sum_{k=0}^Nu_k = u_0\frac {1 - q^{N+1}}{1-q},\]
		et pour la série, il suffit de passer à la limite~:
		\[\lim_{N \to +\infty}\sum_{k=0}^Nu_k = \lim_{N \to +\infty}u_0\frac {1 - q^{N+1}}{1-q} = u_0\frac 1{1-q}.\]
		\end{rmq}

		\begin{déf}[Modèle de Poisson] On prend $\Omega  =\N$, $\mathcal F = \mathcal P(\Omega)$, et un paramètre $\lambda \in \R_0^+$.
		Le modèle poissonien est défini par $p_k = \exp(-\lambda)\frac {\lambda^k}{k!}$ pour tout $k \in \N$. \end{déf}

		\begin{rmq} On remarque que $\P(\Omega) = 1$ en utilisant la formule de Taylor de l'exponentielle~:
		\[\exp(x) = \sum_{k \geq 0}\frac {x^k}{k!}.\]

		On a effectivement~:
		\[\P(\Omega) = \sum_{k \geq 0}\P(\{k\}) = \sum_{k \geq 0}p_k = \sum_{k \geq 0}\exp(-\lambda)\frac {\lambda^k}{k!} = \exp(-\lambda)\exp(\lambda) = 1.\]
		\end{rmq}

		\subsubsection{Modèles continus (à densité)}
		\begin{rmq} On prend $\Omega$ un intervalle (fini ou infini\footnote{On parle d'intervalle fini pour $[a, b]$, avec $a < b \in \R$ et d'intervalle
		semi-infini pour $(-\infty, b]$ ou $[a, +\infty)$ et d'intervalle infini pour $(-\infty, +\infty) = \R$.}) sur $\R$, et $\mathcal F = \mathcal B(I)$,
		la tribu des boréliens sur $I$\footnote{Ou encore la tribu engendrée par les intervalles de $I$.}. \end{rmq}

		\begin{déf} Soit $f : I \to \R^+$ une fonction intégrable telle que $\int_\R f(x)\dif x = 1$. Soit $A \in \mathcal F$, on pose
		$\P(A) = \int_Af(x)\dif x$. $f$ est appelée fonction de densité de modèle stochastique. \end{déf}

		\begin{déf}[Loi uniforme continue] On prend $I = [a, b]$ avec $a < b \i \R$. Le modèle uniforme est défini par $f$ constante~:
		\[f(x) = \begin{cases}0 &\text{ si }x \not \in [a, b] \\\frac 1{b-a} &\text{ si }x \in [a, b]\end{cases}.\] \end{déf}

		\begin{rmq} On remarque effectivement $\int_\R f(x)\dif x = 1$~:
		\[\int_\R f(x)\dif x = \int_{-\infty}^a f(x)\dif x + \int_a^b f(x)\dif x + \int_b^{+\infty} f(x)\dif x = 0 + \frac 1{b-a}\int_a^b\dif x + 0 = 1.\]
		\end{rmq}

		\begin{déf}[Modèle exponentiel]\footnote{Également appelé \emph{modèle des files d'attente}.}\label{modèleExponentiel} On prend $I = \R^+$ et
		$\lambda > 0$. Le modèle exponentiel est défini par~:
		\[f(x) = \begin{cases}\lambda\exp(-\lambda x) &\text{ si }x \geq 0 \\ 0 &\text{ sinon}\end{cases}.\]
		\end{déf}

		\begin{rmq} On peut calculer l'intégrale impropre comme suit~:
		\[\begin{aligned}
			\int_\R f(x)\dif x &= \int_{-\infty}^0f(x)\dif x + \int_0^{+\infty}f(x)\dif x = 0 + \lim_{M \to +\infty}\int_0^Mf(x)\dif x \\
			&= \lim_{M \to +\infty}\left[-\exp(-\lambda x)\right]_0^M = \lim_{M \to +\infty}\left(1 - \exp(-\lambda M)\right) = 1.
		\end{aligned}\]
		\end{rmq}

		\begin{déf}[Modèle gaussien]\footnote{Également appelé \emph{modèle des erreurs} ou encore \textit{modèle normal}.} On prend $I = \R$, et
		$(\mu, \sigma) \in \R \times \R^+_0$. Le modèle gaussien est défini par~:
		\[f(x) = \frac 1{\sigma\sqrt{2\pi}}\exp\left(-\frac {(x-\mu)^2}{2\sigma^2}\right).\]
		\end{déf}

		\begin{rmq} Pour que $\P$ soit une probabilité, il faut que $f$ soit définie positive. Or $f$ est une exponentielle multipliée par un coefficient
		positif. Il faut également $\int_\R f(x)\dif x = 1$, ce qui peut se vérifier par~:
		\[\int_\R f(x)\dif x,\]
		en posant $y \coloneqq x-\mu$, et donc $\dif y = \dif x$~:
		\[\int_\R \frac 1{\sigma \sqrt{2\pi}}\exp\left(-\frac {y^2}{2\sigma^2}\right) = \frac 1{\sigma\sqrt{2\pi}}\int_\R\exp\left(-\frac {y^2}{2\sigma^2}\right).\]
		En posant $z \coloneqq \frac y\sigma$ (et donc $\dif z = \frac {\dif x}\sigma$), on obtient~:
		\[\int_\R f(x)\dif x = \frac 1{\sqrt{2\pi}}\int_\R\exp\left(-\frac {z^2}2\right)\dif z.\]

		Une primitive de $\exp\left(-\frac {z^2}2\right)$ est~:
		\[\int_{-\infty}^z\exp\left(-\frac {x^2}2\right)\frac {\dif x}{\sqrt{2\pi}} = \Erf(z).\]

		On écrit alors~:
		\[\begin{aligned}
			\P(\Omega)^2 &= \left(\int_\R\exp\left(-\frac {x^2}2\right)\frac {\dif x}{\sqrt{2\pi}}\right)
			                \left(\int_\R\exp\left(-\frac {y^2}2\right)\frac {\dif y}{\sqrt{2\pi}}\right) \\
			             &= \iint_{\R^2}\exp\left(-\frac {x^2+y^2}2\right)\frac {\dif x\dif y}{2\pi}.
		\end{aligned}\]
		
		En passant en coordonnées polaires, on obtient~:
		\[\P(\Omega)^2 = \int_{-\pi}^{+\pi}\int_\R\exp\left(-\frac {r^2}2\right)\frac {r\dif r\dif \theta}{2\pi}
		= \int_{-\pi}^{+\pi}\frac {\dif \theta}{2\pi}\int_\R r\exp\left(-\frac {r^2}2\right)\dif r
		= \left[-\exp\left(-\frac {r^2}2\right)\right]_0^{+\infty} = 1.\]

		On en déduit alors $\P(\Omega) = 1$ également. $\P$ est donc bien une probabilité. \end{rmq}
		
		\begin{déf} On a défini une probabilité sur $\left(R^+, \mathcal(R^+)\right)$ via la fonction $f(r) = r\exp\left(-\frac {r^2}2\right)$.
		On l'appelle la \emph{probabilité de Rayleigh}. \end{déf}

		\subsubsection{Divergence sur la fonction Gamma d'Euler}

		\begin{déf}[Fonction Gamma d'Euler] La fonction Gamma d'Euler est définie comme suit~:
		\[\Gamma : \R_0^+ \to \R : x \mapsto \int_0^{+\infty}\exp(-x)x^{t-1}\dif x.\] \end{déf}
		
		\begin{rmq} On note $\gamma \coloneqq -\Gamma'(1) > 0$ la constante d'Euler-Mascheroni. La question $\gamma \stackrel{?}{\in} \Q$ est toujours ouverte.
		\end{rmq}

		\begin{prp}\label{GammaRecursif} $\forall t > 0 : \Gamma(t+1) = t\Gamma(t)$. \end{prp}

		\begin{proof} Soit $t > 0$. Par l'intégration par parties, on a~:
		\[\Gamma(t+1) = \int_0^{+\infty}\exp(-x)x^{t}\dif x = \left[-x^t\exp(-x)\right]_0^{+\infty} + t\int_0^{+\infty}\exp(-x)x^{t-1}\dif x = t\Gamma(t).\]
		\end{proof}

		\begin{rmq} Par la proposition~\ref{GammaRecursif}, on peut définir la factorielle de tout nombre naturel par~:
		\[\forall n \in \N^* : n! = \Gamma(n+1)\]
		\end{rmq}

		\begin{prp}[Formule des compléments] Soit $t \in (0, 1)$. Alors~:
		\[\Gamma(t)\Gamma(1-t) = \frac \pi{\sin(\pi t)}.\]
		\end{prp}

		\subsubsection{Retour aux modèles stochastiques}

		\begin{déf}[Modèle Gamma]\footnote{Le modèle $\Gamma$ est une généralisation du modèle exponentiel (définition~\ref{modèleExponentiel}).}
		On prend $\Omega = \R^+$. Le modèle Gamma est défini par~:
		\[f_t(x) = \frac {x^t-\exp(-x)}{\Gamma(t)}.\]
		\end{déf}

	\subsection{Notion de variables aléatoires}
		\subsubsection{Cas discret}

		\begin{déf} Soit $\Ofp$ un espace de probabilité. Une variable aléatoire discrète\footnote{Souvent écrite v.a.d. ou V.A.-D.} est une application
		$X : \Omega \to E$ où $E$ est un ensemble fini ou infini dénombrable. On demande à cette application d'être mesurable. \end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item Bien souvent, on a $E = \Omega$, et $X(\omega) = \omega$. Dans ce cas, on \emph{identifie} l'espace des chances avec l'espace d'arrivée.
			      La probabilité $\P$ s'appelle alors la \textbf{loi} de la variable aléatoire $X$.
			\item Il arrive parfois que l'espace de probabilités soit plus gros que l'espace d'état.
		\end{itemize}
		\end{rmq}

		\begin{déf} Plus formellement, la \textbf{loi} d'une v.a.d. $X$ est l'ensemble~:
		\[\{\P(X = x) \tq x \in E\}.\]
		\end{déf}

		\begin{déf} Pour toute valeur $k \in E$ que peut prendre la variable aléatoire $X$, on note $\P(X = k)$ la probabilité que la variable $X$ prenne la
		valeur $k$. C'est équivalent à $\P\left(X(\omega) = k\right)$ pour $\omega \in \Omega$. \end{déf}

		\begin{déf} Lorsqu'une v.a.d. $X$ suit une certaine loi $\mathcal L$, on note $X \sim \mathcal L$.
		
		Par exemple, une variable $Y$ suivant une poisson de paramètre $\lambda$ se note $Y \sim \mathcal P(\lambda)$. \end{déf}
	
		\subsubsection{Cas absolument continu}

		\begin{déf} Soit $\Ofp$ un espace de probabilité. Une variable aléatoire absolument continue\footnote{Souvent écrite v.a.c. ou V.A.-C.} est une
		application $X : \Omega \to \R$ mesurable au sens où~:
		\[\forall A \in \mathcal B(\R) : \{\omega \in \Omega \tq X(\omega) \in A\} \in \mathcal F,\]
		et \emph{absolument continue} au sens où~:
		\[\exists f_X : \R \to \R^+\]
		mesurable et telle que~:
		\[\int_\R f_X(x)\dif x = 1,\]
		avec~:
		\begin{equation}\label{eq:loivad}
			\P(X \in A) = \int_A f_X(x)\dif x.
		\end{equation}
		\end{déf}

		\begin{déf} On appelle $f_X$ la \textbf{densité} de $X$. \end{déf}

		\begin{rmq} La \emph{loi} de $X$ est donnée par~\eqref{eq:loivad}. \end{rmq}

		\begin{déf} On note $F_X(t) = \P(X \leq t)$, ou encore $F_X(t) = \int_{-\infty}^tf(x)\dif x$ (en prenant $A = (-\infty, t]$). \end{déf}

		\begin{rmq} La fonction $t \mapsto F_X(t)$ est continue et est (presque) partout dérivable avec~:
		\[\pd{F_X}t(t) = f_X(t) \geq 0.\]
		Donc $F_X$ est croissante avec~:
		\[\lim_{t \to -\infty}F_X(t) = 0,\]
		et~:
		\[\lim_{t \to +\infty}F_X(t) = 1.\]
		\end{rmq}

		\begin{rmq} On peut associer une fonction de répartition $F_X$ à toute variable aléatoire $X$, même si $X$ est une v.a.d. Dans ce cas, on construit $F_X$
		constante par morceaux (et présente donc des points de discontinuité). \end{rmq}

		\begin{déf} Si $F_X$ est continue, on dit que $X$ est continue. \end{déf}

		\begin{rmq} Donc si $X$ est continue, alors $\P(X = x) = F_X(x) - \lim_{y \to x}F_X(y) = 0$. Ce résultat peut également être observé en utilisant le fait
		que $\P(X = x) = \int_x^x f(x)\dif x$, et une intégration sur un point est nulle. \end{rmq}

		\begin{rmq} Il existe des fonction continues nulle part dérivables. On peut donc avoir $F_X(t)$ continue mais pas sous la forme suivante~:
		\begin{equation}\label{eq:abscontinue}
			F_X(t) = \int_{-\infty}^tf(x)\dif x,
		\end{equation}
		pour une fonction $f_X$ donnée.
		\end{rmq}

		\begin{déf} On dit qu'une variable fonction $f : \R \to \R$ est \textbf{absolument continue} si elle admet une représentation intégrale de
		type~\eqref{eq:abscontinue}. \end{déf}

		\begin{déf} Soit $E$ un ensemble. La fonction $1_E$ est appelée \textbf{fonction indicatrice} est est définie telle que~:
		\[\forall x : 1_E(x) = \begin{cases}1 &\text{ si }x \in E \\0 &\text{ sinon}\end{cases}.\]
		\end{déf}

		\paragraph{Exemples}

		\begin{enumerate}
			\item Si $X_1 \sim U_{[a, b]}$ est une v.a.c. uniforme sur $[a, b]$, alors~:
			      \[F_{X_1}(t) = \begin{cases}0 &\text{ si }t \leq a \\t-a &\text{ si }a < t < b \\1 &\text{ si }t > b\end{cases}.\]

			\item Si $X_2 \sim \Exp(\lambda)$ est une v.a.c. exponentielle de paramètre $\lambda$, alors~:
			      \[F_{X_2}(t) = \int_{-\infty}^t\lambda\exp(-\lambda t)1_{(0, +\infty)}(t) = -\exp(-\lambda t)1_{(0, +\infty)}(t).\]

			\item Si $x_3 \sim \Nms$ est une v.a.c. normale de moyenne $\mu$ est de variance $\sigma^2$, alors~:
			      \[F_{X_3}(t) = \int_{-\infty}^tf(x)\dif x = \Erf\left(\frac {t-\mu}\sigma\right).\]

			\item Si $X_4 \sim \mathcal C$ est une v.a.c. de Cauchy de densité donnée par~:
			      \[f_{X_4}(x) = \frac 1{\pi(1+x^2)},\]
				  alors~:
				  \[F_{X_4}(t) = \frac 12 + \frac 1\pi\arctan(t).\]
		\end{enumerate}
	
	\subsection{Théorème de de Moivre-Laplace}
		Soient $p \in (0, 1)$ et $n \geq 1$. On pose $X_{n, p} \sim \mathcal B(n, p)$.

		Soit $Y_{n, p}$ défini par~: \[Y_{n, p} \coloneqq \frac {X_{n, p} - np}{\sqrt{np(1-p)}}.\]
		On remarque que $Y_{n, p}$ est une binomiale renormalisée.

		\begin{thm}[Théorème de de Moivre-Laplace] Si $t \in \R$, alors~:
		\[\P(Y_{n, p} \leq t) \stackrel{n \to +\infty}{\to}F_{\Nzu}(t).\]
		\end{thm}

		\begin{rmq} La signification de ce théorème est qu'une binomiale renormalisée se comporte comme une gaussienne $\Nzu$ lorsque $n \to +\infty$. \end{rmq}

		\begin{prp}[Formule de Stirling] \[n! \stackrel{n \to +\infty}\sim \sqrt{2\pi n}\left(\frac ne\right)^n.\] \end{prp}
	
	\subsection{Convergence en loi}
		\begin{déf}~
		\begin{itemize}
			\item Soit $Z$ une v.a.c. Soit $\{Z_n, n \geq 1\}$ une suite de v.a. quelconques. On dit que $Z_n$ \emph{converge en loi vers} $Z$ si~:
			      \[\forall x : F_{Z_n}(x) = \P(Z_n \leq x) \stackrel{n \to +\infty}\to F_Z(x).\]
			      On note cela~:
			      \[Z_n \convl Z.\]

			\item Soient $Z$ une v.a.d. et une $\{Z_n, n \geq 1\}$ une suite de variables aléatoires discrètes. On dit que $Z_n$ \emph{covnerge en loi vers}
			      $Z$ si~:
			      \[\forall x \in E : \P(Z_n = x) \stackrel{n \to +\infty}\to \P(Z = x).\]
			      On note cela~:
				  \[Z_n \convl Z.\]
		\end{itemize}
		\end{déf}

		\begin{rmq} Un exemple typique de convergence en loi de variables discrètes est~:
		\[\mathcal B\left(n, \frac \lambda{n}\right) \convl \mathcal P(\lambda).\]
		\end{rmq}

\newpage
\section{Espérance}
	\subsection{Pari de pascal}
		Le terme \emph{espérance} vient de Blaise Pascal et de son traitement de la question «~Faut-il croire en Dieu~?~». On pose la variable $X$ qui
		décrit le résultat de l'existence de Dieu définie comme suit~:
		\[X = \begin{cases}0 &\text{ si Dieu n'existe pas} \\+\infty &\text{ sinon}\end{cases}.\]

		On a alors $\P(X = 0) = p$ et $\P(X = +\infty) = 1-p$. Prenons $p < 1$ (car si $p = 1$, on suppose que Dieu n'existe pas). Alors $\bar X$, la valeur
		moyenne de $X$ est donnée par~:
		\[\bar X = p \cdot 0 + (1-p) \cdot +\infty.\]

		Blaise Pascal a appelé cette valeur \textbf{espérance} et l'a noté $\E(X)$.
	
	\subsection{Espérance et variables aléatoires}
		\begin{rmq} Il existe plusieurs méthodes pour décrire le comportement d'une variable aléatoire. On s'intéresse ici aux \textbf{indicateurs de position}.
		Il existe d'autres types d'indicateurs dont les \textbf{indicateurs de répartition} qui seront vus plus loin. \end{rmq}

		\begin{déf} On considère $X$ une variable aléatoire sur un espace de probabilité $\ofp$.

		\begin{enumerate}
			\item \underline{Méthode de la médiane~:}

			      On évalue le nombre $\widetilde x$ tel que $\P(X \leq \widetilde x) = \P(X \geq \widetilde x) = \frac 12$.

			      Lorsque $X$ est continue, la médiane existe toujours. Si $X$ est discrète, la médiane n'existe pas obligatoirement et n'est pas forcément
			      unique.
			
			\item \underline{Méthode de l'espérance~:}

			      On évalue une \emph{moyenne pondérée} des valeurs que peut prendre $X$ par leur probabilité.
		\end{enumerate}
		\end{déf}

	\subsection{Définition de l'espérance}
		\subsubsection{Cas positif}
			
		\begin{déf}[Cas discret]\label{espposdisc} Soit $X$ une v.a.d. à valeurs positives. On note $p_k \coloneqq \P(X = x_k)$. On pose~:
		\[\E(X) = \sum_{k \geq 0}p_kx_k.\]
		\end{déf}

		\begin{rmq} Dans ce cas, l'espérance fait toujours sens et existe toujours mais peut valoir $+\infty$. \end{rmq}

		\begin{déf}[Cas absolument continu]\label{espposabscont} Soit $X$ une v.a.c. définie positive de densité $f_X$ et de répartition $F_X$. On note~:
		\[\left\{\begin{aligned}
			F_X(t) &= \P(X \leq t) \\
			f_X(t) &= \pd {}tF_X(t)
		\end{aligned}\right..\]

		On définit alors~:
		\[\E(X) = \int_0^{+\infty}xf(x)\dif x.\]
		\end{déf}

		\begin{rmq}~
		\begin{itemize}
			\item L'intégrale démarre en $0$ car la variable aléatoire $X$ est définie positive~;
			\item à nouveau, l'espérance existe toujours mais peut valoir $+\infty$.
		\end{itemize}
		\end{rmq}

		\subsubsection{Cas général}
		
		\begin{déf}[Cas discret] Soit $X$ une v.a.d. à valeurs dans $E = \{x_0, \dotsc, x_n\} \subset \R$ fini ou infini dénombrable (typiquement $E = \Z$).
		On pose $p_n \coloneqq \P(X = x_n)$. On considère la série à termes positifs~:
		\[\sum_{x_n \in E}\abs {x_n}p_n.\]

		Si la série vaut $+\infty$, on dit que $X$ \emph{n'est pas intégrable} et on ne peut pas définir son espérance.

		Si la série est finie, alors le théorème~\ref{convabssérie} entraine que la série~:
		\[\sum_{x_n \in E}x_np_n\]
		converge également.

		On définit alors~:
		\begin{equation}
			\E(X) = \sum_{x_n \in E}x_np_n.
		\end{equation}
		\end{déf}

		\begin{déf}[Cas absolument continu (à densité)]\label{espabscont} Soit $X$ une v.a.c. de densité $f_X$ sur $\R$ telle que $\forall A \in \mathcal B(\R) :$
		\[\P(X \in A) = \int_Af(x)\dif x.\]

		On considère~:
		\begin{equation}
			I = \int_{-\infty}^{+\infty}\abs xf(x)\dif x.
		\end{equation}

		Si $I = +\infty$, on dit que $N$ \emph{n'est pas intégrable} et on ne peut pas définir son espérance.

		Si $E < +\infty$, le théorème~\ref{convabsintégrale} entraine que l'intégrale~:
		\[\int_{-\infty}^{+\infty}xf_X(x)\dif x\]
		converge également.

		On définit alors~:
		\begin{equation}
			\E(X) = \int_{-\infty}^{+\infty}xf(x)\dif x.
		\end{equation}
		\end{déf}

	\subsection{Exemples d'espérance}
		\begin{ex} (exemple de \ref{espposdisc}.) Soit $X \sim \mathcal B(n, p)$ une binomiale. Par définition, on évalue~:
		\[\begin{aligned}
			\E(X) &= \sum_{k=0}^n\binom nkp^k(1-p)^{n-k}k = \sum_{k=1}^n\binom nkp^k(1-p)^{n-k}k = np\sum_{k=1}^n\frac {(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k} \\
			      &= np\sum_{\gamma=0}^{n-1}\binom {n-1}\gamma p^\gamma(1-p)^{n-1-\gamma} = np(p + (1-p))^{n-1} = np.
		\end{aligned}\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposdisc}.) Soit $X \sim \mathcal P(\lambda)$ une poisson de paramètre $\lambda$. On évalue~:
		\[\begin{aligned}
			\E(X) &= \sum_{k \geq 0}\P(X = k)k = \sum_{k \geq 0}\exp(-\lambda)\frac {\lambda^k}{k!}k = \exp(-\lambda)\sum_{k \geq 1}\frac {\lambda^k}{k!}k \\
			      &= \exp(-\lambda)\lambda\sum_{k \geq 1}\frac {\lambda^{k-1}}{(k-1)!} = \lambda\exp(-\lambda)\sum_{\gamma \geq 0}\frac {\lambda^\gamma}{\gamma!}
				  = \lambda\exp(-\lambda)\exp(\lambda) = \lambda.
		\end{aligned}\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposdisc}.) Soit $X \sim \Bale$. La loi de $X$ est donnée par $\P(X = k) = \frac 6{(\pi k)^2}$ pour tout $k \geq 1$.
		On évalue~:
		\[\E(X) = \sum_{k \geq 1}\P(X = k)k  \sum_{k \geq 1}\frac 6{\pi^2}\sum_{k \geq 1}\frac 1{k^2}k = \frac 6{\pi^2}\sum_{k \geq 1}\frac 1k = +\infty.
		\footnote{La série $\sum_{k \geq 1}\frac 1k = +\infty$ se démontre en utilisant le fait que $\sum_{i=2^\alpha}^{2^{\alpha+1}}\frac 1i \gneqq \frac 12
		\forall \alpha \in \N$ et donc en faisant tendre $\alpha \to +\infty$, on obtient $+\infty$.}\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposabscont}.) Soit $X \sim \Exp(\lambda)$ une exponentielle négative\footnote{la notion d'exponentielle \emph{négative}
		vient du fait que le paramètre de la fonction exponentielle est négatif, mais la fonction exponentielle est définie positive.}. On sait~:
		\[f_X(t) = \lambda\exp(-\lambda t),\]
		et donc on calcule~:
		\[\E(X) = \int_0^{+\infty}xf_X(x)\dif x = \int_0^{+\infty}x\lambda\exp(-\lambda x)\dif x.\]
		On pose $y \coloneqq \lambda x$ (et donc $\dif y = \lambda \dif x$), et on obtient~:
		\[E(X) = \frac 1\lambda\int_0^{+\infty}y\exp(-y)\dif y = \frac 1\lambda.\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposabscont}.) Soit $X \sim U_{(a, b)}$ une uniforme sur $(a, b)$ où $0 \leq a < b \in \R$. On sait~:
		\[f_X(t) = \frac 1{b-a}1_{(a, b)}(t),\]
		et donc, on calcule~:
		\[\E(X) = \int_0^{+\infty}x f_X(x)\dif x = \int_a^b\frac x{b-a} = \left[\frac {x^2}{2(b-a)}\right]_a^b = \frac {b^2 - a^2}{2(b-a)} = \frac {a+b}2.\]
		\end{ex}

		\begin{ex} (exemple de \ref{espposabscont}.) Soit $X \sim \frac 12\mathcal C$ une demi-Cauchy. On sait (pour $t \in [0, +\infty)$)~:
		\[f_X(t) = \frac 2{\pi(1+t^2)},\]
		et donc, on calcule~:
		\[\E(X) = \int_0^{+\infty}xf_X(x)\dif x = \int_0^{+\infty}\frac {2x}{(1+x^2)}\frac {\dif x}{\pi}= \frac 1\pi \left[\log(1+x^2)\right]_0^{+\infty} = +\infty\]
		\end{ex}

		\begin{ex} (exemple de \ref{espabscont}.) Soit $X \sim \mathcal C$ une Cauchy. On sait~:
		\[f_X(t) = \frac 1{\pi(1+t^2)},\]
		et donc, on calcule~:
		\[\int_{-\infty}^{+\infty}xf_X(x)\dif x = 2\int_0^{+\infty}\abs xf_X(x)\dif x = 2\infty = +\infty.\]
		\end{ex}

		\begin{prp}[Critère de d'Alembert] Soit $f$ une fonction définie positive sur $[1, +\infty)$. On suppose $f(x) \sim \frac c{x^a}$ quand $x \to +\infty$
		avec $a, c \in \R$.

		Si $a < 1$, alors~:
		\[\int_1^{+\infty}f(x)\dif x < +\infty,\]
		et si $a \geq 1$, alors~:
		\[\int_1^{+\infty}f(x)\dif x = +\infty.\]
		\end{prp}

		\begin{rmq} Dans les cas des Cauchy, on a $a=1$ et $c = \frac 1\pi$. Donc, par d'Alembert, on sait que l'intégrale est infinie. On n'a pas besoin de
		primitive explicite. \end{rmq}

		\begin{rmq} Pour les variables aléatoires continues n'ayant pas d'espérance, on peut s'intéresser à la médiane $m \in \R$ telle que~:
		\[\int_{-\infty}^mf(x)\dif x = \int_m^{+\infty}f(x)\dif x = \frac 12.\]

		Si $f$ s'annule en certaines $x$, il se peut que $m$ ne soit pas unique.

		Une variable $X \sim \mathcal C$ Cauchy est paire, et donc $m = 0$.
		\end{rmq}
	
	\subsection{Espérance de fonctions de variables aléatoires}
		\begin{déf} Soit $X$ une v.a.c. réelle et $g : \R \to \R$ une fonction mesurable. La quantité $Y = g(X)$ est une variable aléatoire car c'est une
		application~: $Y : \Omega \to \R : \omega \mapsto (g \circ X)(\omega)$. \end{déf}

		\begin{thm}[Principe de transfert] Soient $X$ une v.a. et $Y \coloneqq g(X)$. On suppose $\E(\abs Y) < +\infty$\footnote{Ainsi, $\E(Y)$ a un sens.},
		alors~:
		\begin{equation}
			\E(Y) =
				\begin{cases}
					\displaystyle \sum_{x_n \in E}g(x_n)\P(X = x_n) &\text{ si $X$ est discrète} \\
					\displaystyle \int_\R g(x)f_X(x)\dif x &\text{si $X$ est absolument continue}
				\end{cases}.
		\end{equation}
		\end{thm}

		\begin{rmq} Ce théorème signifie que pour déterminer l'espérance de $g(X)$, on intègre $g(x)$ le long de la loi de $X$. \end{rmq}

		\begin{ex}[Calcul du moment d'ordre 2] On prend $g : \R \to \R : x \mapsto x^2$.

		\underline{Cas discret~:} soit $X$ à valeurs dans $E \coloneqq \{x_0, x_1, \ldots\}$. On prend $Y \coloneqq g(X)$. Alors, l'espérance est donnée par~:
		\[\E(Y) = \E(g(Y)) = \sum_{x_n \in E}(x_n)^2\P(X = x_n).\]

		Si $X \sim \mathcal P(\lambda)$ est une poisson de paramètre $\lambda$, on a $E = \N$. Dès lors, on considère $x_n = n$. L'espérance est alors~:
		\begin{align*}
			\E(Y) &= \E(X^2) = \sum_{n \geq 0} n^2\P(X = n) = \sum_{n \geq 1}n^2\exp(-\lambda)\frac {\lambda^n}{n!} = \exp(-\lambda)\sum_{n \geq 1}n\frac {\lambda^n}{(n+-1)!} \\
			      &= \exp(-\lambda)\sum_{n \geq 1}\left((n-1) + 1\right)\frac {\lambda^n}{(n-1)!}
				  = \exp(-\lambda)\left[\lambda\sum_{n \geq 1}\frac {\lambda^{n-1}}{(n-1)!} + \sum_{n \geq 1}(n-1)\frac {\lambda^n}{(n-1)!}\right] \\
				  &= \lambda + \exp(-\lambda)\sum_{n \geq 2}\frac {\lambda^n}{(n-2)!} = \lambda + \lambda^2\exp(-\lambda)\sum_{n \geq 2}\frac {\lambda^{n-2}}{(n-2)!} \\
				  &= \lambda + \lambda^2.
		\end{align*}

		\underline{Cas absolument continu~:} soit $X$ à valeurs dans $\R$ de densité $f_X$. On prend $Y \coloneqq g(X)$. Alors, l'espérance est donnée par~:
		\[\E(Y) = \E(g(X)) = \int_\R x^2f_X(x)\dif x.\]

		Si $X \sim \Exp(\lambda)$ est une exponentielle négative de paramètre $\lambda$, on a (en posant $y \coloneqq \lambda x$ et donc
		$\dif y = \lambda \dif x$)~:
		\begin{align*}
			\E(Y) &= \E(X^2) = \int_\R x^2\lambda\exp(-\lambda x)\dif x = \frac 1{\lambda^2}\int_\R y^2\exp(-y)\dif y = \frac {\Gamma(3)}{\lambda^2}
			      = \frac {2!}{\lambda^2}  = \frac 2{\lambda^2}.
		\end{align*}
		\end{ex}

		\begin{déf} Soit $\Ofp$ un espace de probabilités. On note~:
		\begin{equation}
			\Lu \coloneqq \{X \text{ v.a.} \tq \E(\abs X) < +\infty\}.
		\end{equation}
		\end{déf}

		\begin{thm}[Propriété fondamentale de l'espérance] L'espace $\Lu$ est un espace vectoriel réel de dimension infinie. Donc~:
		\[\forall X, Y \in \Lu, \lambda, \mu \in \R : \lambda X + \mu Y \in \Lu.\]

		De plus, $\E(\lambda X + \mu Y) = \lambda \E(X) + \mu \E(Y)$.
		\end{thm}

		\begin{rmq} On dit alors que l'espérance est un opérateur linéaire. \end{rmq}

		\begin{thm} Si $X \geq 0$ est une v.a. définie positive, alors son espérance est positive. \end{thm}

	\subsection{Variance}
		\subsubsection{Définitions}
		\begin{déf} Soit $X \in \Lu$. On pose $Y \coloneqq (X - \E(X))^2$. Par définition, $Y$ est positive, et donc on peut définir son espérance. On pose~:
		\begin{equation}
			\Var(X) \coloneqq \E(Y).
		\end{equation}
		\end{déf}

		\begin{rmq} Il est possible que $\Var(X) = \E(Y) = +\infty$. Dans ce cas, on dit que $X$ est de variance infinie. \end{rmq}

		\begin{rmq} La variance est un indicateur de répartition par rapport à la moyenne. Dans le cas où la variance est infinie, on regarde les quantités
		$\P(\abs{X - \E(X)} \geq x)$ pour $x > 0$ par analogie à la médiane. \end{rmq}

		\begin{prp}\label{var=e-e} Soit $X$ une v.a. de variance $\Var(X) < +\infty$. Alors~:
		\begin{equation}\label{eq:var=e-e}
			\Var(X) = \E(X^2) - \E(X)^2.
		\end{equation}
		\end{prp}

		\begin{proof} On observe que~:
		\[\Var(X) = \E\left[(X-\E(X))^2\right] = \E\left[X^2 + \E(X)^2 - 2X\E(X)\right] = \E(X^2) + \E(X)^2 - 2\E(X)\E(X) = \E(X^2) - \E(X)^2.\]
		\end{proof}

		\begin{rmq} La variance est une valeur positive. Donc on a $\E(X^2) - \E(X)^2 \geq 0$, et donc $\E(X^2) \geq \E(X)^2$. \end{rmq}

		\begin{prp} La proposition~\ref{var=e-e} peut se retrouver à l'aide de l'inégalité de Cauchy-Schwartz. \end{prp}

		\begin{proof} \underline{Dans le cas discret}, on pose $y_n \coloneqq x_n\sqrt{\P(X=x_n)}$, et $z_n \coloneqq \sqrt{\P(X=x_n)}$. L'inégalité de
		Cauchy-Schwartz implique~:
		\[\abs {\sum_{n=1}^Ny_nz_n} \leq \sqrt{\left(\sum_{n=1}^Ny_n^2\right) \left(\sum_{n=1}^Nz_n^2\right)}.\]
		Les valeurs étant positives, on peut passer au carré. En faisant tendre $N \to +\infty$, on obtient~:
		\[\left(\sum_{n \geq 1}y_nz_n\right)^2 \leq \left(\sum_{n \geq 1}y_n^2\right) \left(\sum_{n \geq 1}z_n^2\right).\]
		On sait que~:
		\[
			\left\{\begin{aligned}
				\sum_{n \geq 1}z_n^2 &= \sum_{n \geq 1}\P(X = x_n) = 1, \\
				\sum_{n \geq 1}y_n^2 &= \sum_{n \geq 1}(x_n)^2\P(X = x_n) = \E(X^2), \\
				\sum_{n \geq 1}y_nz_n &= \sum_{n \geq 1}y_nz_n = \sum_{n \geq 1}x_n\P(X = x_n) = \E(X).
			\end{aligned}\right.
		\]

		On a bien~:
		\[\E(X)^2 \leq \E(X^2),\]
		qui est l'inégalité~\eqref{eq:var=e-e}.

		\underline{Dans le cas absolument continu}, on a $X$ une v.a. de densité $f_X$ sur $\R$. On pose $g(x) = \sqrt{f_X(x)}$ et $h(x) = x\sqrt{f_X(x)}$.
		L'inégalité de Cauchy-Scwhartz implique~:
		\[\abs{\int_\R h(x)g(x)\dif x} \leq \sqrt {\left(\int_\R h(x)^2 \dif x\right) \left(\int_\R g(x)^2 \dif x\right)}.\]
		À nouveau, en mettant au carré, on obtient~:
		\begin{align*}
			\left(\int_\R xf_X(x)\dif x\right)^2 &\leq \left(\int_\R \left(x\sqrt{f_X(x)}\right)^2\dif x\right) \left(\int_\R\left(\sqrt{f_X(x)}\right)\dif x\right) \\
			&= \left(\int_\R x^2f_X(x)\dif x\right) \left(\int_\R f_X(x)\dif x\right).
		\end{align*}

		On sait que~:
		\[
			\left\{\begin{aligned}
				\left(\int_\R xf_X(x)\dif x\right)^2 &= \E(X)^2 \\
				\int_\R x^2f_X(x)\dif x &= \E(X^2) \\
				\int_\R f_X(x)\dif x &= 1.
			\end{aligned}\right.
		\]

		On a bien~:
		\[\E(X)^2 \leq \E(X)^2,\]
		qui est l'inégalité~\eqref{eq:var=e-e}.
		\end{proof}

		\begin{déf} Soit $\Ofp$ un espace de probabilités. On pose~:
		\[\Ld \coloneqq \{V \text{ v.a.} \tq \E(X^2) < +\infty\}.\]
		\end{déf}

		\begin{thm} L'espace $\Ld$ est un espace vectoriel réel de dimension infinie. Donc~:
		\[\forall X, Y \in \Ld, \lambda, \mu \in \R : \lambda X + \mu Y \in \Ld.\]
		\end{thm}

		\begin{rmq} L'application $X \mapsto \E(X^2)$ est une forme quadratique et donc n'est pas linéaire. \end{rmq}

		\begin{thm} L'espace $\Ld$ est inclus dans l'espace $\Lu$. Donc si $\E(X^2) < +\infty$, alors $\E(\abs X) < +\infty$. \end{thm}

		\begin{thm}[Inégalité de Cauchy-Schwartz sur les espaces $\mathcal L_i$] Soient $X, Y \in \Ld$. Alors~:
		\begin{equation}\label{eq:C-SL2}
			\abs {\E(XY)} \leq \E\left(\abs {XY}\right) \leq \sqrt{\E(X^2)\E(Y^2)}.
		\end{equation}
		\end{thm}

	\subsection{Moments de variables aléatoires}
		\subsubsection{Cas discret}
		\begin{déf} Soit $E = {x_i}_{i \in \N}$ un espace d'état fini ou infini dénombrable. Si $X$ est une variable aléatoire à valeurs dans $E$, alors sa 
		\emph{loi} est donnée par $\{p_i = \P(X = x_i)\}_{i \in \N}$. Les moments de $X$ sont les valeurs moyennes de $F(X)$ où $F : E \to \R$ est une fonction
		donnée. \end{déf}

		\begin{déf} On considère la suite de terme général $\abs {F(x_i)}p_i$.

		\begin{itemize}
			\item[$(i)$] Si $\sum_{i \in \N}\abs{F(x_i)}p_i$ converge, alors le $F$-moment de $X$ existe et vaut~:
			             \[\E(F(X)) = \sum_{i \in \N}F(x_i)\P(X=x_i)\,;\]
			\item[$(ii)$] si $\sum_{i \in \N}\abs{F(x_i)}p_i$ diverge, alors le $F$-moment de $X$ n'a pas de sens et donc n'est pas défini.
		\end{itemize}
		\end{déf}

		\subsubsection{Cas absolument continu}
		\begin{déf} Soient $E = \R$ et $f_X : \R \to \R^+$ mesurable telle que $\int_\R f_X(x)\dif x$. $f_X$ est appelée \emph{densité de probabilité sur $\R$}.
		La variable aléatoire $X$ associée est telle que~:
		\[\forall A \in \mathcal B(\R) : \P(X \in A) = \int_A f_X(x)\dif x = \int_\R f_X(x)1_A(x)\dif x.\]
		\end{déf}

		\begin{rmq} Soit $A \in \mathcal B(\R)$. Si $\int_A\dif x \eqqcolon \Leb(A) = 0$, alors $\P(X \in A) = 0$. \end{rmq}

		\begin{déf} Soit $F : \R \to \R$ mesurable.

		\begin{itemize}
			\item[$(i)$] Si $\int_\R \abs{F(x)}f_X(x)\dif x$ converge, alors le $F$-moment de $X$ existe et vaut~:
			             \[\E(F(X)) = \int_\R F(x)f_X(fx)\dif x\,;\]
			\item[$(ii)$] si $\int_\R \abs{F(x)}f_X(x)\dif x$ diverge, alors le $F$-moment de $X$ n'a pas de sens et donc n'est pas défini.
		\end{itemize}
		\end{déf}

		\begin{rmq} Le calcul \emph{effectif} de $\E(F(X))$ est une intégrale impropre qui peut s'avérer compliquée. \end{rmq}
	
	\subsection{Fonctions génératrices}
		L'objectif est de trouver un certain type de fonctions qui permet de retrouver la loi d'une variable aléatoire $X$.

		\subsubsection{Cas discret}
		\begin{déf} Soit $X$ une variable aléatoire à valeurs dans $\N$. On pose $p_i \coloneqq \P(X = i)$ pour tout $i \geq 1$.
		On regarde~:
		\[F : \R \to \R : x \mapsto t^x\qquad\qquad\text{avec }t \in [0, 1].\]
		Pour tout $x$, on sait $F(x) \in [0, 1]$, et donc la fonction $F$ est définie positive. Dès lors, la série~:
		\[\sum_{i \geq 1}t^ip_i\]
		est majorée par~:
		\[\sum_{i \geq 1}1^ip_i = \sum_{i \geq 1}p_i = 1.\]
		La série étant convergente, on peut définir pour tout $t \in [0, 1]$ l'espérance suivante~:
		\[\E(t^X) \coloneqq \sum_{k \geq 1}t^kp_k.\]

		On pose $G_X$ telle que~:
		\[G_X : [0, 1] \to [0, 1] : t \mapsto \E(t^X).\]
		Donc $G_X$ envoie $t$ sur le $F$-moment de $X$. On appelle $G_X$ la \emph{fonction génératrice de $X$}.
		\end{déf}

		\begin{prp} Soient $X$ une variable aléatoire à valeurs dans $\N$ et $G_X$ sa fonction génératrice. Alors pour tout $i \in \N^*$~:
		\begin{equation}\label{eq:partialG_X=p_i}
			\evipd t0G_X(t) = i! \cdot \P(X = i).
		\end{equation}
		\end{prp}

		\begin{proof} On sait que $G_X(t)$ s'écrit sous la forme suivante~:
		\[G_X(t) = \sum_{k \geq 1}\P(X = k)t^k.\]
		Soit $i \in \N^*$. On peut «~découper~» la somme en~:
		\[G_X(t) = \sum_{k=1}^{i-1}\P(X = k)t^k + \P(X=i)t^i + \sum_{k \gneqq i}\P(X = k)t^k.\]

		En prenant la dérivée $i$ème selon $t$, on obtient~:
		\[\pd[i] {}tG_X(t) = \sum_{k=1}^{i-1}\pd[i] {}tt^k\P(X=k) + \pd[i] {}tt^i\P(X=k) + \sum_{k \gneqq i}\pd[i] {}tt^k\P(X=k)
		= 0 + i!\P(X=i) + \sum_{k \gneqq i}\frac {k!}{(k-i)!}t^{k-i}\P(X=k).\]
		En évaluant tout cela en $t=0$, on obtient bien~:
		\[\evipd t0G_x(t) = 0 + i! \cdot \P(X = i) + 0,\]
		qui est bien l'égalité~\eqref{eq:partialG_X=p_i}
		\end{proof}

		\begin{ex} Soit $X \sim \mathcal G(p)$, une géométrique de paramètre $p \in (0, 1)$. On pose $q \coloneqq 1-p$ et $p_i \coloneqq q^{i-1}p$ pour tout
		$i \geq 1$. On calcule sa fonction génératrice $G_X$~:
		\[G_X(t) = \E(t^X) = \sum_{k \geq 1}t^k\P(X=k) = \sum_{k \geq 1}t^kq^{k-1}p = p\sum_{k \geq 1}t^kq^{k-1} = pt \sum_{k \geq 1}(tq)^{k-1} = pt \sum_{k \geq 0}(qt)^k
		= \frac {pt}{1-qt},\]
		par la formule de somme d'une suite géométrique.
		On peut réorganiser la formule afin d'obtenir~:
		\[G_X(t) = \frac qq\frac {pt}{1-qt} = \frac pq\frac {qt}{1-qt} = \frac pq\left(-1 + \frac 1{1-qt}\right).\]
		En dérivant et en instanciant en $t=0$, on a bien~:
		\[\evipd t0G_X(t) = \frac pq\evipd t0\frac {1}{1-qt} = \frac pqi!\left(\frac {q^i}{(1-qt)^{i+1}}\right) = \frac {i!\,pq^{i-1}}{(1-qt)^{i+1}} = i!\,pq^{i-1}
		= i! \cdot \P(X = i).\]
		\end{ex}

		\subsubsection{Lien entre moments entiers et fonctions génératrices}
		En prenant une dérivée formelle (terme à terme) de $G_X(t) = \E(t^X)$, on obtient~:
		\[\pd {}tG_X(t) = \sum_{k \geq 1}kt^{k-1}\P(X=k) = \E(Xt^{X-1}).\]

		Le théorème de convergence monotone affirme que si $t$ croît vers $1$, alors $Xt^{X-1}$ croît vers $X$ \textbf{et} $\E(Xt^{X-1})$ croît vers $\E(X)$.
		On a alors~:
		\[\pd[n] {}tG_X(t) = \E\left[t^{X-n}\prod_{i=0}^{n-1}(X-i)\right],\]
		qui croît vers~:
		\[\E\left[\prod_{i=0}^{n-1}(X-i)\right],\]
		quand $t$ croît vers $1$.

		\begin{rmq} On remarque que $\{\E(X^n)\}_{n \in \N^*}$ se retrouve par linéarité à partir de $\{\E\left(\prod_{i=0}^{n-1}(X-i)\right)\}$.
		
		Les moments entiers peuvent donc s'écrire comme une combinaison linéaire d'instanciations de dérivées de fonction génératrices en $t=1$. \end{rmq}

		\begin{ex} Prenons par exemple $\E(X^2)$. Par linéarité de l'opérateur $\E$, on sait que~:
		\[\E(X^2) = \E(X^2 - X + X) = \E(X^2-X) + \E(X) = \E((X-0)(x-1)) + \E(X) = \evipd[2] t1G_X(t) + \evpd t1G_X(t).\]
		\end{ex}

		\subsubsection{Cas absolument continu}
		\begin{déf} On considère la fonction $F : x \mapsto \exp(itx)$. Par définition de l'exponentielle complexe, on sait que $\abs {F(x)} = 1$.
		Donc l'intégrale~:
		\[\int_\R \abs{F(x)}f_X(x)\dif x = \int_\R f_X(x)\dif x = 1.\]
		On peut donc définir~:
		\[\E(F(X)) = \E(\exp(itX)).\]

		On définit alors la fonction génératrice de $X$ par~:
		\[G_X(t) : \R \to \C : t \mapsto \E(\exp(itX)).\]
		\end{déf}

		\begin{rmq} On appelle également $G_X$ la \emph{fonction caractéristique de $X$}. \end{rmq}

		\begin{thm}[Théorème de Lévy] La fonction caractéristique $G_X$ de la variable aléatoire $X$ caractérise la loi de $X$. \end{thm}

		\begin{thm}[Formule d'inversion de Fourier] Soit $X$ une variable aléatoire de densité $f_X$. On suppose $\int_\R \abs {G_X(t)}\dif t < +\infty$. Alors~:
		\[f_X(x) = \frac 1{2\pi}\int_\R\exp(-itx)G_X(t)\dif t.\]
		\end{thm}

		\begin{rmq} Il existe également une formule générale d'inversion due à Lévy qui permet de retrouver $x \mapsto \P(X \leq x)$ en
		connaissant $G_X(t)$. Dès lors, on déduit que deux variables aléatoires $X$ et $Y$ sont égales en loi si et seulement si leur fonction caractéristique
		respective est identique.  % si si, 'est' identique, tout au singulier, c'est correct.

		\[X \eql Y \iff G_X \equiv G_Y.\]
		\end{rmq}

		\subsubsection{Aperçu de la convergence en loi}
		\begin{déf} Soit $\{X_k\}_{k \geq 1}$ une famille de variables aléatoires à valeurs dans $\N$. On dit que $\{X_k\}$ converge en loi si~:
		\[\forall n \geq 0 : (k \to +\infty) \Rightarrow (\P(X_k = n) \to \P(X = n)).\]

		La convergence en loi se note~:
		\[X_k \convl X.\footnote{Le $\mathcal D$ vient du terme \emph{distribution}.}\]
		\end{déf}

		\begin{thm} Soit $\{X_k\}_{k \geq 1}$ une suite de variables aléatoires et $X$ une v.a. On pose $G_{X_k} \coloneqq \E\left(t^{X_k}\right)$.Alors
		les assertions suivantes sont équivalentes~:
		\begin{enumerate}
			\item $X_k \convl X$~;
			\item $\forall n \geq 0 : p_n^{(k)} \coloneqq \P(X_k = n) \to \P(X = n) \eqqcolon p_n$ quand $k \to +\infty$~;
			\item $\forall n \geq 0, t \in [0, 1] : p_n^{(k)}t^n \to p_nt^n$ quand $k \to +\infty$.
		\end{enumerate}
		\end{thm}

		\begin{rmq} Par convergence normale, on déduit $\forall t \in [0, 1]$~:
		\begin{equation}\label{eq:convkinf}
			G_{X_k}(t) \stackrel{k \to +\infty}\to G_X(t).
		\end{equation}
		\end{rmq}

		\begin{déf}[Convergence simple] Soit $(F_n)_{n \in \N}$ une suite de fonctions telles que $F_n : X \to Y$. On dit que la suite $(F_n)$ converge
		simplement en l'application $F$ si~:
		\[\forall x \in X : (F_n(x))_n \to F(x) \in Y.\]
		\end{déf}

		\begin{rmq} On remarque que $F_{X_k} \to F_X$ simplement quand $k \to +\infty$. Dans ce cas, les dérivées convergent également simplement~:
		\[\forall n \in \N^* : \pd[n] {}tG_{X_k} \to \pd[n] {}tG_X \text{ simplement}.\]
		Et par $\P(X=i) = \frac 1{i!}\evipd t0F_X(t)$, on déduit~:
		\[X_k \convl X \iff G_{X_k} \to G_X \text{ simplement}.\]
		\end{rmq}

		\begin{ex}[Loi des événements rares\footnote{Distribution de Poisson.}] Soit $X_k \sim \mathcal B(k, p(k))$ où $p(k) \coloneqq \lambda k$ pour
		$\lambda > 0$ fixé. Par définition, on sait pour tout $n \leq k$~:
		\[\P(X_k = n) = \binom knp(k)^n(1-p(k))^{k-n},\]
		et donc~:
		\begin{align*}
			\E\left(t^{X_k}\right) &= \sum_{n=0}^k\binom knp(k)^q(1-p(k))^{k-n}t^n = \sum_{n=0}^k\binom kn\left(p(k)t\right)^n\left(1-p(k)\right)^{k-n} \\
			&= (1-p(k) + p(k)t)^k = \left(1 + \frac {\lambda(t-1)}k\right)^k = \exp\left[k\log\left(1 + \frac {\lambda(t-1)}k\right)\right].
		\end{align*}

		On sait cependant que le développement de Taylor d'ordre 1 de $x \mapsto \log(1+x)$ autour de $x=0$ est~:
		\[T_1(x \mapsto \log(1+x), 0) = x + o(x).\]
		Et donc~:
		\[\E\left(t^{X_k}\right) = \exp\left[k\left(\frac {\lambda(t-1)}k + o\left(\frac 1k\right)\right)\right].\]
		En faisant tendre $k \to +\infty$, on sait que $k o\left(\frac 1k\right) \to 0$, et donc on trouve~:
		\[\E\left(t^{X_k}\right) \stackrel{k \to +\infty}\to\exp\left(\lambda(t-1)\right).\]

		Soit $X \sim \mathcal P(\lambda)$ une poisson de ce même paramètre $\lambda$. On calcule également sa fonction génératrice~:
		\[\E\left(t^X\right) = \sum_{k \geq 1}\P(X=k)t^k = \exp(-\lambda)\sum_{k \geq 1}\frac {\lambda^k}{k!}t^k = \exp(-\lambda)\exp(\lambda t)
		= \exp\left(\lambda(t-1)\right).\]

		On en déduit alors que $\forall t \in [0, 1] : G_{X_k}(t) \stackrel {k \to +\infty}\to G_X(t)$. Et par~\eqref{convkinf}, on a~:
		\[X_k \stackrel {k \to +\infty}\to X,\]
		ce qui est équivalent à~:
		\[\mathcal B\left(k, \frac \lambda k\right) \stackrel {k \to +\infty}\to \mathcal P(\lambda).\]
		\end{ex}

		\begin{thm}[Théorème de Lévy] Soient $X$ une variable aléatoire réelle de fonction caractéristique $G_X$ et une suite de v.a. réelles $\{X_k\}_{k \in \N}$
		de fonction caractéristique respective $G_{X_k}$. Alors~:
		\[X_k \convl X \iff G_{X_k} \to G_X\quad\text{simplement}.\]
		\end{thm}

		\begin{ex}[Démontrer De Moivre-Laplace grâce à Lévy] Soient $p \in (0, 1)$ et $X_n \sim \mathcal B(n, p)$. On pose~:
		\[Z_n \coloneqq \frac {X_n - np}{\sqrt{np(1-p)}}.\]
		La fonction caractéristique de $Z_n$ est donnée par~:
		\begin{align*}
			G_{Z_n}(t) &= \E\left[\exp(itZ_n)\right] = \E\left[\exp\left(it\frac {X_n}{\sqrt{np(1-p}}\right)\right]\exp\left(-it \sqrt{\frac {np}{1-p}}\right) \\
			           &= \left[(1-p) + p\exp\left(\frac {it}{\sqrt{np(1-p)}}\right)\right]^n\exp\left(-it\sqrt {\frac {np}{1-p}}\right) \\
					   &= \left[1+p\left(\exp\left(\frac {it}{\sqrt{np(1-p)}}\right)-1\right)\right]^n\exp\left(-it\sqrt{\frac {np}{1-p}}\right).
		\end{align*}

		On regarde maintenant l'approximation de Taylor de $x \mapsto \exp(ix)$ autour de $x = 0$ qui vaut~:
		\[T_1(x \mapsto \exp(ix), 0) = 1 - \frac {x^2}2 + o(x^2) + i\left(x + o(x^2)\right) = 1 + ix - \frac {x^2}2 + o(x^2).\]
		On peut donc ré-écire la fonction caractéristique comme~:
		\begin{align*}
			G_{Z_n} &= \left[1+p\left(\left(1 + i\frac t{\sqrt{np(1-p)}} - \frac {t^2}{2np(1-p)} + o(n^{-1})\right) - 1\right)\right]^n\exp\left(-it\sqrt{\frac {np}{1-p}}\right) \\
			        &= \left[1+\left(i\frac {t\sqrt p}{\sqrt{n(1-p)}} - \frac {t^2}{2n(1-p)} + o(n^{-1})\right)\right]^n\exp\left(-it\sqrt {\frac {np}{1-p}}\right).
		\end{align*}

		En posant~:
		\[\alpha \coloneqq i\frac {t\sqrt p}{\sqrt{n(1-p)}} - \frac {t^2}{2n(1-p)} + o(n^{-1}),\]
		on peut approximer $G_{Z_n}(t)$ par~:
		\begin{align*}
			G_{Z_n}(t) &= \left[1 + \alpha\right]^n\exp\left(-it\sqrt{\frac{np}{1-p}}\right) \\
			           &= \exp\left(\log\left(\left[1 + \alpha\right]^n\right)\right)\exp\left(-it\sqrt{\frac {np}{1-p}}\right) \\
			           &= \exp\left(n\log(1+\alpha)\right)\exp\left(-it\sqrt{\frac{np}{1-p}}\right) \\
			           &= \exp\left(\alpha - \frac {\alpha^2}{2} + o(\alpha^3)\right)\exp\left(-it\sqrt{\frac{np}{1-p}}\right)
		\end{align*}

		On calcule donc $\alpha - \frac {\alpha^2}2$~:
		\begin{align*}
			\alpha - \frac {\alpha^2}2 = i\frac {t\sqrt p}{\sqrt {n(1-p)}} - \frac {t^2}{2n(1-p)} + o(n^{-1})
			                           - \frac 12\left(\frac {i^2t^2p}{n(1-p)} + \frac {t^4}{4n^2(1-p)^2} + o(n^{-2}) - 2\frac {it^3\sqrt p}{2n(1-p)\sqrt {n(1-p)}}\right).
		\end{align*}

		Or,
		\[\frac {t^4}{4n^2(1-p)^2} + o(n^{-2}) - 2\frac {it^3\sqrt p}{2n(1-)\sqrt {n(1-p)}} = o(n^{-1}).\]
		Donc, on peut simplifier en~:
		\begin{align*}
			\alpha - \frac {\alpha^2}2 &= i\frac {t\sqrt p}{\sqrt{n(1-p)}} - \frac {t^2}{2n(1-p)} + o(n^{-1}) - \frac {i^2t^2p}{2n(1-p)} + o(n^{-1}) \\
			                           &= it\frac {\sqrt p}{\sqrt{n(1-p)}} - \frac {t^2}{2n}\left(\frac 1{1-p} - \frac p{1-p}\right) + o(n^{-1}) \\
			                           &= it\frac {\sqrt p}{\sqrt{n(1-p)}} - \frac {t^2}{2n} + o(n^{-1}).
		\end{align*}

		En remettant cela dans la formule précédente, on obtient~:
		\begin{align*}
			G_{Z_n}(t) &= \exp\left[n\left(it\frac {\sqrt p}{\sqrt{n(1-p)}} - \frac {t^2}{2n} + o(n^{-1})\right)\right]\exp\left(-it\sqrt{\frac {np}{1-p}}\right) \\
			           &= \exp\left[it\sqrt{\frac {np}{1-p}} - \frac {t^2}2 + no(n^{-1})\right]\exp\left(-it\sqrt {\frac {np}{1-p}}\right) \\
			           &= \exp\left(it\sqrt{\frac {np}{1-p}}\right)\exp\left(-\frac {t^2}2\right)\exp(no(n^{-1}))\exp\left(-it\sqrt {\frac {np}{1-p}}\right) \\
					   &= \exp\left(-\frac {t^2}2 + no(n^{-1})\right).
		\end{align*}

		Or, on a~:
		\[\exp\left(-\frac {t^2}2 + no(n^{-1})\right) \stackrel{n \to +\infty}\to \exp\left(-\frac {t^2}2\right) = G_{\Nzu}.\]

		De là, par Lévy, on sait que $\E(\exp(itZ_n)) \stackrel{n \to +\infty}\to \E(\exp(it\Nzu))$, ce qui implique $Z_n \convl \Nzu$.

		\begin{flushright} $\square$ \end{flushright}
		\end{ex}

\newpage
\section{Conditionnement et indépendance}
	\subsection{Événements indépendants}
		\begin{déf} Soir $\Ofp$ un espace de probabilités. Soit $A \in \mathcal F$ un événement de probabilité non-nulle. On note~:
		\[\P_A : \mathcal F \to [0, 1] : B \mapsto \frac {\P(A \cap B)}{\P(A)}\]
		la \emph{probabilité conditionnelle selon $A$}. \end{déf}

		\begin{rmq} Les deux notations suivantes~: $\P(B | A)$ et $\P_A(B)$ sont strictement équivalentes. \end{rmq}

		\begin{prp} La fonction $\P_A$ définit une probabilité sur $(\Omega, \mathcal F)$. \end{prp}

		\begin{thm}[Formule de Bayes] Soit $\Ofp$ un espace de probabilité, et soient $A, B \in \mathcal F$ deux événements de probabilité non nulle. Alors~:
		\[\P(B | A) = \frac {\P(B)}{\P(A)}\P(A | B).\]
		\end{thm}

		\begin{thm}[Formule des probabilités totales] Soit $A \in \mathcal F$ un événement tel que $0 < \P(A) < 1$. Alors, pour tout $B \in \mathcal F$, on a~:
		\[\P(B) = \P(A)\P(B|A) + \P(A^\complement)\P(B|A^\complement).\]
		\end{thm}

		\begin{déf} Soient $A, B \in \mathcal F$ deux événements tels que $\P(A), \P(B) \in (0, 1)$. On dit que $A$ et $B$ sont indépendants si~:
		\[\P(B|A) = \P(B)\qquad\qquad\text{et}\qquad\qquad\P(A|B)=\P(A).\]
		La notation usuelle est $A \sqcup B$.
		\end{déf}

		\begin{rmq} Deux événements $A$ et $B$ sont indépendants si et seulement si~:
		\[\P(A \cap B) = \P(A)\P(B).\]
		Cela permet d'étendre la notion d'indépendance à tout $\mathcal F$. \end{rmq}

		\begin{déf} Soit $\{A_i\}_{1 \leq i \leq n} \subset \mathcal F$ une famille d'événements. On dit que les $A_i$ sont \emph{mutuellement indépendants} si~:
		\[\forall k \in \N, 1 \leq i_1 < \dotsb < i_k \leq n : \P\left(\bigcap_{j=1}^kA_{i_j}\right) = \prod_{j=1}^k\P(A_{i_j}).\]
		\end{déf}

		\begin{ex} Pour $n=3$, on a $A, B, C \in \mathcal F$. Si~:
		\begin{itemize}
			\item[$(i)$] $\P(A \cap B) = \P(A)\P(B)$~;
			\item[$(ii)$] $\P(A \cap C) = \P(A)\P(C)$~;
			\item[$(iii)$] $\P(B \cap C) = \P(B)\P(C)$~;
			\item[$(iv)$] $\P(A \cap B \cap C) = \P(A)\P(B)\P(C)$,
		\end{itemize}
		alors $A$, $B$, et $C$ sont mutuellement indépendantes.
		\end{ex}

		\begin{déf} Soit $\{A_i\} \subset \mathcal F$ une famille d'événements. On dit que les $A_i$ sont indépendants deux à deux si~:
		\[\forall i \neq j : \P(A_i \cap A_j) = \P(A_i)\P(A_j).\]
		\end{déf}

		\begin{rmq} On remarque que l'indépendance mutuelle implique l'indépendance deux à deux, mais que la réciproque est fausse. \end{rmq}

	\subsection{Variables aléatoires indépendantes}
		\begin{déf} Soient $X, Y$ deux variables aléatoires. On dit que $X$ et $Y$ sont indépendantes si~:
		\[\forall A, B \in \mathcal B(\R) : \P\left[(X \in A) \cap (Y \in B)\right] = \P(X \in A)\P(Y \in B).\]
		\end{déf}

		\begin{déf} Soient $\{X_i\}_{1 \leq i \leq n}$ des variables aléatoires réelles. On dit que les $X_i$ sont mutuellement indépendants si les événements
		$\{X_i \in A_i\}$ sont mutuellement indépendants $\forall \{A_i\}_{i \in I} \subset \mathcal B(\R)$. \end{déf}

	\subsection{Formules de convolution}
		\subsubsection{Cas discret}
		Soient $X, Y$ deux variables aléatoires à valeurs dans $\N$. On suppose $X \sqcup Y$. On a donc~:
		\[\forall \omega \in \Omega : X(\omega) \in \N \ni Y(\omega),\]
		ce qui implique~:
		\[(X+Y)(\omega) \in \N.\]

		On doit calculer $\P(X+Y = n)$ avec $n \in \N$. On remarque que~:
		\[\{X+Y = n\} = \bigcup_{k=0}^n\left(\{X = k\} \cap \{Y = n-k\}\right),\]
		qui est une union disjointe. On peut donc y appliquer l'axiomatique des probabilités~:
		\[\P(X+Y = n) = \P\left(\bigcup_{k=0}^n\left(\{X=k\} \cap \{Y = n-k\}\right)\right) = \sum_{k=0}^n\P(\{X = k\} \cap \{Y = n-k\}).\]
		Or, par indépendance (supposée par hypothèse) de $X$ et $Y$, on peut encore séparer la probabilité~:
		\[\P(X+Y = n) = \sum_{k=0}^n\P(X=k)\P(Y=n-k).\]

		\begin{prp}[Formule de convolution discrète] Soient $X, Y$ deux v.a.d. indépendantes, alors~:
		\begin{equation}\label{eq:convdisc}
			\forall n \in \N : \P(X+Y=n) = \sum_{k=0}^n\P(X=k)\P(Y=n-k).
		\end{equation}
		\end{prp}

		\begin{ex}[Somme indépendante de poissons] Soient $X_1, X_2$ deux variables aléatoires de loi respective $\mathcal P(\lambda_1)$ et $\mathcal P(\lambda_2)$.
		On calcule, par la formule~\eqref{eq:convdisc}~:
		\begin{align*}
			\P(X_1+X_2 = n) &= \sum_{k=0}^n\P(X_1=k)\P(X_2=n-k) = \sum_{k=0}^n\exp(-\lambda_1)\frac {\lambda_1^k}{k!}\exp(-\lambda_2)\frac {\lambda_2^{n-k}}{(n-k)!} \\
			                &= \exp(-\lambda_1-\lambda_2)\sum_{k=0}^n\frac {n!}{n!}\frac {\lambda_1^k\lambda_2^{n-k}}{k!(n-k)!} \\
							&= \exp\left(-(\lambda_1+\lambda_2)\right)\frac 1{n!}\sum_{k=0}^n\binom nk\lambda_1^k\lambda_2^{n-k} \\
							&= \exp\left(-(\lambda_1+\lambda_2)\right)\frac 1{n!}(\lambda_1 + \lambda_2)^n.
		\end{align*}

		On a donc $X+y \sim \mathcal P(\lambda_1 + \lambda_2)$. Cela se note~:
		\[\mathcal P(\lambda_1) + \mathcal P(\lambda_2) = \mathcal P(\lambda_1+\lambda_2).\]
		\end{ex}

		\begin{déf} Soient $X_1, X_2$ deux variables aléatoires de même loi, paramétrisés respectivement par le vecteur $\theta_1$ et $\theta_2$. Donc
		$X_1 \sim \mathcal L(\theta_1)$, et $X_2 \sim \mathcal L(\theta_2)$. Si $X_1 + X_2$ est de même loi, paramétrisé par une transformation de $\theta_1$
		et $\theta_2$, on dit que la somme est \emph{interne}~:
		\[(X_1 \sim \mathcal L(\theta_1)) \land (X_2 \sim \mathcal L(\theta_2)) \Rightarrow (X_1 + X_2) \sim \mathcal L(F(\theta_1, \theta_2)) \iff + \text{ interne},\]
		où $F$ est une fonction quelconque. \end{déf}

		\begin{rmq} Une réciproque a été montrée dans les années 1930 par Raïkov~: Soit $X \sim \mathcal P(\lambda)$. Supposons qu'il existe $Y, Z$ indépendantes
		telles que $X = Y+Z$. Alors il existe $\mu \in (0, \lambda)$ tel que $Y = \mathcal P(\mu)$ et $Z = \mathcal P(\lambda-\mu)$. \end{rmq}

		\begin{thm}[Formule de Chu-Vanermonde] Soient $\alpha, \beta, n \in \N$ tels que $\alpha + \beta \geq n$. Alors~:
		\begin{equation}\label{eq:chu-vdm}
			\sum_{k=0}^n\binom \alpha k\binom \beta{n-k} = \binom {\alpha+\beta}n.
		\end{equation}
		\end{thm}

		\begin{ex}[Somme indépendante de binomiales]\label{ex:sommeindébinom} Soient $X \sim \mathcal B(\alpha, p)$, et $Y \sim \mathcal B(\beta, p)$ deux
		binomiales de paramètre $p$. On calcule $\P(X+Y = n)$ :
		\[\P(X+Y = n) = \sum_{k=0}^n\binom \alpha kp^k(1-p)^{\alpha-k}\binom \beta{n-k}p^{n-k}(1-p)^{\beta-n+k}
		= p^n(1-p)^{\alpha+\beta-n}\sum_{k=0}^n\binom \alpha k\binom \beta{n-k},\]
		où par la formule de Vandermonde (\eqref{eq:chu-vdm}), la somme de coefficients binomiaux est le coefficient binomial suivante~: $\binom {\alpha+\beta}n$.
		On a donc~:
		\[\P(X+Y = n) = \binom {\alpha+\beta}np^n(1-p)^{\alpha+\beta-n},\]
		ou encore~:
		\[\mathcal B(\alpha, p) + \mathcal B(\beta, p) = \mathcal B(\alpha+\beta, p).\]
		\end{ex}

		\begin{rmq} L'exemple~\ref{ex:sommeindébinom} peut également se montrer par une somme de $N$ variables indépendantes de Bernoulli $\mathcal B(p)$.
		\end{rmq}

		\subsubsection{Cas absolument continu}
		Soient $X, Y$ deux v.a. réelle de densité respective $f_X$ et $f_Y$. On a donc~:
		\[\P(X+Y \leq x) = \P(X \leq x - Y).\]
		En intégrant cette valeur selon les valeurs prises par $y$, on obtient~:
		\[\P(X+Y \leq x) = \int_\R \P(X \leq x - Y)f_Y(y)\dif y.\]
		On dérive ensuite (formellement, sous l'intégrale) afin d'obtenir~:
		\[\pd {}x\P(X+Y \leq x) = \pd {}x\int_\R \P(X \leq x - y)f_Y(y)\dif y = \int_\R f_X(x-y)f_Y(y)\dif y.\]

		\begin{prp}[Formule de convolution absolument continue] Soient $X, Y$ deux variables aléatoires réelles à densité respective $f_X$ et $f_Y$. Alors~:
		\begin{equation}\label{eq:convabscont}
			f_{X+Y}(x) = \int_\R f_X(x-y)f_Y(y)\dif y.
		\end{equation}
		\end{prp}

		\begin{ex}[Somme indépendante de normales] Soient $X_1 \sim \mathcal N(0, \sigma_1^2)$ et $X_2 \sim \mathcal N(0, \sigma_2^2)$. Par la
		formule~\eqref{eq:convabscont}, on obtient~:
		\begin{align*}
			f_{X+Y}(x) &= \int_\R f_X(x-y)f_Y(y)\dif y
			= \int_\R\frac 1{\sqrt{2\pi}\sigma_1}\exp\left(-\frac {(x-y)^2}{2\sigma_1^2}\right)\frac 1{\sqrt {2\pi}\sigma_2}\exp\left(-\frac {y^2}{2\sigma_2^2}\right)\dif y \\
			&= \frac 1{2\pi\sigma_1\sigma_2}\int_\R\exp\left(-\frac {x^2+y^2-2xy}{2\sigma_1^2}\right)\exp\left(-\frac {y^2}{2\sigma_2^2}\right)\dif y \\
			&= \frac {\exp\left(-\frac {x^2}{2\sigma_1^2}\right)}{2\pi\sigma_1\sigma_2}\int_\R\exp\left(-\frac {y^2}2\left(\frac 1{\sigma_1^2} + \frac 1{\sigma_2^2}\right)+ \frac {xy}{\sigma_1^2}\right)\dif y \\
			&= \frac {\exp\left(-\frac {x^2}{2\sigma_1^2}\right)}{2\pi\sigma_1\sigma_2}\int_\R\exp\left(-\frac 1{2\sigma_1^2\sigma_2^2}\left(y^2(\sigma_1^2 + \sigma_2^2) - 2xy\sigma_2^2\right)\right)\dif y.
		\end{align*}

		On cherche ensuite à faire apparaître un carré parfait dans l'exponentielle dans l'intégrale. Pour cela, on cherche $\alpha, \beta \in \N$ tels que
		\[\alpha^2 - 2\alpha\beta = y^2(\sigma_1^2 + \sigma_2^2) - 2xy\sigma_2^2.\]
		Pour cela, on trouve~:
		\[\alpha = y\sqrt{\sigma_1^2 + \sigma_2^2}.\]
		Dès lors, on sait~:
		\[-2xy\sigma_2^2 = -2\alpha\beta = -2y\sqrt{\sigma_1^2 + \sigma_2^2}\beta,\]
		ou encore~:
		\[\beta = \frac {x\sigma_2^2}{\sqrt{\sigma_1^2 + \sigma_2^2}}.\]
		Dès lors, on peut réécrire la densité de $X+Y$ comme~:
		\begin{align*}
			f_{X+Y}(x) &= \frac {\exp\left(-\frac {x^2}{2\sigma_1^2}\right)}{2\pi\sigma_1\sigma_2}\int_\R\exp\left(-\frac 1{2\sigma_1^2\sigma_2^2}(\alpha-\beta)^2 + \frac {\beta^2}{2\sigma_1^2\sigma_2^2}\right) \\
			           &= \frac {\exp\left(-\frac {x^2}{2\sigma_1^2}\right)}{2\pi\sigma_1\sigma_2}\int_\R\exp\left(-\frac 1{2\sigma_1^2\sigma_2^2}(\alpha-\beta)^2 + \frac {x^2\sigma_2^4}{2\sigma_1^2\sigma_2^2(\sigma_1^2 + \sigma_2^2)}\right) \\
			           &= \frac {\exp\left(-\frac {x^2}{2\sigma_1^2}\right)}{2\pi\sigma_1\sigma_2}\exp\left(\frac {x^2\sigma_2^2}{2\sigma_1^2(\sigma_1^2 + \sigma_2^2)}\right)\int_\R\exp\left(-\frac {(\alpha-\beta)^2}{2\sigma_1^2\sigma_2^2}\right)\dif y.
		\end{align*}

		On remarque~:
		\begin{align*}
			\Delta &\coloneqq \exp\left(-\frac {x^2}{2\sigma_1^2}\right)\exp\left(\frac {x^2\sigma_2^2}{2\sigma_1^2(\sigma_1^2 + \sigma_2^2)}\right) \\
			       &= \exp\left(-\frac {x^2}{2\sigma_1^2}\left(1 - \frac {\sigma_2^2}{\sigma_1^2 + \sigma_2^2}\right)\right) \\
			       &= \exp\left(-\frac {x^2}{2\sigma_1^2}\left(\frac {\sigma_1^2 + \sigma_2^2 - \sigma_2^2}{\sigma_1^2 + \sigma_2^2}\right)\right) \\
			       &= \exp\left(-\frac {x^2}{2\sigma_1^2}\frac {\sigma_1^2}{\sigma_1^2 + \sigma_2^2}\right) \\
			       &= \exp\left(-\frac {x^2}{2(\sigma_1^2 + \sigma_2^2)}\right).
		\end{align*}

		Dès lors, on peut réécrire~:
		\[f_{X+Y}(x) = \frac {\exp\left(-\frac {x^2}{2(\sigma_1^2 + \sigma_2^2)}\right)}{2\pi\sigma_1\sigma_2}\int_\R\exp\left(-\frac {(\alpha-\beta)^2}{2\sigma_1^2\sigma_2^2}\right)\dif y.\]

		En posant~:
		\[\xi \coloneqq \frac {\alpha-\beta}{\sigma_1\sigma_2},\]
		on a également~:
		\[\dif\xi \coloneqq \frac {\sqrt {\sigma_1^2 + \sigma_2^2}}{\sigma_1\sigma_2}\dif y,\]
		et on peut intégrer~:
		\begin{align*}
			f_{X+Y}(x) &= \frac {\exp\left(\frac {x^2}{2(\sigma_1^2 + \sigma_2^2)}\right)}{2\pi\sigma_1\sigma_2}\int_\R\exp\left(-\frac {\xi^2}2\right)\dif \xi\frac {\sigma_1\sigma_2}{\sqrt{\sigma_1^2 + \sigma_2^2}} \\
			           &= \frac 1{\sqrt {2\pi}\sqrt{\sigma_1^2+\sigma_2^2}}\exp\left(-\frac {x^2}{2(\sigma_1^2 + \sigma_2^2)}\right).
		\end{align*}

		On retrouve finalement $f_{X+Y}(x) = \mathcal N(0, \sqrt{\sigma_1^2+\sigma_2^2})$. On peut en conclure que la gaussienne est stable par l'addition~:
		\[\mathcal N(0, \sigma_1) + \mathcal N(0, \sigma_2) = \mathcal N(0, \sqrt{\sigma_1^2+\sigma_2^2}).\]
		\end{ex}

		\subsubsection{Application de la formule de convolution}
		On suppose $X \sim \Gamma_t$ et $Y \sim \Gamma_s$ deux v.a. réelles indépendantes. On sait~:
		\[\displaystyle \begin{cases}f_X(x) &= \frac 1{\Gamma(t)}x^{t-1}\exp(-x)1_{\{x > 0\}}, \\f_Y(x) &= \frac 1{\Gamma(s)}x^{s-1}\exp(-x)1_{\{x > 0\}}.\end{cases}\]
		Montrons que la somme de Gamma est interne.

		\begin{déf} On définit l'intégrale abélienne de seconde espèce $B(t, s)$ par~:
		\[B(t, s) \coloneqq \int_0^1(1-z)^{t-1}z^{s-1}\dif z.\]
		\end{déf}

		\begin{rmq} L'intégrale abélienne $B(t, s)$ est une généralisation de~:
		\[\int_0^1(1-z)^{t-1}\dif z = \frac 1t\qquad\qquad\text{ et }\qquad\qquad\int_0^1z^{s-1}\dif z = \frac 1s.\]
		\end{rmq}

		\begin{prp} La somme indépendante de $X \sim \Gamma_t$ et $Y \sim \Gamma_s$ est une $\Gamma_{t+s}$. \end{prp}

		\begin{proof} Par la formule de convolution continue~\eqref{eq:convabscont}, on a~:
		\[f_{X+Y}(x) = \int_0^x\left(\frac {(x-y)^{t-1}}{\Gamma(t)}\exp(y-x)\right) \left(\frac {x^{s-1}}{\Gamma(s)}\exp(-y)\right)\dif y
		= \frac {\exp(-x)}{\Gamma(s)\Gamma(t)}\int_0^x(x-y)^{t-1}y^{s-1}\dif y.\]

		On pose ensuite $y \coloneqq xz$, et donc $\dif y = x \dif z$. En substituant, on obtient~:
		\[f_{X+Y}(x) = \frac {\exp(-x)}{\Gamma(t)\Gamma(s)}\int_0^1(x-xz)^{t-1}(xz)^{s-1}x\dif z = \frac {\exp(-x)}{\Gamma(t)\Gamma(s)}x^{(t-1)+(s-1)+1}\int_0^1(1-z)^{t-1}z^{s-1}\dif z.\]

		On pose~:
		\[\Psi \coloneqq \frac 1{\Gamma(t)\Gamma(s)}B(t, s).\]
		On a donc~:
		\[f_{X+Y}(x) = \Psi x^{t+s-1}\exp(-x).\]
		Étant donné que $f_{X+Y}$ est une fonction de densité, on peut imposer~
		\[1 = \int_\R f_{X+Y}(x)\dif x = \Psi \int_0^{+\infty}x^{t+s-1}\exp(-x) = \Psi \Gamma(t+s).\]
		On en déduit alors~:
		\[\Psi = \frac 1{\Gamma(t+s)}.\]
		En replaçant $\Psi$ dans l'équation de $f_{X+Y}$, on obtient~:
		\[f_{X+Y}(x) = \frac 1{\Gamma(t+s)}\exp(-x)x^{t+s-1}.\]
		Ce qui prouve que $f_{X+Y} = f_{\Gamma(t+s)}$.
		\end{proof}

		\begin{rmq} On peut trouver une valeur pour $B(t, s)$ étant donné que~:
		\[\frac {B(t, s)}{\Gamma(t)\Gamma(s)} = \Psi = \frac 1{\Gamma(t+s)},\]
		on détermine~:
		\[B(t, s) = \frac {\Gamma(t)\Gamma(s)}{\Gamma(t+s)}.\]

		On a donné une \emph{preuve probabiliste} du calcul exact de $B(t, s)$. La preuve \emph{classique} repose sur de l'intégration curviligne complexe
		(c.f. cours d'analyse de Dieudonné) et est beaucoup plus longue.
		\end{rmq}

		\begin{rmq} Il a été mentionné plus haut que $B(t, s)$ est une généralisation de deux intégrales abéliennes séparées. On observe en réalité~:
		\begin{itemize}
			\item $B(1, s) = \frac {\Gamma(1)\Gamma(s)}{\Gamma(s+1)} = \frac {\Gamma(s)}{s\Gamma(s)} = \frac 1s$~;
			\item $B(t, 1) = \frac {\Gamma(t)\Gamma(1)}{\Gamma(t+1)} = \frac {\Gamma(t)}{t\Gamma(t)} = \frac 1t$~;
			\item $B(0.5, 0.5) = \frac {\Gamma(0.5)^2}{\Gamma(1)} = \frac {\sqrt \pi^2}1 = \pi$ (intégrale de Gauss pour $\Gamma(0.5) = \sqrt \pi$).
		\end{itemize}

		On sait cependant que~:
		\[\int_\R f_{\Gamma_t+\Gamma_s}(x) = \frac 1{\Gamma(t+s)}\int_0^1(1-z)^{t-1}z^{s-1}\dif z.\]
		En prenant $t = s = \frac 12$, on peut déterminer~:
		\[1 = \frac 1{\Gamma\left(\frac 12 + \frac 12\right)}\int_0^1(1-z)^{\frac 12}z^{\frac 12}\dif z = \frac 1\pi\int_0^1\frac {\dif z}{\sqrt {z(1-z)}}.\]

		On peut donc définir une nouvelle densité de probabilité~:
		\[z \mapsto \frac {1}{\pi\sqrt{z(1-z)}}1_{(0, 1)}(z).\]

		Effectivement, on peut poser $u^2 = z$ (et donc $\dif z = 2u\dif u$), ce qui permet d'écrire~:
		\[\frac 1\pi\int_0^1\frac {2u\dif u}{\sqrt {u^2(1-u^2)}} = \frac 2\pi\int_0^1\frac {\dif u}{\sqrt {1-u^2}} = \frac 2\pi\left[\arcsin(u)\right]_0^1
		= \frac 2\pi\frac \pi 2 = 1,\]
		qui donne donc bien une probabilité.
		\end{rmq}
	
	\subsection{Indépendance et fonctions caractéristiques}
		\begin{prp} Soit $X$ une variable aléatoire à valeurs dans un ensemble $E$. Soit $A \subseteq E$. Alors $\E(1_A(X)) = \P(X \in A)$. \end{prp}

		\begin{proof} Commençons par le cas discret. Soient $E = \{x_n\}_{n \in I}$ et $X$ une v.a.d. à valeurs dans $E$. On sait alors~:
		\[\P(X \in A) = \sum_{x_n \in A}\P(X = x_n) = \sum_{x_n \in A}1 \cdot \P(X = x_n) + \sum_{x_n \not \in A}0 \cdot \P(X=x_n)
		= \sum_{x \in E}1_A(x)\P(X=x_n) = \E(1_A(X)).\]

		Intéressons-nous maintenant au cas absolument continu. Soient $E \subset \R$ et $X$ une v.a.c. de densité $f_X(x)$. On sait alors~:
		\[\P(X \in A) = \int_Af_X(x)\dif x = \int_\R 1_A(x)f_X(x)\dif x = \E(1_A(X)).\]
		\end{proof}

		\begin{thm} Soient $X, Y$ deux variables aléatoires à valeurs respectivement dans $A$ et $B$. Alors~:
		\[X \sqcup Y \iff \E\left(1_A(X)1_B(Y)\right) = \E(1_A(X))\E(1_B(Y)).\]
		\end{thm}

		\begin{rmq} Prenons $A_1, \dotsc, A_n, B_1, \dotsb, B_m \in \mathcal B(\R)$ et $\lambda_1, \dotsb, \lambda_n, \mu_1, \dotsb, \mu_m \in \R$.
		On pose ensuite~:
		\begin{align*}
			f_n(x) &= \sum_{i=1}^n\lambda_i1_{A_i}(x), \\
			g_m(y) &= \sum_{j=1}^m\mu_j1_{B_j}(y).
		\end{align*}
		Par linéarité, on trouve alors~:
		\begin{equation}\label{eq:esp(fg)=esp(f)esp(g)}
			\E\left(f_n(X)g_m(Y)\right) = \E(f_n(X))\E(g_m(Y)).
		\end{equation}
		\end{rmq}

		\begin{thm} Toute fonction $f$ mesurable (au sens où $\forall A \in \mathcal B(\R) : f^{-1}(A) \in \mathcal B(\R)$) et bornée est limite monotone de
		fonctions étagées, c'est-à-dire des fonctions du type~:
		\[\sum_{i=1}^n\lambda_i1_{A_i}(x).\]
		\end{thm}

		\begin{thm}[Principe de convergence monotone] En passant à la limite pour $n, m \to +\infty$ dans~\eqref{eq:esp(fg)=esp(f)esp(g)}, on a~:
		\begin{equation}\label{eq:caractfonctind}
			\forall f, g \text{ mesurables bornées }, X, Y \text{ v.a. } : X \sqcup Y \iff \E(f(X)g(Y)) = \E(f(X))\E(g(Y)).
		\end{equation}
		\end{thm}

		\begin{rmq} On dit que~\eqref{eq:caractfonctind} est la \emph{caractérisation fonctionnelle de l'indépendance}. \end{rmq}

		\begin{thm}[Théorème de Lévy]\label{thm:Lévyindé} Soient $X, Y$ deux v.a. réelles. Alors~:
		\[\forall t \in \R : X \sqcup Y \iff \E(\exp(itX+Y)) = \E(\exp(itX))\E(\exp(itY)).\]
		\end{thm}

		\begin{rmq} Le théorème~\ref{thm:Lévyindé} est un cas particulier du principe de convergence monotone où la classe des fonctions mesurables bornées
		a été réduite à $f(x) = g(x) = \exp(itx)$. \end{rmq}

		\begin{ex}[Application de Lévy à deux Gamma] Soient $X \sqcup Y$ telles que $X \sim \Gamma_t$ et $Y \sim \Gamma_s$. Soit $z \in \R$, on calcule~:
		\[\E(\exp(iz\Gamma_t)) = \int_0^{+\infty}\exp(izu)\exp(-u)u^{t-1}\frac {\dif u}{\Gamma(t)} = \int_0^{+\infty}\exp(u(1-iz))u^{t-1}\frac {\dif u}{\Gamma(t)}.\]

		On pose ensuite $v \coloneqq u(1-iz)$, et donc $\dif v = (1-it)\dif u$. Ce qui amène~:
		\[\E(\exp(it\Gamma_t)) = \int_0^{+\infty}\exp(-v)\frac {v^{t-1}}{(1-iz)^{t-1}}\frac {\dif v}{\Gamma(t)}
		= \frac 1{(1-iz)^t}\int_0^{+\infty}\exp(-v)\frac {v^{t-1}\dif v}{\Gamma(t)} = \frac 1{(1-iz)^t}.\]

		De manière similaire, on obtient~:
		\[\E(\exp(iz\Gamma_s)) = \frac 1{(1-iz)^s}.\]
		Et également~:
		\[\E(\exp(iz\Gamma_{t+s})) = \frac 1{(1-iz)^{t+s}} = \frac 1{(1-iz)^t}\frac 1{(1-iz)^s} = \E(\exp(iz\Gamma_t))\E(\exp(iz\Gamma_s)).\]

		Les fonctions caractéristiques caractérisent les lois, on a donc~:
		\[\Gamma_t + \Gamma_s \stackrel {\mathcal D}= \Gamma_{t+s}.\footnote{Ce qui est un résultat déjà obtenu plus haut.}\]
		\end{ex}

	\subsection{Lien entre indépendance et De Moivre-Laplace}
		\paragraph{Rappel et topo} Si $X_{n, p} \sim \mathcal B(n, p)$, on a vu que De Moivre-Laplace implique pour $n \to +\infty$~:
		\[\frac {X_{n, p} - np}{\sqrt{np(1-p)}} \stackrel {\mathcal D}\leftrightarrow \Nzu.\]

		On sait également que~:
		\[X_{n, p} = \sum_{i=1}^nX_p^{(i)},\]
		où les $X_p^{(i)} \sim \mathcal B(p)$ sont des Bernoulli de paramètre $p$. L'espérance et la variance peuvent être aisément déterminées~:
		\[\begin{cases}\E(X_p^{(i)}) &= p, \\\Var(X_p^{(i)}) &= p(1-p).\end{cases}\]
		On a donc~:
		\[\frac {\sum_{i=1}^nX_p^{(i)}-n\E(X_p^{(1)})}{\sqrt {n\Var(X_p^{(1)})}} \convl \Nzu.\]

		Le but est donc de généraliser ce résultat.

		\begin{thm}[Théorème central limite (TCL)] Soit $X \in \Ld$ une v.a. réelle. On pose $\mu \coloneqq \E(X)$ et $\sigma^2 \coloneqq \Var(X)$.
		Soient $\{X_i\}_{1 \leq i \leq n}$ des variables aléatoires mutuellement indépendantes de même loi. Alors~:
		\[\frac {S_n - n\mu}{\sigma\sqrt n} \stackrel{n \to +\infty}\to \Nzu,\]
		où $S_n = X_1 + X_2 + \dotsb X_n$.
		\end{thm}

		\begin{proof} On pose~:
		\[\varphi_n(t) \coloneqq \E\left(\exp\left(it\frac {S_n - n\mu}{\sigma\sqrt n}\right)\right).\]
		On sait que $\E(it\Nzu) = \exp\left(-\frac {t^2}2\right)$. Par linéarité de l'espérance, on a~:
		\[\varphi_n(t) = \exp\left(\frac {-it\mu\sqrt n}\sigma\right)\E\left(\frac {itS_n}{\sigma\sqrt n}\right)
		= \exp\left(\frac {-it\mu\sqrt n}\sigma\right)\prod_{j=1}^n\E\left(\exp\left(\frac {it}{\sigma\sqrt n}X_j\right)\right).\]
		Or, tous les $X_j$ ont la même loi. Dès lors~:
		\[\varphi_n(t) = \exp\left(\frac {-it\mu\sqrt n}\sigma\right)\left(\exp\left(\frac {it}{\sigma\sqrt n}X_1\right)\right)^n.\]

		On observe que~:
		\[\forall u \in \R : \abs{\exp(iu) - 1 + iu - \frac {u^2}2} \leq u^2\min\{u, 1\}.\]
		Donc en posant $\psi(u) \leq u^2\min\{u, 1\}$, on peut trouver $\psi$ tel que~:
		\[\exp(iu) = 1 + iu - \frac {u^2}2 + \psi(u).\]
		Et donc~:
		\begin{align*}\E\left(\exp\left(it\frac {X_1}{\sigma \sqrt n}\right)\right)
		 &= \left[1 + \frac {it\mu}{\sigma\sqrt n} - \frac {t^2\E(X_1^2)}{2\sigma^2n} + \psi\left(\frac {tX_1}{\sigma \sqrt n}\right)\right]^n \\
		 &= \left[1 + \frac {it\mu}{\sigma\sqrt n} - \frac {t^2(\E(X_1)^2 + \Var(X_1))}{2\sigma^2n} + \psi\left(\frac {tX_1}{\sigma \sqrt n}\right)\right]^n \\
		 &= \left[1 + \frac {it\mu}{\sigma\sqrt n} - \frac {t^2\mu^2}{2\sigma^2n} - \frac {t^2}{2n} + \psi\left(\frac {tX_1}{\sigma \sqrt n}\right)\right]^n
		\end{align*}
		
		En posant~:
		\[\alpha \coloneqq \frac {it\mu}{\sigma\sqrt n} - \frac {t^2\mu^2}{2\sigma^2n} - \frac {t^2}{2n} + \psi\left(\frac {tX_1}{\sigma \sqrt n}\right),\]
		on peut déterminer~:
		\[\E\left(\exp\left(it\frac {X_1}{\sigma\sqrt n}\right)\right) = \exp\left(n\log(1 + \alpha)\right).\]
		On détermine~:
		\[n\log(1 + \alpha) = n\alpha - \frac {n\alpha^2}2 + no(\alpha^3).\]
		En regroupant tous les termes en $o(n^{-\frac 12})$, on trouve~:
		\begin{align*}
			n\log(1 + \alpha) &= n\left[\frac {it\mu}{\sigma\sqrt n} - \frac {t^2\mu^2}{2\sigma^2n} - \frac {t^2}{2n} - \frac {(it\mu)^2}{2\sigma^2n} + \psi\left(\frac {tX_1}{\sigma \sqrt n}\right) + o(n^{-\frac 12})\right] \\
			&= \left[\frac {it\mu\sqrt n}\sigma - \frac {t^2}2 + n\psi\left(\frac {tX_1}{\sigma\sqrt n} + no(n^{-\frac 12})\right)\right].
		\end{align*}

		On retrouve alors~:
		\[\varphi_n(t) = \exp(n\log(1 + \alpha)) = \exp\left(-\frac {t^2}2 + o(n^{-\frac 12})\right)\E\left(\exp\left(in\psi\left(\frac {tX_1}{\sigma \sqrt n}\right)\right)\right).\]

		Et on sait que~:
		\[\beta \coloneqq \abs{n\psi\left(\frac {tX_1}{\sigma\sqrt n}\right)} \leq \frac {t^2X_1^2}{\sigma^2}\min\left\{1, \frac {tX_1}{\sigma\sqrt n}\right\} \stackrel {n \to +\infty}\to 0,\]
		ce qui fait tendre l'espérance de $\exp(\beta)$ vers 1, il reste donc~:
		\[\varphi_n(t) = \exp\left(-\frac {t^2}2 + o(n^{-\frac 12})\right) \stackrel {n \to +\infty}\to \exp\left(-\frac {t^2}2\right).\]

		On voit bien que $\varphi_n(t)$ tend vers la fonction caractéristique d'une $\Nzu$ et donc, par Lévy (théorème de convergence), on a bien~:
		\[\frac {S_n - n\E(X_1)}{\sqrt {n\Var(X_1)}} \convl \Nzu.\]
		\end{proof}

\end{document}
