\documentclass{article}

\usepackage{palatino, eulervm}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fullpage}
\usepackage[bottom]{footmisc}
\usepackage[parfill]{parskip}
\usepackage{mathtools}
\usepackage{mathdots}
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{commath}
\usepackage{hyperref}

\makeatletter
\def\thm@space@setup{
	\thm@preskip=.4cm%
	\thm@postskip=\thm@preskip%
}
\makeatother

%amsthm
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemme}
\newtheorem{cor}[thm]{Corollaire}
\renewcommand{\proofname}{\it{Preuve}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}

\DeclareMathOperator{\Jac}{Jac}
\DeclareMathOperator{\tq}{t.q.}
\DeclareMathOperator{\fl}{fl}
\DeclareMathOperator{\tr}{tr}

\newcommand{\C}{\mathbb C}
\newcommand{\F}{\mathbb F}
\newcommand{\N}{\mathbb N}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}

\newcommand{\kappaabs}{\kappa_{\text{abs}}}
\newcommand{\algonum}[3]{F_{#1}(#2^{(#1)}, #3^{(#1)})}
\newcommand{\algnum}{\algonum nxd}

\author{R. Petit}
\date{Année académique 2015 - 2016}
\title{INFOF-205 : Calcul formel et numérique}

\begin{document}
\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}

\section{Introduction}
	\begin{déf} Le \emph{calcul numérique} est une discipline qui traite de la définition, l'analyse, et l'implémentation d'algorithmes pour la résolution
	numérique des problèmes mathématiques qui proviennent de la modélisation des phénomènes réels.\footnote{Nick Trefehen, Oxford.}
	\end{déf}

	Le calcul numérique représente donc le triplet (modèle analytique, solution théorique, résolution algorithmique).

	\begin{rmq} Le calcul numérique étant une application informatique pour la résolution de problèmes mathématiques continus, plusieurs types de problèmes
	peuvent arriver (section suivante). Afin de limiter les problèmes de précision sur des fonctions continues compliquées à évaluer précisément informatiquement,
	plusieurs outils d'approximation peuvent être utilisés. Le théorème de Taylor permet d'approcher certaines fonctions de manière plus facilement calculatoires
	de manière informatique.
	\end{rmq}

	\begin{thm}[Théorème de Taylor]\label{thm:Taylor} Soient $f : I \to \R$ où $I$ est un intervalle, $a \in I$ et $k \geq 1$. Alors $T(f, a, k)(x)$ est le seul
	polynôme de degré inférieur ou égal à $k$ tel que~:
	\[\lim_{x \to a}\frac {f(x)-T(f, a, k)}{(x-a)^k} = 0,\]
	où $T(f, a, k)(x)$, appelé \emph{polynôme de Taylor} est défini par~:
	\[T(f, a, k)(x) = \sum_{i=0}^k\frac {f^{(i)}(a)(x-a)^i}{i!}.\]
	\end{thm}

	Le calcul numérique est défini comme étant une application informatique à des problèmes relatifs à des phénomènes réels. Bien souvent, ces phénomènes
	sont modélisés de manière \emph{continue}. Les ordinateurs quant à eux sont \emph{discrets}. Cette différence majeure force des approximations par le matériel
	informatique. Les transformations discrètes (\emph{discrétisations}) des phénomènes réels doivent alors être rigoureusement analysés afin de déterminer leur
	robustesse et leur fiabilité.

	Les problèmes peuvent être classifiés de plusieurs manières selon leurs propriétés et ce qui en est attendu.

	\begin{déf} Un problème est dit~:
	\begin{itemize}
		\item \emph{qualitatif} lorsque le comportement des solutions est étudié afin d'en déterminer sa stabilité, son comportement asymptotique~;
		\item \emph{quantitatif} lorsque la solution (numérique) précise est étudiée afin de tirer des conclusions spécifiques.
	\end{itemize}
	\end{déf}

	Un problème qualitatif cherche des conclusions globales à un problème (étude d'une famille de problèmes) et un problème quantitatif est une application
	précise appliquée à un problème donné.

	\begin{déf} Un problème est dit sous forme~:
	\begin{itemize}
		\item \emph{explicite} quand la solution $x$ d'un problème est une fonction donnée des données $d$~;
		\item \emph{implicite} quand la solution ne peut être extraite explicitement des données.
	\end{itemize}
	\end{déf}

	\begin{ex} \emph{Trouver la racine carrée d'un nombre $d \in \R$} est un problème explicite que l'on peut écrire $x = f(d) = \sqrt d$.

	\emph{Déterminer l'ensemble des solutions $x$ à l'équation $ax^2 + bx + c$} est un problème implicite car la solution n'est pas séparée explicitement des
	données. On peut tout de même exprimer ce problème implicite comme~:
	\[X = \left\{\frac {-b \pm \sqrt {b^2-4ac}}{2a}\right\},\]
	qui est un problème explicite.
	\end{ex}

	\begin{rmq} La forme générale d'un problème explicite est $x = F(d)$, alors que la forme générale d'un problème implicite est $F(x, d) = 0$. \end{rmq}

	\begin{déf} Le problème explicite $x = F(d)$ est dit \emph{bien posé} si la solution $x$~:
	\begin{enumerate}
		\item existe~;
		\item est unique~;
		\item dépend \textbf{continument} de $d$.
	\end{enumerate}

	Si un problème n'est pas bien posé, on dit qu'il est \emph{mal posé}.
	\end{déf}

	\begin{déf} Un problème est dit \emph{problème inverse} s'il correspond à la détermination des données d'entrée $x$ d'une application $G$ en connaissant
	les données de sortie $G(x) \eqqcolon d$.
	\end{déf}

	\begin{rmq} Les problèmes inverses sont de manière générale mal posés, entre autre parce qu'il est fréquent que l'application $G$ ne soit pas injective
	et donc que plusieurs données $x$ peuvent donner la même donnée $d = G(x)$.
	\end{rmq}

	\begin{rmq} Ce cours ne traitera que de problèmes bien posés. \end{rmq}

	\begin{déf}~
	\begin{itemize}
		\item Le \emph{conditionnement} d'un problème $x = F(d)$ bien posé est la mesure de la \emph{sensibilité} de $x$ à des petits changements sur $d$.
		\item On définit par $\delta d$ une faible perturbation (également dite \emph{perturbation admissible}) sur la donnée $d$. On définit alors la
		      perturbation induite sur $x$ par $\delta x = F(d + \delta d) - F(d)$.
		\item Le \emph{conditionnement relatif} du problème est la quantité~:
		      \[\kappa(d) \coloneqq \lim_{\abs D \to 0}\sup_{\delta d \in D} \frac {\norm {\delta x}\norm d}{\norm x\norm{\delta d}}
			  = \lim_{\abs D \to 0}\sup_{\delta \in D}\frac {\norm {F(d + \delta d) - F(d)}\norm d}{\norm {F(d)}\norm {\delta d}},\]
		      où $D$ est un voisinage de l'origine, et $\sup$ désigne la borne supérieure.
	\end{itemize}
	\end{déf}

	\begin{rmq}~
	\begin{itemize}
		\item si $x = 0$, alors le conditionnement relatif est forcément infini~;
		\item si $d = 0$, alors le conditionnement relatif est forcément nul~;
		\item quand $0 \in \{x, d\}$, il faut définir une autre notion, le conditionnement absolu~:
		      \[\kappaabs(d) \coloneqq \lim_{\abs D \to 0}\sup_{\delta d \in D}\frac {\norm {\delta x}}{\norm {\delta d}}.\]
	\end{itemize}
	\end{rmq}

	\begin{prp} Si $x = F(d)$ est un problème explicite, et $F$ est une fonction différentiable en $d$, alors, par définition~:
	\[\lim_{\delta \to 0}\frac {\delta x}{\delta d}\]
	ne dépend pas de la trajectoire de $\delta d$ vers $0$. On note alors~:
	\[F'(d) = \lim_{\delta d \to 0}\frac {\delta x}{\delta d},\]
	et on réécrit le conditionnement par~:
	\[\kappa(d) = \lim_{\delta d \to 0}\frac {\norm {\delta x}\norm d}{\norm {\delta d}\norm x}
	= \frac {\norm d}{\norm x}\lim_{\delta d \to 0}\frac {\norm {\delta x}}{\norm {\delta d}} = \norm {F'(d)}\frac {\norm  d}{\norm x}.\]
	\end{prp}

	\begin{rmq} Si $d \in \R^m$, et $x \in \R^n$, alors $F'(d)$ est la matrice jacobienne $(\Jac F)(d)$. Et si $q = 1$, la matrice jacobienne n'a qu'une seule
	ligne et on parle du gradient $(\nabla F)(d)$
	\end{rmq}

	\begin{ex}[Conditionnement d'une différence] Soit le problème $x = F(d) = d-a$. La fonction $F$ est différentiable, on peut donc déterminer le
	conditionnement~:
	\[\kappa(d) = \norm {F'(d)}\frac {\norm d}{\norm x} = 1\frac {\norm d}{\norm {d-a}}.\]
	On voit alors que le conditionnement est petit pour $\norm {d-a} >> 0$. Cependant, pour $d$ proche de $a$, le conditionnement devient très grand.
	Le problème est donc \emph{mal conditionné} pour $d$ proche de $a$.
	\end{ex}

	\begin{ex}[Conditionnement d'une exponentiation] Soit le problème $x = F(d) = d^r$ avec $r \in \R$. À nouveau, $F$ est différentiable, et donc on peut
	exprimer le conditionnement comme~:
	\[\kappa(d) = \norm {F'(d)}\frac {\norm d}{\norm x} = \norm r\norm {d^{r-1}}\frac {\norm d}{\norm {d^r}} = \norm r.\]
	Le conditionnement dépend donc de l'exposant $r$. Si $r$ est grand, le problème est mal conditionné, peu importe la valeur de $d$.
	\end{ex}

	Le conditionnement d'un problème est une caractéristique qui lui est intrinsèque. Si un problème est mal conditionné, peu importe l'algorithme utilisé pour
	le résoudre, la solution restera fortement influencé par des perturbations sur les données $d$. De plus, plus un problème a un grand conditionnement, plus
	il sera difficile à résoudre numériquement.

	\begin{rmq} les exemples ci-dessus montrent qu'un problème peut avoir un conditionnement faible pour certaines valeurs de $d$ et un conditionnement élevé
	pour d'autres valeurs.
	\end{rmq}

	Soit $F(x, d) = g(x) - d = 0$, un problème implicite. Prenons $g : \R \to \R$ une fonction réelle différentiable. On peut alors exprimer $x = g^{-1}(d)$.
	Donc le conditionnement vaut~:
	\[\kappa(d) = \abs {\frac {(g^{-1})'(d)d}{g^{-1}(d)}} = \abs {\frac 1{g'(g^{-1}(d))}}\abs{\frac d{g^{-1}(d)}} = \abs {\frac 1{g'(x)}}\abs{\frac dx}.\]
	On remarque donc que pour $g'(x)$ petit le conditionnement devient grand. C'est intuitivement lié au fait qu'une fonction à faible dérivée (pente) en $d$
	va croitre lentement et donc pour une faible perturbation sur $d$ (axe vertical), une grande perturbation sur $x$ (axe horizontal) va être induite.

	\begin{déf} Soit $F(x, d) = 0$ un problème bien posé. On définit l'\emph{algorithme numérique} pour la résolution du problème $F$ par la suite de problèmes
	approchés $\algonum 1xd, \algonum 2xd, \dotsc, \algnum$ dépendant d'un paramètre $n$.
	\end{déf}

	L'idée derrière la division en sous-problèmes est d'avoir des $F_k$ plus simples à résoudre que $F$, ce qui permet une résolution numérique.

	\begin{déf} Un algorithme numérique est dit~:
	\begin{itemize}
		\item \emph{direct} si le nombre $n$ de sous-problèmes est fixé (du moins majoré), habituellement par une fonction de la taille du problème~;
		\item \emph{itératif} si $n$ n'est pas borné et s'il existe une routine $f(u)$ admissible, indépendante de $n$ telle que $x^{(n)} = f(x^{(n-1)})$.
	\end{itemize}
	\end{déf}

	\begin{déf} Un algorithme numérique $\{\algonum ixd\}_{1 \leq i \leq n}$ est consistant si~:
	\[\lim_{n \to +\infty}\algnum = F(x, d^{(n)}),\]
	et donc si $x$, la solution précise, est une solution ses sous-problèmes pour $n \to +\infty$.
	\end{déf}

	\begin{rmq} Un algorithme itératif $x^{(n)} = f(x^{(n-1)})$ est consistant si $x^{(n)} = x$ implique que $x^{(n+1)} = x$. Ce qui revient à dire qu'une fois
	la solution exacte atteinte, l'algorithme itératif la conserve et ne diverge pas.
	\end{rmq}

	\begin{déf} Un algorithme $\algnum$ est dit \emph{fortement} consistant si~:
	\[\forall n \geq 1 : F_n(x, d^{(d)}) = 0,\]
	c'est-à-dire si $x$ est une solution admissible de tous les sous-problèmes $\algnum$.
	\end{déf}

	Intéressons-nous au problème $F(x, d)$ et à $\algnum$, un algorithme numérique de résolution du problème. Supposons que cet algorithme numérique soit composé
	d'étapes telles que~:
	\[x^{(n)} = F_n^{(m)}\left(d_{m-1}^{(n)}\right),\]
	où~:
	\[d_{k}^{(n)} = F_n^{(k)}\left(d_{k-1}^{(n)}\right)\qquad\qquad\text{ et }\qquad\qquad d_0^{(n)} = d^{(n)}.\]

	On considère que la résolution numérique est l'application de cet algorithme sur des valeurs perturbées~:
	\[\begin{cases}
		\bar x^{(n)} &= F_m^{(n)}\left(\bar d_{m-1}^{(n)}\right) + \delta d_m^{(n)} \\
		\bar d_k^{(n)} &= F_{k}^{(n)}\left(\bar d_{k-1}^{(n)}\right) + \delta d_k^{(n)} \\
		\bar d_0^{(n)} &= d^{(n)}
	\end{cases}\]

	\begin{rmq} On voit bien que l'algorithme à l'étape $n$ commence avec $\bar d_0^{(n)} = d^{(n)}$ qui est une donnée initiale \emph{non perturbée}. \end{rmq}

	\begin{déf} Soit $\algnum$ un algorithme numérique. On dit qu'il est \emph{stable} (ou \emph{bien posé}) si~:
	\begin{itemize}
		\item $\forall n : \exists! x^{(n)}$, solution~;
		\item \[\forall \epsilon > 0 : \exists \eta > 0, n_0 \in \N^* \tq \forall n > n_0 :
			\left(\forall i \in \{1, \dotsc, m\} : \norm {\delta d_i^{(n)}} < \eta\right) \Rightarrow \left(\norm {\bar x^{(n)}-x^{(n)}} < \epsilon\right).\]
	\end{itemize}
	\end{déf}

	\begin{déf} Si l'opération $F_m^{(n)}(d)$ ne dépend ni de $m$, ni de $n$, on parle d'algorithme \emph{itératif}. \end{déf}

	\begin{rmq} Un algorithme est donc dit itératif si c'est constamment la même opération qui est appliquée sur des données consécutives. On a alors~:
	\[x^{(n)} = f(x^{(n-1)}) = (f \circ f)(x^{(n-2)}) = \dotsb = \left(f^n\right)(x^{(0)}) = \left(f^n\right)(d).\]
	\end{rmq}

	On peut traduire la définition de stabilité de manière plus informelle par le fait qu'un algorithme est stable s'il existe un voisinage de $x$, la solution
	tel que pour tout $x_1, x_2$ dans ce voisinage, on a un $R \in (0, 1)$ tel que~:
	\[\norm {f(x_2)-f(x_1)} \leq R\norm {x_2-x_1}.\]
	Si $f$ est une fonction différentiable, alors on peut dire que~:
	\[\norm {f'(x_2)} \leq R.\]

\newpage
\section{Analyse et mesure d'erreurs}
	\subsection{Définitions}
		\begin{déf} $\F$ est l'ensemble des nombres représentés exactement par un ordinateur. \end{déf}

		\begin{rmq} On remarque aisément que $\F \subset \R$ car $\F \not \subset \C \setminus \R$. On peut tout de même raffiner car il semble évident que
		$\F \subset \Q$~: un nombre irrationnel n'a pas de représentation physique finie, et ne peut donc pas être représentés par un ordinateur.
		\end{rmq}

		\begin{déf} Soit $x$ un nombre dans $\Q$. Une approximation de $x$ est une valeur $\widehat x$ légèrement différente de $x$ et qui remplace $x$ dans les
		calculs effectués. On note également $x \simeq \widehat x$ pour montrer que $\widehat x$ est une approximation de $x$.

		Si $\widehat x < x$, on parle d'approximation par défaut, et si $\widehat x > x$, on parle d'approximation par excès.
		\end{déf}

		\begin{déf} On définit l'\emph{erreur absolue} entre $x$ et son approximation $\widehat x$ par~:
		\[\delta_x = \abs {\widehat x - x}.\]

		On définit également l'\emph{écart relatif} entre $x$ et $\widehat x$ par~:
		\[\rho_x = \frac {\widehat x - x}x.\]

		On définit alors l'écart absolue défini comme $\epsilon_x = \abs {\rho_x}$.
		\end{déf}

		\begin{rmq} L'écart relatif permet d'écrire l'approximation sous la forme $\widehat x = x(1+\rho_x)$ où $\rho_x$ est censé être faible (car l'écart
		entre $x$ et son approximation doit rester relativement faible). Cette notation est fortement utilisée.

		Les écarts ne sont cependant définis qu'en $x \neq 0$, ce dont il faut tenir compte.
		\end{rmq}

		\begin{déf} La \emph{borne supérieure d'erreur relative} d'une approximation $\widehat x$, notée $u$ est nombre positif quelconque tel que
		$u \geq \epsilon_x$.
		\end{déf}

		Mis à part les erreurs de calcul (qui consistent à déterminer un résultat erroné sur base de données bien définies) et les erreurs d'implémentation
		(qui consiste en une implémentation erronée amenant à des erreurs de calcul), il existe cinq catégories d'erreurs que l'on peut regrouper en deux
		familles~:

		\begin{itemize}
			\item les erreurs de modèle qui consistent en simplifier les phénomènes en omettant des éléments afin de le rendre plus facile à étudier~;
			\item les erreurs numériques qui consistent en l'approximation due à l'observation et non à la résolution théorique.
		\end{itemize}

	\subsection[les erreurs numériques]{Les erreurs numériques\footnote{Les erreurs de modélisation ne sont pas traitées ici.}}
		\begin{déf} Les \emph{erreurs de troncature} sont les erreurs liées aux processus théoriques mathématiques infinis (série infinie par exemple).
		\end{déf}

		\begin{déf} Les \emph{erreurs d'arrondi} sont les erreurs liées au système numérique de la machine venant du fait qu'un ordinateur ne peut représenter
		qu'un sous-ensemble fini $\F$ des nombres.
		\end{déf}

		\begin{déf} Les \emph{erreurs de génération et de propagation} sont les erreurs liées à l'évaluation d'une opération sur des opérandes pas exactes.
		\end{déf}

		\begin{rmq} Les erreurs de troncature sont compliquées à éviter~: il est nécessaire d'avoir un procédé fini pour y échapper. Cette catégorie d'erreurs
		ne seront donc pas étudiées dans ce cours.
		\end{rmq}

		Les différents types d'erreurs concernent différentes propriétés des problèmes ou des algorithmes numériques utilisés.

		\begin{prp}~
		\begin{itemize}
			\item Les erreurs d'approximation ou de troncature se mesurent par la \textbf{consistance} de l'algorithme~;
			\item les erreurs de propagation se mesurent par le \textbf{conditionnement} de l'algorithme~;
			\item les erreurs de génération se mesurent par la \textbf{stabilité de l'algorithme}~;
			\item les erreurs d'arrondi sont liées à la représentation interne des nombres.
		\end{itemize}
		\end{prp}

	\subsection{Représentation interne des nombres par l'ordinateur}
		Il existe deux manières de représenter les nombres décimaux par un ordinateur~: la \emph{virgule fixe} et la \emph{virgule flottante}.

		\subsubsection{Représentation en virgule fixe}
		Soit $x \in \F$ un nombre. Sa représentation en virgule fixe est donnée par le triplet $(\{a_i\}_{-m \leq i \leq n}, b, s)$ où~:
		\begin{itemize}
			\item $b \geq 2$ est la base de représentation~;
			\item $s \in \{0, 1\}$ est le signe~;
			\item $\{a_{-m}, \dotsc, a_n\}$ est l'ensemble de chiffres $0 \leq a_i \lneqq b$ pour tout $i$.
		\end{itemize}

		\begin{rmq} $m$ représente le nombre de chiffres suivant la virgule, et $n+1$ caractérise le nombre de chiffres précédant la virgule. On en déduit que
		la virgule est (implicitement) placée entre $a_0$ et $a_{-1}$.
		\end{rmq}

		On peut donc exprimer $x$ par~:
		\[x = (-1)^s\sum_{k=-m}^na_kb^k.\]

		\begin{rmq} La base choisie pour les ordinateurs est souvent $2, 8$ ou $16$ car $2$ représente le binaire, et les bases octale et hexadécimale
		représentent chacune une écriture \emph{compactée} du binaire par paquets de 3 ou 4 bits.

		La base 10 est par fois également choisie.
		\end{rmq}

		\begin{prp}[Propriétés des nombres en virgule fixe]~
		\begin{itemize}
			\item Les nombres représentés par virgule fixe sont équirépartis sur la droite des réels~;
			\item l'écart entre deux nombres consécutifs représentés en virgule flottante est $b^{-m}$, qui est le plus petit nombre représentable
			      (en valeur absolue)~;
			\item et la plus grande valeur représentable est $b^{n+1}-1$, où $n+1$ est le nombre de chiffres avant la virgule.
		\end{itemize}
		\end{prp}

		\begin{rmq} La représentation par virgule flottante limite fortement les valeurs extrêmes que peut prendre un nombre de par son équirépartition. Les
		nombres à virgule fixe (comme vu juste après) ont une densité de répartition différente, ce qui leur permet de prendre des valeurs maximum et minimum
		bien plus haute (en terme d'ordre de grandeur).
		\end{rmq}

		\subsubsection{Représentation en virgule flottante}
		Soit $x \in \F$ un nombre. Sa représentation en virgule flottante est donnée par le quadruplet $(\{a_i\}_{1 \leq i \leq t}, b, s, e)$où~:
		\begin{itemize}
			\item $b$ et $s$ représentent les mêmes quantités que pour la virgule fixe~;
			\item $t$ est le nombre de \emph{chiffres significatifs}~;
			\item $\{a_i\}_{1 \leq i \leq t}$ est l'ensemble des chiffres $0 \lneqq a_1 \lneqq b$ et $0 \leq a_i \lneqq b$ pour $i > 1$.
		\end{itemize}

		\begin{rmq} On impose $a_1 \neq 0$ afin que la représentation d'un nombre soit unique. \end{rmq}

		\begin{déf} La \emph{mantisse} est la quantité définie par $\sum_{i=1}^ta_ib^{t-i}$. On la note $m \in \N$, ou encore $m[x] \in \N$ quand il est
		nécessaire de montrer que $m$ est la mantisse de la valeur $x$.
		\end{déf}

		\begin{rmq} Dû à la normalisation des $a_i$, on sait borner $m$ par~:
		\[b^{t-1} \leq m \leq b^t - 1.\]
		\end{rmq}

		On peut donc au final exprimer $x$ comme~:
		\[x = (-1)^sb^e\sum_{i=1}^ta_ib^{-i} = (-1)^sb^eb^tb^{-t}\sum_{i=1}^ta_ib^{-i} = (-1)^sb^{e-t}\sum_{i=1}^ta_ib^{t-i} = (-1)^sb^{e-t}m.\]

		\begin{rmq} On note $L$ et $U$ les valeurs respectivement plus petite et plus grande que peut prendre la valeur $e$ de l'exposant. \end{rmq}

		\begin{prp} On paramétrise l'ensemble $\F$ par les quantités $b$, $t$, $L$, et $U$. Quand la paramétrisation doit être explicite, on note l'ensemble~:
		\[\F(b, t, L, U).\]
		\end{prp}

		\begin{rmq} Dans une représentation normalisée, $0 \not \in \F$. \end{rmq}

		\begin{thm} Si $x$ est un élément de $\F(b, t, L, U)$, alors on peut borner $x$ tel que~:
		\[b^{L-1} \leq \abs x \leq b^U(1-b^t).\]
		\end{thm}

		\begin{prp} Le cardinal de l'ensemble $\F(b, t, L, U)$ est donné par~:
		\[\abs {\F(b, t, L, U)} = 2(b-1)b^{t-1}(U-L+1).\]
		\end{prp}

		\begin{rmq} Étant donné que l'exposant $e$ est code sur un nombre $n_e$ de bits (et représenté en complément à 2) dans une représentation machine de
		représentation flottante, on peut trouver que $L = -2^{n_e-1}-1 \leq e \leq 2^{n_e} = U$. On voit alors que les valeurs maximum prises par un nombre
		sont beaucoup plus grandes (en valeur absolue de l'ordre de grandeur) qu'en virgule fixe.
		\end{rmq}

		\subsubsection{Distance relative dans $\F$}
		Prenons $x_i$ et $x_{i+1}$ dans $\F$. On note $\eta(x_i)$ la distance relative entre $x_i$ et $x_{i+1}$ que l'on définit~:
		\[\eta(x_i) : \abs {\frac {x_{i+1}-x_i}{x_i}}.\]

		Dans un système à virgule fixe, $\eta(x_i)$ est fixe pour tout $i$. Pour un système à virgule flottante, on trouve~:
		\[\eta(x_i) = \abs {\frac {x_{i+1}-x_i}{x_i}} = \abs {\frac {m[x_{i+1}]b^{e-t}-m[x_i]b^{e-t}}{m[x_i]b^{e-t}}} = \frac 1{m[x_i]}.\]
		Si $x_{i+1}$ a un exposant plus grand que $x_i$, on a~:
		\[\eta(x_i)=  \abs {\frac {b^{t-1}b^{e-t+1} - (b^t-1)b^{e-t}}{(b^t-1)^{e-t}}} = \abs {\frac{b^{e-t}}{(b^t-1)b^{e-t}}} = \frac 1{m[x_i]}.\]

		On peut donc, en virgule flottante, également déterminer une distance générale (formule) mais qui n'est pas constante.

		En sachant que~:
		\[b^{t-1} \leq m < b^t,\]
		on peut trouver~:
		\[b^{-t} < \frac 1m = \eta \leq b^{1-t}.\]
		En divisant de part et d'autre par $b^{1-t}$, on trouve~:
		\[\frac \epsilon b < \eta(x_i) \leq \epsilon.\]

		\begin{déf} On appelle $\epsilon \coloneqq b^{1-t}$ l'\emph{epsilon machine} qui représente la distance maximale entre deux nombres consécutifs en
		virgule flottante.
		\end{déf}

		\begin{rmq} L'epsilon machine permet de déterminer $1+\epsilon$ qui est le plus petit nombre $x \in \F$ tel que $x \gneqq 1$. \end{rmq}

		\begin{rmq} Il ne faut pas confondre $\epsilon$ qui est la distance maximale entre deux nombres et $b^{L-1}$ qui est le plus petit nombre que l'on peut
		représenter. En pratique, $\epsilon \simeq 10^{-16}$ alors que $b^{L-1} \simeq 10^{-308}$. \end{rmq}

		\begin{déf} Le phénomène d'oscillation de $\eta(x_i)$ est appelé \textit{wobbling precision} en anglais. \end{déf}

		\begin{rmq} Le phénomène de \textit{wobbling precision} est d'autant plus grand que la base $b$ est grande. C'est entre autres pour cela que les petites
		bases ($b = 2$) sont utilisées en pratique. \end{rmq}

		\begin{déf} Soit $x \in \R \setminus \F$ un réel. $x$ n'a pas de représentation exacte par l'ordinateur puisque $x \not \in \F$.

		\begin{itemize}
			\item Si $\abs x > b^U(1-b^{-t})$, alors $x$ est plus grand que le plus grand nombre que l'on peut représenter. On parle alors d'\emph{overflow}.
			      En cas d'overflow, habituellement, le système interrompt le programme.
			\item Si $\abs x < b^{L-1}$, alors $x$ est plus petit que le plus petit nombre possible à représenter. On parle alors d'\emph{underflow}. En cas
			      d'underflow, habituellement, le nombre $x$ est arrondi à 0.
			\item Si $x$ ne dépasse pas des bornes de représentation, on considère $a_{t+1}$, le chiffre suivant $a_t$ dans la représentation théorique à
			      précision infinie de $x$. On peut alors déterminer $\widehat x$ de deux manières~:
				\begin{itemize}
					\item par arrondi~;
					\item par troncature.
				\end{itemize}
		\end{itemize}

		Un arrondi se fait par l'application $x \mapsto \widehat x = \fl(x)$, qui \emph{remplace} $a_t$ par $a_t^*$ défini par~:
		\[a_t^* = \begin{cases}a_t &\text{ si }a_{t+1} < \frac b2, \\ a_t + 1 &\text{ si }a_{t+1} \geq \frac b2.\end{cases}\]
		Si $a_{t+1} \geq \frac b2$ et $a_t = b-1$, on réitère le processus pour $a_{t-1}$ selon $a_t$, etc.

		Une troncature se fait par l'application $x \mapsto \widehat x = \tr(x)$, qui conserve uniquement les $t$ premiers chiffres de la notation théorique.
		\end{déf}

		\begin{déf} On définit $\epsilon_x$ l'erreur relative de $x$ par~:
		\[\epsilon_x = \abs {\frac {\fl(x)-x}x}.\]

		On définit également la \emph{précision machine} $u \coloneqq \frac \epsilon2$.
		\end{déf}

		\begin{prp} Soit $x \in \R$ et $\fl(x) \in \F$. On a $\epsilon_x \leq \frac \epsilon2$. \end{prp}

		\begin{proof} $\abs {\fl(x)-x}$ représente la distance entre $x$ et son approximation. $x$ est arrondi au nombre dans $\F$ le plus proche, et donc
		$\abs {\fl(x)-x} \leq \frac 12\abs{x_{i+1}-x_{i}}$ avec $x_i \leq x \leq x_{i+1}$. On trouve alors~:
		\[\epsilon_x = \abs {\rho_x} \leq \frac \epsilon2 = u.\]
		\end{proof}

		\begin{rmq} La précision machine $u$ donne l'ordre de grandeur de la meilleure approximation possible pour un arrondi sur une machine donnée. \end{rmq}

		\begin{rmq} On trouve alors~:
		\[\fl(x) = x(1 + \rho_x).\]
		\end{rmq}

	\subsection{Erreurs de propagation et de génération}
		Les erreurs de propagation sont dues au conditionnement du problème. Les erreurs de génération quant à elles sont dues à la stabilité de l'algorithme
		mis en place pour la résolution du problème.

		\subsubsection{Erreurs de propagation}
		Soit $F$ une fonction admettant une dérivée d'ordre 1 en $d$. Par Taylor (voir théorème~\ref{thm:Taylor}), on sait que~:
		\[F(\widehat d) = F(d + d\rho_d) \simeq F(d) + F'(d)d\rho_d = F(d)\left(1 + \frac {F'(d)d}{F(d)}\rho_d\right) = x(1 + \kappa(d)\rho_d).\]

		On appelle donc $\kappa(d)\rho_d$ l'\emph{erreur de propagation}.

		Il est également possible que $F(\widehat d)$ subisse une approximation. On a alors~:
		\[\widehat {F(\widehat d)} = x(1 + \kappa(d)\rho_d)(1 + \rho_{F(\widehat d)})
		= x(1 + \kappa(d)\rho_d + \rho_{F(\widehat d)} + \kappa(d)\rho_d\rho_{F(\widehat d)}).\]
		On remarque cependant que $\rho_d\rho_{F(\widehat d)}$ est négligeable face au reste (ordre de grandeur deux fois plus grand en valeur absolue) et donc,
		\[\widehat {F(\widehat d)} \simeq x(1 + \kappa(d)\rho_d + \rho_{F(\widehat d)}).\]

		\begin{rmq} On dit que le conditionnement est lié aux erreurs de propagation car si $\kappa(d) > 1$, alors l'erreur d'arrondi initiale $\rho_d$ va être
		amplifiée, ce qui est encore plus flagrant sur un algorithme itératif.
		\end{rmq}

		On ne peut pas changer le conditionnement d'un problème, et donc en cas de mauvais conditionnement, il est préférable de transformer le problème en un
		problème équivalent mais de plus faible conditionnement.

		\subsubsection{Erreurs de génération}
		Supposons que le problème $x = F(d)$ soit décomposé en $n$ sous-étapes $x_i = F_i(x_{i-1})$ où $x_0 = d$. Soit $\widehat d = d(1+\rho_d)$ la valeur
		encodée en machine de $d$. On détermine~:
		\[\widehat {x_1} = d(1 + \kappa_1(d)\rho_d + \rho_i + \kappa_1(d)\rho_d\rho_i) = x(1 + \rho_{x_1}).\]
		En réitérant ceci $n$ fois, on obtient~:
		\[\widehat x = x\left(1 + \rho_n + \sum_{i=1}^{n-1}\rho_{n-i}\prod_{k=i+1}^{n}\kappa_k(d) + \prod_{k=1}^n\kappa_k(d)\rho_d\right).\]

		On comprend de cela que $\rho_n$ est l'erreur d'arrondi final et ne peut donc être évité. De même, $\rho_d\prod_{k=1}^n\kappa_k(d)$ est l'erreur de
		propagation et dépend du conditionnement, qui dès lors ne peut être évitée. La somme des produits sur $\kappa_k$ et $\rho_{n-i}$ quant à elle est
		l'erreur de génération et est dépendante de l'algorithme choisi pour résoudre le problème. Les $\rho_{n-i}$ dépendent des fonctions $F_i$ choisies lors
		des décisions d'implémentation. Ces erreurs sont donc évitables (ou du moins contrôlables par les choix d'implémentation).

		\begin{rmq} Si l'algorithme a besoin de réaliser un calcul dangereux -- tel qu'une soustraction de deux nombres proches -- il est préférable que cette
		opération soit réalisée le plus tôt possible afin de limiter l'erreur relative.
		\end{rmq}

\newpage
\section{Résolution de systèmes linéaires}
	\subsection{Définitions}
		\begin{déf}Un système de $N$ équations linéaires à $n$ inconnues est donné par $(S) : \sum_{i=1}^na_{i\,j}x_i = b_i$ pour $j \in \{1, \dotsb, N\}$.

		Un tel système se note également sous forme matricielle par $Ax = b$ où $A \in \R^{N \times n}$, $x \in \R^n$ et $b \in \R^N$.
		Si $x = (x_1, \dotsc, x_n) \in \R^n$ est un $n$-uple satisfaisant ces $N$ conditions, alors $x$ est une solutions de $(S)$.
		\end{déf}

		\begin{rmq} Dans cette section, seuls les systèmes linéaires carrés ($N = n$) seront étudiés. \end{rmq}

		\begin{déf} Soit $A$ une matrice carrée. Le rang de $A$ est la dimension de l'espace vectoriel engendré par ses vecteurs colonnes. \end{déf}

		\begin{prp} La solution d'un système linéaire carré $(S) : Ax = b$ existe et est unique si et seulement si une des conditions équivalentes suivantes
		est remplie~:
		\begin{enumerate}
			\item $A$ est inversible~;
			\item $A$ est régulière ($\det(A) \neq 0$)~;
			\item le rang de $A$ vaut $n$~;
			\item Le système homogène $(\bar S) : Ax = 0$ admet $x = (0, \dotsc, 0)$ pour seule solution.
		\end{enumerate}
		\end{prp}

		\begin{thm}[Formule de Cramer] Soit $(S) : Ax = b$ un système linéaire carré. La solution est donnée par le vecteur $x$ tel que~:
		\[x_j = \frac 1{\det(A)}\Delta_j,\]
		où $\Delta_j$ est le déterminant de la matrice obtenue en remplaçant la $j$ème colonne de $A$ par le vecteur $b$.
		\end{thm}

		\begin{rmq} Le calcul du déterminant est en $\mathcal O(n!)$ et est donc impraticable pour des $n$ même relativement petits (et impensables pour
		$n \sim 10^5$, ce qui est l'ordre de grandeur de certains systèmes de résolutions d'équations différentielles partielles). On opte donc pour une
		résolution numérique du système.
		\end{rmq}

		\begin{déf} Une méthode de résolution est dite \emph{directe} si elle fournit la solution exacte en un nombre fini d'étapes. Elle est dite itérative
		si elle fournit une approximation convergente vers la solution.
		\end{déf}

	\subsection{Systèmes triangulaires}
		\begin{déf} Une matrice carrée $A$ est dite \emph{triangulaire inférieure} si $\forall j > i : A_{i\,j} = 0$. \end{déf}

		\begin{déf} Une matrice carrée $A$ est dite \emph{triangulaire supérieure} si $A^T$ est triangulaire inférieure. \end{déf}

		\begin{déf} Un système $(S) : Ax = b$ est dit triangulaire inférieur (respectivement supérieur) si sa matrice $A$ est triangulaire inférieure
		(respectivement supérieure).
		\end{déf}

		\begin{rmq} Il est fréquent de noter les matrices triangulaires inférieures $L$ (pour \emph{lower}) et les matrices triangulaires supérieures $U$
		(pour \emph{upper}).
		\end{rmq}

		\begin{prp}[Résolution d'un système triangulaire inférieur] Soit $(S) : Lx = b$ un système triangulaire inférieur. On trouve (dans l'ordre croissant,
		à savoir pour $j$ de $1$ à $n$) les solutions de la manière suivante~:
		\begin{equation}\label{eq:ressystriang}
			x_j = \frac {(b_j - \sum_{k=1}^{j-1}x_kL_{j\,k})}{L_{k\,k}}.
		\end{equation}
		\end{prp}

		\begin{cor} La résolution d'un système triangulaire supérieur $(S) : Ux = b$ se fait de la même manière mais dans l'ordre décroissant, c'est-à-dire
		pour $j$ de $n$ à $1$. (Cela revient, théoriquement, à dire que la solution est la transposée de la solution de la transposée.)
		\end{cor}

		\begin{déf} On définit le \emph{flop} comme étant une unité de mesure des opérations à virgule flottante tel qu'une opération est $1$~flop. \end{déf}

		\subsubsection{Analyse du coût calculatoire de la résolution d'un système triangulaire}
		Par l'équation~\eqref{eq:ressystriang}, on voit que pour chaque $x_j$, il y a à opérer $(j-1)$ multiplications, $(j-1)$ additions, et une division.
		La résolution d'un système carré de dimension $n \times n$ nécessite donc, au total, $n + \frac {n(n-1)}2 + \frac {n(n-1)}2 = n^2$ opérations.
		On peut donc exprimer le coût calculatoire par $n^2$~flops.

		\begin{déf} Soient $(S_1) : A_1x = b_1$ et $(S_2) : A_2x = b_2$ deux systèmes linéaires d'équations. On dit qu'ils sont équivalents si leur ensemble
		de solution respectif est identique. \end{déf}

		\begin{prp} Soit $(S) : Ax = b$ un système. Il existe trois opérations fondamentales permettant de modifier un système en un autre système équivalent.
		Ces opérations sont~:
		\begin{enumerate}
			\item échanger deux lignes~;
			\item multiplier une ligne par une constante~;
			\item ajouter à une ligne une combinaison linéaire des autres.
		\end{enumerate}
		\end{prp}

		\begin{thm}[Méthode de Gauss de diagonalisation de matrice] La méthode de gauss permet de diagonaliser une matrice carrée. Une fois la matrice carrée
		diagonalisée, la solution est immédiate.

		La méthode de diagonalisation est la suivante~: tout d'abord, on \emph{ajoute} le vecteur $n$ en $n+1$ème colonne de $A$. Ensuite, pour chaque ligne
		$i$ (une par une), on prend l'élément $A_{i\,i}$. S'il est nul, on échange la $i$ème ligne avec la première ligne $j > i$ telle que $A_{j\,i} \neq 0$.
		Si un tel $j$ n'existe pas, le déterminant est nul et donc la matrice n'est pas inversible, le système n'a donc pas de solution (du moins unique).Une
		fois qu'il est assuré que $A_{i\,i} \neq 0$, on remplace toutes les colonnes $j \neq i$ par $A_j - \frac {A_{i\,i}}{A_{j\,i}}A_i$. Une fois toutes les
		lignes traitées, la matrice est diagonalisée.
		\end{thm}

		\subsubsection{Analyse du coût calculatoire de la méthode de Gauss}
		On peut limiter l'élimination de Gauss en triangulant la matrice et pas en la diagonalisant. Dans ce cas, à chaque colonne $i$ à normaliser, il y a
		$(n-i)$ divisions à opérer. Le nombre de divisions est donc $\frac {n(n-1)}2$.

		Il y a une multiplication à chaque élément normalisé (en considérant le coefficient $\frac {A_{i\,i}}{A_{j\,i}}$ calculé par la division comptée juste
		au-dessus). Il y a $(n-1)$ lignes, et pour la $i$ème d'entre elles, il y a $(n-i)(n-i+1)$ normalisations. Il en est de même pour les additions et
		soustractions. Le coût total est donc~:

		\begin{align*}
			\sum_{k=1}^{n-1}1 + 2\sum_{k=1}^{n-1}(n-k)(n-k+1) &= \frac {n(n-1)}2 + 2\sum_{k=1}^{n-1}k(k+1) = \frac {n(n-1)}2 + 2\sum_{k=1}^{n-1}(k^2 + k) \\
			&= \frac {n(n-1)}2 + 2\sum_{k=1}^{n-1}k^2 + 2\sum_{k=1}^{n-1}k = \frac {3n(n-1)}2 + 2\frac {n(n-1)(2n-1)}6 \\
			&= \frac {n(n-1)}2\left(9 + 2(2n-1)\right) = \frac {n(n-1)}2(4n+7) = \frac {2n^3}3 + \frac {7n^2}6 - \frac {4n^2}6 - \frac {7n}6 \\
			&= \frac {2n^3}3 + \frac {n^2}2 - \frac {7n}6.
		\end{align*}

		En rajoutant à cela les $n^2$~flops de résolution de la matrice triangulaire, on obtient un coût total de résolution de
		$\frac {2n^3}3 + \frac {3n^2}2 + \frac {7n}6$.
	
	\subsection{Factorisation de matrices}
		\subsubsection{Factorisation LU}
		\begin{déf} On définit l'application $\delta$ sur un ensemble quelconque $E$ telle que :
		\[\delta : E \times E \to E : (x, y) \mapsto \delta_{x\,y} \coloneqq \begin{cases}1 &\text{ si }x = y, \\0 &\text{ sinon}.\end{cases}\]
		\end{déf}

		\begin{déf} Soit $A$ une matrice triangulaire (inférieure ou supérieure). Si pour tout $i$, on a : $A_{i\,i} = 1$, on dit que $A$ est triangulaire
		\emph{atomique}.
		\end{déf}

		\begin{prp} L'inverse $A^{-1}$ d'une matrice triangulaire atomique $A$ est également triangulaire atomique. \end{prp}

		Il peut être intéressant de décomposer la matrice carrée $A$ d'un système par un produit de deux matrices $L$ et $U$ respectivement triangulaire
		inférieure et triangulaire supérieure, où $\forall i : L_{i\,i} = 1$.

		Il existe plusieurs méthodes (dont certaines directes) pour procéder à cette factorisation, mais commençons par l'adaptation de la méthode de Gauss pour
		créer les matrices pendant la triangulation.

		À l'étape de la renormalisation de la $i$ème colonne, il y a $(n-i)$ lignes à remplacer par une combinaison linéaire des autres. Cette renormalisation
		de la ligne peut s'écrire~:
		\[\forall j > i, k \geq i : A_{j\,k} \leftarrow A_{j\,k} - \frac {A_{j\,i}}{A_{i\,i}}A_{i\,k}.\]
		On peut noter cette opération de manière matricielle par~:
		\[A \leftarrow M^{(i)}A,\]
		où $M^{(i)}$ est la $i$ème matrice de diagonalisation et vaut~:
		\[M^{(i)} = \left[M^{(i)}_{k\,l}\right]_{k\,l} = \left[\delta_{k\,l} - \delta_{i\,l}\frac {A_{k\,i}}{A_{i\,i}}\right]_{k\,l}\]

		\begin{rmq} La matrice inverse de $M^{(i)}$ est la matrice $\left(M^{(i)}\right)^{-1}$ définie par~:
		\[\left(M^{(i)}\right)^{-1} = \left[\delta_{k\,l} + \delta_{i\,l}\frac {A_{k\,i}}{A_{i\,i}}\right]_{k\,l} = (2I - M^{(i)}).\]

		Cela est intuitivement vrai du fait que la matrice inverse représente l'application inverse. Et l'application inverse du fait de retirer $\alpha_{k\,i}$
		fois la ligne $i$ est de l'ajouter $\alpha_{k\,i}$, où $\alpha_{k\,i}$ représente le coefficient $\frac {A_{k\,i}}{A_{i\,i}}$.
		\end{rmq}
		
		On peut nommer les matrices intermédiaires $A^{(k)}$. On a donc $A^{(0)} = A$, $A^{(1)} = M^{(1)}A$, $A^{(2)} = M_2A^{(1)} = M_2M_1A$, etc. que l'on
		peut généraliser en~:
		\[A^{(k)} = M^{(k)}M^{(k-1)}\dotsm M^{(2)}M^{(1)}A = \left(\prod_{\gamma=0}^{k}M^{(k-\gamma)}\right)A.\]

		La matrice finale est une matrice triangulaire supérieure (algorithme de Gauss vu plus haut). On peut donc poser $U = A^{(n)}$ si $n$ est la dimension
		de la matrice. On pose alors~:
		\[L \coloneqq (M^{(k)}M^{(k-1)} \dotsm M^{(2)}M^{(1)})^{-1}
		= \left(\left(M^{(1)}\right)^{-1}\left(M^{(2)}\right)^{-1} \dotsm \left(M^{(k-1)}\right)^{-1}\left(M^{(k)}\right)^{-1}\right).\]

		\begin{rmq} Étant donné que les $M_i$ sont atomiques inférieures, leur inverse l'est également. Et la \emph{composition} de ces matrices atomiques
		est également une matrice atomique inférieure. Dès lors, on sait que $L$ est atomique inférieure et peut satisfaire la factorisation.
		\end{rmq}

		On a donc finalement bien $A = LU$ avec $U$ triangulaire supérieure et $L$ triangulaire inférieure atomique.

		\begin{rmq} L'intérêt de cette décomposition LU est qu'une fois la factorisation faite, la résolution du système $(S) : Ax = b$ se fait par la résolution
		de deux système triangulaires, à savoir~:
		\[\begin{cases}Ly &= b, \\Ux &= y.\end{cases}\]

		Supposons qu'il y ait $p \in \N^*$ systèmes à résoudre ayant tous la même matrice caractéristique $A$. Cette suite de problèmes peut donc se noter~:
		\[Ax^{(k)} = b^{(k)}.\]
		Ainsi, en appliquant $p$ fois Gauss, asymptotiquement, le terme $n^2$ de Gauss devient négligeable, et on obtient~: $p\mathcal O(n^3)$~flops.
		En appliquant une fois la décomposition et en utilisant ces deux matrices pour la résolution de sous-systèmes triangulaires, on obtient~:
		$\mathcal O(n^3 + pn^2)$. Par définition du grand O, c'est équivalent à $\mathcal O(n^3)$. Asymptotiquement, la factorisation rend le programme $p$
		fois plus rapide (du moins, moins coûteux en opérations).
		\end{rmq}

		\subsubsection{Pivots de la méthode de Gauss}
		Lors d'une élimination de Gauss, si le pivot $A_{k\,k}$ vaut 0 à la $k$ème étape, l'algorithme ne peut fonctionner. Numériquement, quand $A_{k\,k}$ est
		proche de 0, l'algorithme risque de mal se dérouler.

		\paragraph{Changement de pivot partiel}
		Pour le changement \emph{partiel} de pivot, il faut trouver, dans la $k$ème colonne (en dessous de $A_{k\,k}$) un élément $A_{p\,k} \neq 0$. Et ensuite,
		il faut échanger les lignes $p$ et $k$ dans la matrice $A$ \textbf{et} dans le vecteur $b^{(k)}$\footnote{Et donc dans la matrice étendue utilisée par
		l'algorithme de Gauss.}.

		Cela évite d'avoir un pivot nul. Cependant, on a dit que numériquement, un pivot \emph{proche} de 0 était \emph{dangereux}. Dès lors, on cherche le plus
		grand $A_{p\,k}$ (en valeur absolue).

		\paragraph{Changement de pivot total}
		Pour le changement \emph{total}, le plus grand élément (en valeur absolue) ne doit pas être cherché dans la $k$ème colonne mais bien dans la sous-matrice
		$[N_{i\,j}]_{k \leq i \leq n, k \leq j \leq m}$. Une fois le plus grand élément $A_{p\,r}$ trouvé, à nouveau, on échange les lignes $p$ et $k$, mais on
		échange également les colonnes $k$ et $r$.

		\begin{rmq} Si la recherche d'un pivot est faite à toutes les étapes (et que la recherche est supposée en $\mathcal O(n)$), un pivot partiel amènerait
		une complexité en $\mathcal O(n^2)$ et un pivot total impliquerait une complexité en $\mathcal O(n^3)$ (toutes opérations confondues, tant pour l'un que
		pour l'autre).
		\end{rmq}

		Notons $P^{(i)}$ la matrice de permutations à la $i$ème étape. La matrice de permutation\footnote{Qui est une permutation de la matrice identité.} est
		celle qui permet d'échanger les lignes (et éventuellement colonnes) de $A$ pour le $i$ème pivot. On remarque que cette matrice est \emph{auto-inverse}.
		En effet, $P^{(i)}\left(P^{(i)}\right)^{-1}$ représente un échange de deux lignes (et éventuellement deux colonnes) suivi de l'opération inverse. Or
		pour annuler une permutation, il faut la réeffectuer.

		La matrice $U$ se remplit lors de l'exécution de l'algorithme de Gauss. Dès lors, on pouvait écrire \\$A = LU$ s'il n'y avait pas de permutations car
		tous les pivots étaient non-nuls. Avec la notation $P^{(i)}$, on peut réécrire~:
		\[U = \left(\prod_{i=1}^nM^{(n+1-i)}P^{(n+1-i)}\right)A.\]

		$U$ est toujours une matrice triangulaire supérieure (par construction). Cependant, la matrice $L' \coloneqq AU^{-1}$ n'est plus triangulaire inférieure,
		mais en est une permutation. Dès lors, on note $P \coloneqq P^{(n)}P^{(n-1)}P^{(n-2)}\dotsm P^{(2)}P^{(1)}$. On définit alors la matrice $L$ par~:
		\[L = PAU^{-1}.\]
		On a alors l'égalité suivante~:
		\[PA = LU.\]

		\begin{rmq} Même s'il est assez coûteux d'effectuer les pivots à chaque étape, il est préférable lorsque le résultat doit être assez précis de tout de
		même les appliquer. Les deux raisons principales sont~:
		\begin{enumerate}
			\item le conditionnement (erreur de propagation) car un petit pivot peut entraîner une très grande erreur relative, or le pivot est au centre de
			      tout l'algorithme, ce qui risquerait de fausser toutes les valeurs~;
			\item la stabilité (erreur de génération) car un petit pivot pourrait amener des produits à donner des résultats très bas qui pourraient être
			      assimilés à 0 par absorption.
		\end{enumerate}
		\end{rmq}

		On sait que le déterminant d'une matrice triangulaire est le produit des éléments de sa diagonale. Donc~:
		\[\det(A)=\det(L)\det(U) = 1\prod_{k=1}^nU_{k\,k}.\]

		Si on appelle $D$ la matrice définie par~:
		\[D = [D_{i\,j}] = \left[\delta_{i\,i}U_{i\,i}\right].\]

		Il existe des méthodes directes pour la factorisation LU (contrairement à la construction par l'algorithme de gauss qui est itérative). Ces méthodes
		doivent fixer $n$ éléments afin de permettre la résolution. En effet, la factorisation $A = LU$ revient à résoudre un système de $n(n+1)$ variables et
		$n^2$ équations. En fixant $n$ inconnues, on obtient un système de $n^2$ équations à $n^2$ inconnues qui possède une solution unique si ces équations
		forment une partie libre.

		L'algorithme de Doolittle (voir juste ci-dessous) fixe les éléments de la diagonale $L$, mais il est possible également de fixer les éléments de la
		diagonale de $U$ par exemple, c'est ce que fait la méthode de Crout.

		\subsubsection{Algorithme de Doolittle}
		En écrivant $LU = A$ avec $L_{i\,i} = 1$ pour $i = 1, \dotsc, n$, on peut résoudre toutes les équations dans l'ordre suivante~:
		\begin{itemize}
			\item la 1ère ligne de $U$ par $U_{1\,i} = A_{1\,i}$~;
			\item la 1ère colonne de $L$ par $L_{i\,1}$ = $\frac {A_{i\,1}}{U_{1\,1}}$~;
			\item la 2ème ligne de $U$~;
			\item la 2ème colonne de $L$~;
			\item etc.
		\end{itemize}

		\subsubsection{Algorithme de Crout}
		Le principe est exactement le même que pour l'algorithme de Doolittle, sauf que ce ne sont pas les $L_{i\,i}$ qui sont imposés à 1 mais bien les
		$U_{i\,i}$. La méthode de résolution est similaire mais se fait dans l'ordre inverse~:
		\begin{itemize}
			\item la 1ère colonne de $L$~;
			\item la 1ère ligne de $U$~;
			\item la 2ème colonnes de $L$~;
			\item la 2ème ligne de $U$~;
			\item etc.
		\end{itemize}

		\subsubsection{Factorisation de Cholesky}
		Prenons $(S) : Ax = b$, un système linéaire tel que $A$ est définie positive et symétrique. Ce genre de systèmes est fréquent en statistiques de
		simulation.

		\begin{thm} Soit $A \in \R^{n \times n}$ symétrique et définie positive. Alors il existe une unique matrice $H$ triangulaire supérieure telle que sa
		diagonale est définie positive et $A = H^TH$.
		\end{thm}

		La méthode de Cholesky permet de déterminer cette matrice $H$ symétrique en la déterminant ligne par ligne.

		\begin{rmq} Les équations sont données explicitement en écrivant $A = H^TH$. \end{rmq}

		Tout comme pour la factorisation $LU$, la factorisation de Cholesky permet de scinder le système $(S)$ en deux systèmes triangulaire qui sont beaucoup
		plus simples à résoudre. On a effectivement~:
		\[Ax = b \iff H^THx = b \iff \begin{cases}H^Ty &= b \\Hx &= y\end{cases}.\]

		Le coût numérique de cet algorithme est de $\mathcal O(\frac {n^3}6)$ produits et additions, $n$ racines carrées et $\mathcal O(\frac {n^2}2)$ divisions.
		On peut donc dire que Cholesky se fait en $\mathcal O(\frac {n^3}3)$, comparé à la méthode de Gauss qui se fait en $\mathcal O(\frac {2n^3}3)$, sans
		compter les pivotages.

		\begin{rmq} De plus, la place de stockage nécessaire est réduite de moitié car il n'y a qu'une seule matrice à déterminer ($H$) et plus deux ($L$ et $U$).
		De plus, $A$ est supposée symétrique, et donc $A$ et $H$ peuvent toutes deux être stockées dans une matrice carrée $n \times n$.
		\end{rmq}

	\subsection{Analyse des propriétés des algorithmes de factorisation matricielle}
		\subsubsection{Analyse du conditionnement}
		\begin{déf} Soit $A$ une matrice réelle carrée $n \times n$ et soit $p$ un naturel non nul. On définit la $p$-norme matricielle par~:
		\[\norm A_p \coloneqq \sup_{x \in \R^n \setminus \{0\}}\frac {\norm {Ax}_p}{\norm x_p}.\]

		Quand $p = 2$, on note~:
		\[\norm A \coloneqq \sup_{x \in \R^n \setminus \{0\}}\frac {\norm {Ax}}{\norm x}.\]
		\end{déf}

		Soient $A$ et $b$ les données d'un système linéaire $(S) : Ax = b$. On sait que si $x$ est perturbé par $\delta x$, on a~:
		\[A(x + \delta x) = b + \delta b.\]
		Or dans notre cas, c'est $x$ que l'on cherche. On veut donc savoir comment se comporte $\delta x$.
		On sait que $Ax = b$, et donc $A\delta x = \delta b$, ou encore $\delta x = A^{-1}\delta b$. Par définition de la norme matricielle, on sait~:
		\[\norm {\delta x} = \norm{A^{-1}\delta b} \leq \norm {A^{-1}} \norm{\delta b}.\]
		On sait également que $\norm b \leq \norm A\norm x$ et donc $\frac 1{\norm x} \leq \frac {\norm A}{\norm b}$.

		On peut alors définir le conditionnement, par définition~:
		\[\kappa(A) = \max_x \frac {\frac {\norm {\delta x}}{\norm x}}{\frac {\norm {\delta b}}{\norm b}}
		= \frac 1{\frac {\norm {\delta b}}{\norm b}}\norm {A^{-1}}\norm {\delta b}\frac {\norm A}{\norm b} = \norm {A^{-1}}\norm A.\]

		\begin{déf} Le $p$-conditionnement $\kappa_p$ de la matrice $A$ est donné par~:
		\[\kappa_p(A) = \norm A_p\norm{A^{-1}}_p.\]
		\end{déf}

		\begin{rmq} On remarque que $1 = \norm I = \norm{A^{-1}A} \leq \norm A\norm{A^{-1}} = \kappa(A)$. Le conditionnement est donc toujours supérieur à 1.
		On remarque également que~:
		\[\kappa_p(A) = \norm{A^{-1}}_p\norm A_p = \norm A_p\norm{A^{-1}}_p = \kappa_p(A^{-1}).\]

		De plus, on aimerait que multiplier la matrice $A$ par une constante ne change pas le conditionnement car le problème reste intrinsèquement le même.
		En effet, $\kappa_p(\alpha A) = \norm{\alpha A}_p\norm{(\alpha A)^{-1}}_p = \alpha\norm A_p\frac 1\alpha\norm{A^{-1}}_p = \kappa_p(A)$.
		\end{rmq}

		\begin{déf} Soit $A \in \R^{n \times n}$ une matrice carrée. On appelle \emph{vecteur propre} de $A$ tout vecteur $x$ tel qu'il existe $\lambda \in \R$
		tel que $Ax = \lambda x$.
		\end{déf}

		\begin{déf} On appelle valeur propre de $A$ tout $\lambda \in \R$ tel qu'il existe $x \in \R^n$ tel que $Ax = \lambda x$. \end{déf}

		\begin{rmq} Même si le nombre de valeurs propres d'une matrice est fini, une valeur propre engendre un sous-espace vectoriel de vecteurs propres.

		En effet, si $x$ est un vecteur propre de $A$, alors il existe $\lambda \in \R$ tel que $Ax = \lambda x$. On en déduit donc que pour tout $\mu \in \R$,
		$A(\mu x) = \mu(Ax) = \mu\lambda x = \lambda (\mu x)$ et donc $\mu x$ est également un vecteur propre de $A$.
		\end{rmq}

		\begin{déf} Si $\lambda$ est une valeur propre de $A \in \R^{n \times n}$ et $\lambda > 0$, alors $\sigma \coloneqq \sqrt \lambda$ est appelée une
		\emph{valeur singulière} de $A$.
		\end{déf}

		\begin{déf} Si $A \in \R^{n \times n}$ est une matrice carrée de valeurs propres $\lambda_1, \dotsc, \lambda_m$, on définit son \emph{rayon spectral}
		par~:
		\[\rho(A) \coloneqq \max_k\abs{\lambda_k}.\]
		\end{déf}

		\begin{rmq} On peut définir le conditionnement à l'aide de ces définitions~:
		\[\kappa(A) = \rho(A)\rho(A^{-1}) = \frac {\sigma_{\text{max}}}{\sigma_{\text{min}}}.\]
		\end{rmq}

		\subsubsection{Analyse de la stabilité}
		À cause des erreurs d'arrondi, une méthode numérique fournit une solution approchée $\widehat x = x + \delta x$. Procédons à une analyse directe de
		la stabilité. Supposons que $A$ et $b$ soient représentés de manière approchée par $\widehat A = A + \delta A$ et $\widehat b = b + \delta b$.

		On a alors~:
		\[(A + \delta A)(x + \delta x) = \widehat A\widehat x = \widehat b = b + \delta b.\]
		Or on sait que $Ax = b$. Dès lors~:
		\[Ax + \delta Ax + A\delta x + \delta A\delta x = b + \delta b \qquad\iff\qquad \delta A x + (A+\delta A)\delta x = \delta b.\]

		\begin{thm} Soit $A \in \R^{n \times n}$ une matrice carrée régulière et $\delta A$ une perturbation telles que~:
		\[\norm {A^{-1}}\norm {\delta A} \lneqq 1.\]
		Alors~:
		\[\frac {\norm{\delta x}}{\norm x}
		\leq \frac {\kappa(A)}{1 - \kappa(A)\frac {\norm {\delta A}}{\norm A}}\left(\frac {\norm{\delta b}}{\norm b} + \frac {\norm{\delta A}}{\norm A}\right).\]
		\end{thm}

		\begin{rmq} La preuve de ce théorème est omise. \end{rmq}

		\begin{cor} Si les conditions du théorème précédent sont respectées et $\norm {\delta A} = 0$, alors~:
		\[\frac 1{\kappa(A)}\frac {\norm {\delta b}}{\norm b} \leq \frac {\norm {\delta x}}{\norm x} \leq \kappa(A)\frac {\norm {\delta b}}{\norm b}.\]
		\end{cor}

		\begin{rmq} Ce corollaire dit que pour un grand conditionnement $\kappa(A)$, la borne supérieure pour $\frac {\norm {\delta x}}{\norm x}$ devient très
		grande. Cependant, il dit également que la borne inférieure devient très petite (et tend vers 0 pour $\kappa(A) \to +\infty$).

		On en déduit qu'un conditionnement élevé n'implique \emph{pas obligatoirement} une grande perturbation $\delta x$ sur la solution déterminée.
		\end{rmq}

		On a pu remarquer que le calcul du $p$-conditionnement $\kappa_p(A)$ pour l'analyse du problème requiert le calcul de $\norm {A^{-1}}_p$, et donc de
		$A^{-1}$ qui est assez coûteux. L'analyse directe de stabilité vue ci-dessus requiert le conditionnement et donc par extrapolation nécessite également
		le calcul de $A^{-1}$. 

		\begin{rmq} Il y a moyen, d'effectuer des estimations du conditionnement, par exemple à l'aide de la méthode LAPACK\footnote{Algorithme implémenté dans
		MATLAB.}. Ceci permet de déterminer une valeur approchée du conditionnement en $\mathcal O(n^2)$, ce qui est largement préférable à $\mathcal O(n^3)$
		nécessaire pour inverser la matrice $A$.
		\end{rmq}

		On peut cependant procéder à une analyse à posteriori (contrairement à l'analyse à priori faite juste avant)\footnote{L'analyse à priori permet d'évaluer,
		avant de lancer la résolution, quelle va être la sensibilité de la résolution aux problèmes d'arrondis, et donc possiblement d'améliorer l'implémentation
		afin d'en éviter les conséquences néfastes. Une analyse à posteriori est moins coûteuse de manière générale et se fait une fois la résolution terminée.
		Elle permet d'évaluer la pertinence de la solution suivant la sensibilité aux arrondis.}

\end{document}
