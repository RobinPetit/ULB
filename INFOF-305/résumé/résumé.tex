\documentclass{article}

\usepackage{commath}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{palatino, eulervm}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage[bottom]{footmisc}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{stmaryrd}
\usepackage{hyperref}

%%%%%  amsthm  %%%%%
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollaire}
\newtheorem{lem}[thm]{Lemme}
\addto\captionsfrench{\renewcommand\proofname{\underline{Démonstration}}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}[section]

% link amsthm and mdframed
\iftrue
%\iffalse
	% pre-amsthm
	\mdfdefinestyle{resultstyle}{%
		hidealllines=true,%
		leftline=true,%
		rightline=true,%
		innerleftmargin=10pt,%
		innerrightmargin=10pt,%
		innertopmargin=10pt,%
		innerbottommargin=8pt,%
	}

	\surroundwithmdframed[style=resultstyle]{thm}
	\surroundwithmdframed[style=resultstyle]{prp}
	\surroundwithmdframed[style=resultstyle]{cor}
	\surroundwithmdframed[style=resultstyle]{lem}
\fi

\newcommand{\N}{\mathbb N}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\K}{\mathbb K}
\newcommand{\tq}{\text{ t.q. }}
\newcommand{\restr}[2]{\left.#1\vphantom{\big|}\right|_{#2}}
\newcommand{\intint}[2]{{\left\llbracket#1, #2\right\rrbracket}}
\newcommand{\scpr}[2]{{\left\langle#1, #2\right\rangle}}

\title{Modélisation et simulation --- INFOF-305}
\author{R. Petit}
\date{Année académique 2016 - 2017}

\begin{document}
\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}
\setcounter{page}1

\section{Introduction aux systèmes dynamiques}
	\subsection{Généralités}

	\begin{déf} Soit $T$, \textit{l'ensemble de temps}. Selon la nature de $T$, on parle de \textit{système à temps discret}, ou de \textit{système à temps
	continu}. Les applications~:
	\[u : T \to U \subseteq \R^n \qquad\qquad \text{ et } \qquad\qquad y : T \to Y \subseteq \R^m\]
	sont respectivement appelées \textit{fonction d'entrée} et \textit{fonction de sortie}. L'application $u$ correspond aux apports que subit le système, alors
	que l'application $y$ correspond à l'observation du système.

	Le couple d'applications $(u, y)$ appartient à $\Omega \times \Gamma$, où $\Omega$ est l'ensemble des fonctions d'entrées acceptables et $\Gamma$ est
	l'ensemble des fonctions de sortie acceptables.
	\end{déf}

	\begin{rmq} $\forall (u, y) \in \Omega \times \Gamma : \forall t \in T : \left(u(t), y(t)\right) \in U \times Y$.
	\end{rmq}

	\begin{déf} On appelle variable d'état la variable $x : T \to X \subseteq \R^d$ représentant l'\textit{état interne du système} en fonction du temps.

	L'évolution du système sera décrite comme un système d'équations différentielles ou d'équations aux différences par rapport à la variable d'état.
	\end{déf}

	\begin{rmq} Le fait qu'une variable supplémentaire soit introduite induit que la connaissance de $(t_0, u, y) \in T \times \Omega \times \Gamma$ ne permet
	pas de prédire $y(t)$ pour $T \ni t > t_0$. Pour cela, il faut également connaître $x^0 \coloneqq x(t_0) \in \R^d$. Alors les théorèmes de Cauchy-Lipschitz
	sont applicables (habituellement) pour affirmer que $t \mapsto x(t)$ est une solution.
	\end{rmq}

	\begin{déf} Un système est dit \textit{statique} (ou \textit{memoryless}) lorsque la sortie ne dépend que de l'entrée, et pas de la variable d'état.
	\end{déf}

	\begin{rmq} Dans un tel système, connaitre $(t_0, u, y)$ est suffisant pour connaitre $y(t)$ pour tout $t > t_0$.
	\end{rmq}

	\begin{déf} L'application~:
	\[\varphi : T \times T \times X \times \Omega \to \R^d\]
	telle que $\forall t \in T : x(t) = \varphi(t_0, t, x^0, u)$ est appelée \textit{fonction d'état}.

	L'application~:
	\[\eta : T \times X \to Y\]
	telle que $\forall t \in T : y(t) = \eta(t, x(t))$ est appelée \textit{fonction de transformation de sortie}.
	\end{déf}

	\begin{déf} Un système dynamique se définit alors par le 8-uple suivant~:
	\[S = \left(T, U, \Omega, X, Y, \Gamma, \varphi, \eta\right).\]
	\end{déf}

	\begin{rmq} On peut donc synthétiser un système dynamique par~:
	\[u(t) \xrightarrow{\varphi(t)} x(t) \xrightarrow{\eta(t)} y(t).\]
	\end{rmq}

	\begin{prp} L'application $\varphi$ admet les propriétés suivantes~:
	\begin{itemize}
		\item consistance~: $\forall (t, x, u) \in T \times X \times \Omega : \varphi(t, t, x, u) = x$~;
		\item irréversibilité~: $\varphi$ est définie sur $[t_0, +\infty) \cap T$~;
		\item composition~: $\forall t_0 < t_1 < t_2 \in T : \forall (u, x) \in \Omega \times X : \varphi(t_2, t_0, x, u)
			= \varphi\left(t_2, t_1, \varphi\left(t_1, t_0, x, u\right), u\right)$~;
		\item causalité~: $\forall t_0 \in T : \forall u_1, u_2 \in \Omega : \left(\forall t \in T : u_1(t) = u_2(t)\right)
			\Rightarrow \left(\forall t \in T : \varphi(t, t_0, x, u_) = \varphi(t, t_0, x, u_2)\right)$.
	\end{itemize}
	\end{prp}

	\begin{déf} Soit un système dynamique régi par~:
	\[x(t) = \varphi(t, t_0, x(t_0), u).\]

	On appelle le \textit{mouvement du système} l'ensemble $\left\{(t, x(t)) \tq t \geq t_0\right\}$.

	On appelle la \textit{trajectoire du système} l'ensemble $\left\{x(t) \tq t \geq t_0\right\}$.
	\end{déf}

	\begin{rmq} La trajectoire est donc la projection du mouvement parallèlement au temps.
	\end{rmq}

	\begin{déf} Soit $\overline x \in X$. On dit que $\overline x$ est un \textit{état d'équilibre (en temps infini)} lorsque~:
	\[\exists u \in \Omega \tq \forall (t, t_0) \in T^2 : t \geq t_0 \Rightarrow \varphi(t, t_0, \overline x, u) = \overline x.\]
	\end{déf}

	\begin{déf} Soit $\overline y \in Y$. On dit que $\overline y$ est une \textit{sortie d'équilibre (en temps infini)} lorsque~:
	\[\forall t_0 \in T : \exists (x, u) \in X \times \Omega \tq \forall t \geq t_0 : \eta\left(t, \varphi(t, t_0, x, u)\right) = \overline y.\]
	\end{déf}

	\begin{déf} Un système est dit \textit{invariant} lorsque~:
	\begin{enumerate}
		\item $T$ est stable par l'addition~;
		\item $\forall (u, \delta) \in \Omega \times T : \Omega \ni u^{(\delta)} : T \to U : t \mapsto u(t-\delta)$~;
		\item $\forall (t_0, \delta, x^0) \in T \times T \times X : \forall t \geq t_0 : \varphi\left(t, t_0, x^0, u\right)
			= \varphi\left(t+\delta, t_0+\delta, x^0, u^{(\delta)}\right)$~;
		\item $y$ est indépendante de $t$, c-à-d~: $y(t) = (\eta \circ x)(t))$.
	\end{enumerate}
	\end{déf}

	\begin{déf} Soient $x^{(1)}, x^{(2)} \in X$. On dit que $x^{(2)}$ est \textit{accessible} à l'instant $t_2 \in T$ à partir de $x^{(1)}$ lorsque~:
	\[\exists (t_1, u) \in T \times \Omega \tq t_1 < t_2 \text{ et } \varphi(t_2, t_1, x^{(1)}, u) = x^{(2)}.\]
	\end{déf}

	\begin{déf} Un système est dit \textit{connexe à l'instant $t \in T$} lorsque $\forall (x^{(1)}, x^{(2)}) \in X^2 : x^{(2)}$ est accessible à l'instant
	$t$ à partir de $x^{(1)}$.

	Si un système est connexe pour tout $t \in T$, alors il est dit connexe.
	\end{déf}

	\begin{déf} Soient $x^{(1)}, x^{(2)} \in X$. On dit que $x^{(1)}$ et $x^{(2)}$ sont équivalents à l'instant $t_0 \in T$ lorsque~:
	\[\forall u \in \Omega : \forall t \geq t_0 : \eta\left(t, \varphi\left(t, t_0, x^{(1)}, u\right)\right)
		= \eta\left(t, \varphi\left(t, t_0, x^{(2)}, u\right)\right).\]
	\end{déf}

	\begin{déf} Un système est dit en \textit{forme réduite} si $\forall (x^{(1)}, x^{(2)}) \in X^2 : x^{(1)} \neq x^{(2)} \Rightarrow x^{(1)}$ n'est pas
	équivalent à $x^{(2)}$.
	\end{déf}

	\begin{déf} Soit $\hat x \in X$. L'état $\hat x$ est dit observable à l'instant $t_0 \in T$ lorsque $\exists (t, u) \in T \times \Omega \tq x(t_0)$ peut
	être retrouvé de manière univoque à l'aide de $\restr u{[t_0, t)}$ et $\restr y{[t, t_0)}$.
	\end{déf}

	\subsection{Systèmes dynamiques complexes}

	\begin{déf} Un \textit{sous-système dynamique} est un système dynamique faisant partie d'un système dynamique complexe.
	\end{déf}

	\begin{déf} Soient $S_1$ et $S_2$ deux systèmes dynamiques. $S_1$ et $S_2$ sont dits \textit{connectés en cascade} lorsque~:
	\[y_1 = u_2,\]
	c-à-d lorsque la sortie du premier système sert d'entrée au second.
	\end{déf}

	\begin{rmq} Pour que deux systèmes $S_1$ et $S_2$ soient connectés en cascade, il est nécessaire que $T_1 = T_2$, $\Gamma_1 \subseteq \Omega_2$
	(et donc $Y_1 \subseteq U_2$).
	\end{rmq}

	\begin{prp} Soient les deux systèmes dynamiques suivants~:
	\begin{align*}
		S_1 &= \left(T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1\right), \\
		S_2 &= \left(T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2\right).
	\end{align*}

	Le système dynamique résultant de la cascade de $S_1$ et $S_2$ est donné par~:
	\[S = \left(T, U_1, \Omega_1, X_1 \times X_2, Y_2, \Gamma_2, \varphi, \eta_2\right),\]
	où~:
	\begin{align*}
		&T = T_1 = T_2 \\
		&\varphi : T \times T \times (X_1 \times X_2) \times \Omega_1 \to X : \\
		&\qquad\left((t, t_0, \left(x_1(t_0), x_2(t_0)\right), u\right) \mapsto
				\left(\varphi_1\left(t, t_0, x_1(t_0), u\right), \varphi_2\left(t, t_0, x_2(t_0), y_1(t_0, x_1, u)\right)\right), \\
		&y_1(t_0, x_1, u) : T \to Y_1 \subseteq U_2 : t \mapsto \eta_1\left(t, \varphi_1\left(t, t_0 x_1(t_0), u\right)\right).
	\end{align*}
	\end{prp}

	\begin{déf} Soient $S_1$ et $S_2$ deux systèmes dynamiques. $S_1$ et $S_2$ sont dits \textit{connectés en parallèle} lorsque~:
	\[u_1 = u_2,\]
	c-à-d lorsqu'ils ont la même fonction d'entrée.
	\end{déf}

	\begin{rmq} Pour que deux systèmes dynamiques soient connectés en parallèle, il est nécessaire que $T_1 = T_2$, $\Omega_1 = \Omega_2$ (et donc $U_1 = U_2$).
	\end{rmq}

	\begin{prp} Soient les deux systèmes dynamiques suivants~:
	\begin{align*}
		S_1 &= \left(T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1\right), \\
		S_2 &= \left(T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2\right).
	\end{align*}

	Le système dynamique résultant des systèmes $S_1$ et $S_2$ en parallèle est donné par~:
	\[S = \left(T, U, \Omega, X_1 \times X_2, Y_1 \times Y_2, \Gamma_1 \times \Gamma_2, \varphi, \eta\right),\]
	où~:
	\begin{align*}
		T &= T_1 = T_2 \\
		U &= U_1 = U_2 \\
		\Omega &= \Omega_1 = \Omega_2 \\
		\varphi &: (t, t_0, x, u) \mapsto \left(\varphi_1(t, t_0, x, u), \varphi_2(t, t_0, x, u)\right) \\
		\eta &: \left(t, (x_1, x_2)\right) \mapsto \left(\eta_1(t, x_1), \eta_2(t, x_2)\right)
	\end{align*}
	\end{prp}

	\subsection{Rétroaction}

	\begin{déf} Deux systèmes $S_1 = (T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1)$ et $S_2 = (T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2)$
	sont dits en rétroaction l'un sur l'autre lorsqu'il existe $v_1 : T \to U_1, v_2 : T \to U_2$ et~:
	\[\psi_1 : Y_1 \times U_2 \times T \to U_2 \qquad\qquad \text{ et } \qquad\qquad \psi_2 : Y_2 \times U_1 \times T \to U_1\]
	tels que~:
	\begin{align*}
		u_1(t) &= \psi_2\left(y_1(t), v_2(t), t\right) \\
		u_2(t) &= \psi_1\left(y_2(t), v_1(t), t\right).
	\end{align*}
	\end{déf}

	\begin{déf} On parle de \textit{rétroaction négative} lorsqu'une modification de $y_1(t)$ entraine une modification de $y_2(t)$ qui s'oppose au changement
	de $y_1(t)$.

	De même, on parle de \textit{rétroaction positive} lorsqu'une modification de $y_1(t)$ entraine une modification de $y_2(t)$ qui amplifie le changement de
	$y_2(t)$.
	\end{déf}

	\begin{rmq} Ce type de construction est le plus simple contenant une boucle.

	De plus, il est ici question de rétroaction sur la sortie. Il peut être plus intéressant de définir une rétroaction sur l'état.
	\end{rmq}

	\begin{déf} Un système est dit \textit{rétroactionné sur l'état} lorsqu'il existe $v : T \to U$ et $\psi : X \times U \times T \to U$ tels que~:
	\[u(t) = \psi\left(x(t), v(t), t\right).\]

	Cette fonction $\psi$ est appelée \textit{loi de contrôle}.
	\end{déf}

\section{Automates --- systèmes à temps discret et et à espace d'états discret}
	\begin{déf} Un \textit{automate} est un système dynamique invariant à temps discret et avec un espace d'états discret, et où les ensembles d'entrée et de
	sortie sont finis.
	\end{déf}

	\begin{déf} Un automate est dit \textit{fini} lorsque l'espace d'états est fini.
	\end{déf}

	\begin{prp} Dans un système dynamique invariant à temps discret, la fonction $\varphi$ de transition peut être remplacée par~:
	\[x(t+1) = \delta(x(t), u(t)),\]
	et la fonction de transformation de sortie peut être remplacée par~:
	\[y(t) = \eta(x(t)),\]
	ce qui implique que l'observation du système dépend uniquement de l'état, et que l'état à un certain instant ne dépend plus que de la valeur à l'état
	précédent (modèle markovien).
	\end{prp}

	\begin{déf} Un automate \textit{cellulaire} de dimension $(n_1, \ldots, n_k) \in {\N^*}^k$ est un automate tel que $X = \chi^{\prod_{i=1}^kn_i}$, où $\chi$
	est un ensemble fini d'états tel que~:
	\[\forall \alpha \in {\N^*}^k : \left(\forall 1 \leq j \leq k : 1 \leq \alpha_j \leq n_k\right) \Rightarrow \left(\forall t \in T : x_\alpha(t) \in \chi\right),\]
	et tel que $x(t+1) = (\delta \circ x)(t)$, à savoir, aucune entrée $u \in \Omega$ n'est présente.

	Les telles valeurs $x_\alpha$ sont appelées les cellules de l'automate.
	\end{déf}

	\begin{rmq} Dans un automate cellulaire, la nombre de variables d'états est vite très grand, mais reste toute fois fini.
	\end{rmq}

	\begin{déf} la fonction de transition d'un automate cellulaire $\delta : X \times U \to X$ est une fonction à valeurs dans $X = \chi^{\prod_{i=1}^kn_i}$.
	Chaque fonction $\delta_\alpha$ telle que $x_\alpha(t+1) = \delta_\alpha(x(t))$ est défini sur un \textit{voisinage} de $\alpha \in {\N^*}^k$. Et donc,
	on peut écrire $x_\alpha(t+1) = \delta_\alpha\left(\gamma(x(t), \alpha)\right)$, où $\gamma : X \times {\N^*}^k$ est une fonction renvoyant uniquement
	un sous-ensemble (non-strict) de $x(t) \in X$.
	\end{déf}

	\begin{ex} Un automate cellulaire de dimension $(n_1, n_2) \in \N^* \times \N^*$ représente donc une \textit{grille} de cellules, où l'état de chaque cellule
	$x_{i\,j}$ à l'instant $t+1 \in T$ ne dépend que d'un voisinage de $(i, j) \in \N^* \times \N^*$. Par exemple, dans le jeu de la vie (J. Conway), le
	voisinage de $(i, j)$ est défini par~:
	\[\left\{(k, \ell) \in \N^* \times \N^* \tq \abs {k-i} = \abs {\ell-j} = 1\right\}.\]
	\end{ex}

	\begin{rmq} Ces systèmes dynamiques que représentent les automates cellulaires (finis) font partie des systèmes complexes suite à leur grand nombre de
	variables d'état. Ils ont entre autre prouvé que des règles simples et déterministes pouvaient engendrer un comportement très compliqué à décrire et à
	prédire. En effet, un \textit{simple} automate cellulaire de dimension $(n_1, n_2) \in \N^* \times \N^*$ peut produire plusieurs comportements distincts
	et simultanés dans plusieurs voisinages de cellules, certains périodiques, d'autres erratiques.
	\end{rmq}

\section{Systèmes continus}
	Dans cette section, on considère l'espace $T = [t_0, +\infty) \subset \R$, pour $t_0 \in \R^+$, et donc continu.

	\subsection{Systèmes réguliers}

	\begin{déf} Un système dynamique $S$ est dit \textit{de dimensionnalité finie} lorsque les ensembles $U, X$ et $Y$ sont des espaces vectoriels de dimension
	finie (pas nécessairement la même dimension), i.e. $\exists n_1, n_2, n_3 \in \N^*$ tels que $(U, X, Y) = (\K_1^{n_1}, \K_2^{n_2}, \K_3^{n_3})$, où
	les $\K_i$ sont des corps (habituellement $\K \in \{\R, \C\}$).
	\end{déf}

	\begin{rmq} Nous ferons ici l'hypothèse que ces espaces vectoriels sont normés, afin de pouvoir définir une distance~:
	\[\forall a, b \in \K^d : d_\K(a, b) = \norm {a-b}_\K,\]
	où $\norm \cdot_\K : \K \to \R$ est la norme de l'espace vectoriel normé $(\K, \norm \cdot_\K)$.
	\end{rmq}

	\begin{déf} Un système dynamique continu de dimensionnalité finie est dit \textit {régulier} lorsque~:
	\begin{itemize}
		\item les espaces $U, X, Y, \Omega, \Gamma$ sont des espaces vectoriels normés~;
		\item la fonction de transition $\varphi$ est continue sur $T \times T \times X \times \Omega$~;
		\item la fonction de transition $\varphi$ est continûment dérivable par rapport au temps sur le sous-ensemble de définition de $u \in \Omega$ où
			$u$ est continue~;
		\item la fonction $\eta$ est continue sur $X \times T$.
	\end{itemize}
	\end{déf}

	\begin{rmq} On fait ici les hypothèses de régularité suffisantes pour lier les systèmes dynamiques continus aux équations différentielles ordinaires, donc
	ici en particulier, afin d'assurer l'existence d'une solution maximale unique, il est nécessaire de supposer $\od \varphi t$ localement lipschitzienne sur $X$
	en plus de sa continuité (théorème de Cauchy-Lipschitz local).
	\end{rmq}

	L'équation différentielle vectorielle du premier ordre $\od xt = f(x(t), u(t), t)$ peut se réécrire indépendamment selon les composantes\footnote{Toute
	équation vectorielle, peu importe son degré, peut se réécrire comme une équation différentielle vectorielle d'ordre 1.}~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t), t) \\
		\od {x_2}t(t) &= f_2(x(t), u(t), t) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t), t),
	\end{cases}\]
	où $n$ est la dimension d'arrivée de $f$, et donc la dimensionnalité de $X$.

	\begin{thm} Pour $t_0 \in T$ fixé, le mouvement $t \mapsto \varphi(t, t_0, x^{(0)}, u)$ pour $x^{(0)} = x(t_0)$ d'un système dynamique régulier est solution
	unique maximale d'une équation différentielle de la forme~:
	\begin{align}\label{eq:equadiffvec}
		\od xt = f(x(t), u(t), t).
	\end{align}
	\end{thm}

	\begin{déf} Dans l'équation~\eqref{eq:equadiffvec}, la fonction $f : X \times U \times T \to X$ est appelée \textit{fonction génératrice du système}.
	\end{déf}

	\begin{rmq} Il est souvent très difficile (voire impossible) de déterminer analytiquement la solution d'un système exprimé sous forme différentielle
	(équation~\eqref{eq:equadiffvec}). Dans ces cas, la simulation numérique est requise.
	\end{rmq}

	\begin{déf} Un système régulier est dit \textit{autonome} lorsque $\od xt = f(x(t))$, c'est-à-dire lorsque $f$ ne fait pas intervenir le temps explicitement.
	\end{déf}

	\begin{prp} Tout système d'équations différentielles peut être mis sous forme autonome.
	\end{prp}

	\begin{proof} Le système suivant~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t), t) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t), t)
	\end{cases}\]
	peut être réécrit comme suit~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t)) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t)) \\
		\od {x_{n+1}}t(t) &= \od tt = 1
	\end{cases}\]
	\end{proof}

	\subsection{Espace et portrait de phases}

	\begin{déf} L'espace d'états $X$ est également appelé \textit{espace des phases}, dans lequel tout état $x \in X$ représente un point $(x_1, \ldots, x_n) \in X$
	de l'espace des phases.
	\end{déf}

	\begin{rmq} Selon cette définition, la trajectoire d'un système représente donc la projection du mouvement dans l'espace des phases, ce qui correspond à
	une courbe de dimension 1 dans $X$.
	\end{rmq}

	\begin{déf} On appelle \textit{portrait de phases} la représentation du champ de vecteurs $f : X \times U \times T \to X$ dans l'espace des phases.
	\end{déf}

	\begin{rmq} Le portrait de phases d'un système donne une représentation qualitative de l'évolution du système. Cette représentation est très pratique du fait
	qu'elle ne requiert rien d'autre que la fonction $f$, génératrice du système, qui est connue. Il est donc toujours possible de dessiner un portrait de phases,
	même lorsqu'il est impossible de résoudre analytiquement l'équation.

	Afin de rendre l'information encore plus qualitative, il est commun de renormaliser tous les vecteurs du champ lors de la représentation. Ainsi, toute
	information sur $t$ est perdue (ce qui ne change rien dans le cas d'un système autonome).
	\end{rmq}

	\subsection{Stabilité des points d'équilibre}

	La stabilité est la notion qui va permettre de classifier les points d'équilibre selon leur comportement induit suite à des perturbations.

	\begin{déf} Soient $(\bar t, \bar x, \bar u) \in T \times X \times \Omega$. Le mouvement $t \mapsto \varphi(t, \bar t, \bar x, \bar u)$ d'un système $S$
	est dit \textit{stable} lorsque~:
	\[\forall \varepsilon > 0 : \exists \delta > 0 \tq \forall x \in X : \left(\norm {x-\bar x} < \delta\right) \Rightarrow
		\left(\forall t \in T : t \geq \bar t \Rightarrow \norm {\varphi(t, \bar t, \bar x, \bar u) - \varphi(t, \bar t, x, \bar u)} < \varepsilon\right).\]

	Si un mouvement n'est pas stable, il est dit \textit{instable}.
	\end{déf}

	\begin{déf} Soit $(\bar x, \bar u, \bar t) \in X \times \Omega \times T$, où $\bar x$ est un point d'équilibre pour $\bar u$ à l'instant $\bar t$.
	Le point d'équilibre $\bar x$ est dit \textit{stable} lorsque~:
	\[\forall \varepsilon > 0 : \exists \delta > 0 \tq \forall x \in X : \left(\norm {x-\bar x} < \delta\right) \Rightarrow
		\left(\forall t \in T : t \geq \bar t \Rightarrow \norm {\varphi(t, \bar t, x, \bar u) - \bar x} < \varepsilon\right).\]
	\end{déf}

	\begin{déf} Un point d'équilibre $\bar x \in X$ pour une entrée $\bar u \in \Omega$ à l'instant $\bar t \in T$ est dit \textit{asymptotiquement stable}
	lorsqu'il est stable, et~:
	\[\lim_{t \to +\infty}\norm {\varphi(t, \bar t, x, \bar u) - \bar x} = 0,\]
	ou encore~:
	\[\lim_{t \to +\infty}\varphi(t, \bar t, x, \bar u) = \bar x,\]
	pour $x \in X \tq \norm {x-\bar x} < \delta$ de la définition de stabilité.
	\end{déf}

		\subsubsection{Critère de Liapounov}

	\begin{déf} Une fonction $V : X \to \R$ est dite définie positive (respectivement négative) en $\bar x \in X$ lorsqu'il existe $\mathcal V \subseteq X$, un
	voisinage de $\bar x$ tel que~:
	\[V(\bar x) = 0 \qquad\qquad \text{ et } \qquad\qquad \forall x \in \mathcal V : V(x) > 0 \text{ (respectivement $V(x) < 0$)}.\]
	\end{déf}

	\begin{déf} Une fonction $V : X \to \R$ est dite semi-définie positive (respectivement négative) lorsque les inégalités ci-dessus ne sont pas strictes.
	\end{déf}

	\begin{déf} Soit $A \in \K^{n \times n}$ pour $n \in \N^*$, une matrice symétrique sur un corps $\K$.

	On dit que $A$ est définie positive (respectivement négative) lorsque la forme quadratique associée $x \mapsto x^TAx$ est définie positive
	(respectivement négative).

	On dit que $A$ est semi-définie positive (respectivement négative) lorsque la forme quadratique associée $x \mapsto x^TAx$ est semi-définie positive
	(respectivement négative).
	\end{déf}

	\begin{thm}[Critère de Sylvester] Soit $A \in \K^{n \times n}$, pour $n \in \N^*$, une matrice symétrique sur un corps $\K$. $A$ est définie positive
	si et seulement si~:
	\[\forall k \in \intint 1n : \det
	\begin{bmatrix}
		a_{11} & \ldots & a_{1k} \\
		\vdots & \ddots & \vdots \\
		a_{k1} & \ldots & a_{kk}
	\end{bmatrix} > 0\]
	\end{thm}

	\begin{cor} Soit $A \in \K^{n \times n}$ pour $n \in \N^*$. Si $A$ est définie positive, alors $\det(A) \neq 0$.
	\end{cor}

	\begin{thm}[Critère de stabilité de Liapounov] Soit une équation différentielle vectorielle d'ordre 1~:
	\[\od xt(t) = f(x(t), u(t)).\]
	Soit $\bar \in X$, un point d'équilibre pour l'entrée constante $t \mapsto \bar u \in U$.

	S'il existe une fonction $V : X \xrightarrow{C^1} X$ telle que~:
	\[\od Vt(x) = \scpr {\nabla V(x)}{f(x, \bar u)}\]
	semi-définie négative (respectivement définie négative) en $\bar x$, alors $\bar x$ est asymptotiquement stable (respectivement stable).
	\end{thm}

	\begin{déf} Une telle fonction $V : X \to X$ est appelée une fonction de Liapounov.
	\end{déf}

	\newpage

	\begin{thm}[Critère d'instbilité de Liapounov] Soit une équation différentielle vectorielle d'ordre 1~:
	\[\od xt(t) = f(x(t), u(t)).\]
	Soit $\bar x \in X$, un point d'équilibre pour l'entrée constante $t \mapsto \bar u \in U$.

	S'il existe une fonction $V : X \to X$ continûment dérivable sur un voisinage de $\bar x$ telle que $V$ est définie positive en $\bar x$ et~:
	\[\od Vt(x) = \scpr {\nabla V(x)}{f(x, \bar u)}\]
	est définie positive en $\bar x$, alors $\bar x$ est instable.

	\end{thm}

\end{document}
