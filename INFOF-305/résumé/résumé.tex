\documentclass{article}

\usepackage{commath}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{palatino, eulervm}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage[bottom]{footmisc}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{stmaryrd}
\usepackage{hyperref}

%%%%%  amsthm  %%%%%
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollaire}
\newtheorem{lem}[thm]{Lemme}
\addto\captionsfrench{\renewcommand\proofname{\underline{Démonstration}}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}[section]

% link amsthm and mdframed
\iftrue
%\iffalse
	% pre-amsthm
	\mdfdefinestyle{resultstyle}{%
		hidealllines=true,%
		leftline=true,%
		rightline=true,%
		innerleftmargin=10pt,%
		innerrightmargin=10pt,%
		innertopmargin=10pt,%
		innerbottommargin=8pt,%
	}

	\surroundwithmdframed[style=resultstyle]{thm}
	\surroundwithmdframed[style=resultstyle]{prp}
	\surroundwithmdframed[style=resultstyle]{cor}
	\surroundwithmdframed[style=resultstyle]{lem}
\fi

\DeclareMathOperator{\Tr}{Tr}

\newcommand{\N}{\mathbb N}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\K}{\mathbb K}
\newcommand{\tq}{\text{ t.q. }}
\newcommand{\restr}[2]{\left.#1\vphantom{\big|}\right|_{#2}}
\newcommand{\intint}[2]{{\left\llbracket#1, #2\right\rrbracket}}
\newcommand{\scpr}[2]{{\left\langle#1, #2\right\rangle}}

\title{Modélisation et simulation --- INFOF-305}
\author{R. Petit}
\date{Année académique 2016 - 2017}

\begin{document}
\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}
\setcounter{page}1

\section{Introduction aux systèmes dynamiques}
	\subsection{Généralités}

	\begin{déf} Soit $T$, \textit{l'ensemble de temps}. Selon la nature de $T$, on parle de \textit{système à temps discret}, ou de \textit{système à temps
	continu}. Les applications~:
	\[u : T \to U \subseteq \R^n \qquad\qquad \text{ et } \qquad\qquad y : T \to Y \subseteq \R^m\]
	sont respectivement appelées \textit{fonction d'entrée} et \textit{fonction de sortie}. L'application $u$ correspond aux apports que subit le système, alors
	que l'application $y$ correspond à l'observation du système.

	Le couple d'applications $(u, y)$ appartient à $\Omega \times \Gamma$, où $\Omega$ est l'ensemble des fonctions d'entrées acceptables et $\Gamma$ est
	l'ensemble des fonctions de sortie acceptables.
	\end{déf}

	\begin{rmq} $\forall (u, y) \in \Omega \times \Gamma : \forall t \in T : \left(u(t), y(t)\right) \in U \times Y$.
	\end{rmq}

	\begin{déf} On appelle variable d'état la variable $x : T \to X \subseteq \R^d$ représentant l'\textit{état interne du système} en fonction du temps.

	L'évolution du système sera décrite comme un système d'équations différentielles ou d'équations aux différences par rapport à la variable d'état.
	\end{déf}

	\begin{rmq} Le fait qu'une variable supplémentaire soit introduite induit que la connaissance de $(t_0, u, y) \in T \times \Omega \times \Gamma$ ne permet
	pas de prédire $y(t)$ pour $T \ni t > t_0$. Pour cela, il faut également connaître $x^0 \coloneqq x(t_0) \in \R^d$. Alors les théorèmes de Cauchy-Lipschitz
	sont applicables (habituellement) pour affirmer que $t \mapsto x(t)$ est une solution.
	\end{rmq}

	\begin{déf} Un système est dit \textit{statique} (ou \textit{memoryless}) lorsque la sortie ne dépend que de l'entrée, et pas de la variable d'état.
	\end{déf}

	\begin{rmq} Dans un tel système, connaitre $(t_0, u, y)$ est suffisant pour connaitre $y(t)$ pour tout $t > t_0$.
	\end{rmq}

	\begin{déf} L'application~:
	\[\varphi : T \times T \times X \times \Omega \to \R^d\]
	telle que $\forall t \in T : x(t) = \varphi(t_0, t, x^0, u)$ est appelée \textit{fonction d'état}.

	L'application~:
	\[\eta : T \times X \to Y\]
	telle que $\forall t \in T : y(t) = \eta(t, x(t))$ est appelée \textit{fonction de transformation de sortie}.
	\end{déf}

	\begin{déf} Un système dynamique se définit alors par le 8-uple suivant~:
	\[S = \left(T, U, \Omega, X, Y, \Gamma, \varphi, \eta\right).\]
	\end{déf}

	\begin{rmq} On peut donc synthétiser un système dynamique par~:
	\[u(t) \xrightarrow{\varphi(t)} x(t) \xrightarrow{\eta(t)} y(t).\]
	\end{rmq}

	\begin{prp} L'application $\varphi$ admet les propriétés suivantes~:
	\begin{itemize}
		\item consistance~: $\forall (t, x, u) \in T \times X \times \Omega : \varphi(t, t, x, u) = x$~;
		\item irréversibilité~: $\varphi$ est définie sur $[t_0, +\infty) \cap T$~;
		\item composition~: $\forall t_0 < t_1 < t_2 \in T : \forall (u, x) \in \Omega \times X : \varphi(t_2, t_0, x, u)
			= \varphi\left(t_2, t_1, \varphi\left(t_1, t_0, x, u\right), u\right)$~;
		\item causalité~: $\forall t_0 \in T : \forall u_1, u_2 \in \Omega : \left(\forall t \in T : u_1(t) = u_2(t)\right)
			\Rightarrow \left(\forall t \in T : \varphi(t, t_0, x, u_) = \varphi(t, t_0, x, u_2)\right)$.
	\end{itemize}
	\end{prp}

	\begin{déf} Soit un système dynamique régi par~:
	\[x(t) = \varphi(t, t_0, x(t_0), u).\]

	On appelle le \textit{mouvement du système} l'ensemble $\left\{(t, x(t)) \tq t \geq t_0\right\}$.

	On appelle la \textit{trajectoire du système} l'ensemble $\left\{x(t) \tq t \geq t_0\right\}$.
	\end{déf}

	\begin{rmq} La trajectoire est donc la projection du mouvement parallèlement au temps.
	\end{rmq}

	\begin{déf} Soit $\overline x \in X$. On dit que $\overline x$ est un \textit{état d'équilibre (en temps infini)} lorsque~:
	\[\exists u \in \Omega \tq \forall (t, t_0) \in T^2 : t \geq t_0 \Rightarrow \varphi(t, t_0, \overline x, u) = \overline x.\]
	\end{déf}

	\begin{déf} Soit $\overline y \in Y$. On dit que $\overline y$ est une \textit{sortie d'équilibre (en temps infini)} lorsque~:
	\[\forall t_0 \in T : \exists (x, u) \in X \times \Omega \tq \forall t \geq t_0 : \eta\left(t, \varphi(t, t_0, x, u)\right) = \overline y.\]
	\end{déf}

	\begin{déf} Un système est dit \textit{invariant} lorsque~:
	\begin{enumerate}
		\item $T$ est stable par l'addition~;
		\item $\forall (u, \delta) \in \Omega \times T : \Omega \ni u^{(\delta)} : T \to U : t \mapsto u(t-\delta)$~;
		\item $\forall (t_0, \delta, x^0) \in T \times T \times X : \forall t \geq t_0 : \varphi\left(t, t_0, x^0, u\right)
			= \varphi\left(t+\delta, t_0+\delta, x^0, u^{(\delta)}\right)$~;
		\item $y$ est indépendante de $t$, c-à-d~: $y(t) = (\eta \circ x)(t))$.
	\end{enumerate}
	\end{déf}

	\begin{déf} Soient $x^{(1)}, x^{(2)} \in X$. On dit que $x^{(2)}$ est \textit{accessible} à l'instant $t_2 \in T$ à partir de $x^{(1)}$ lorsque~:
	\[\exists (t_1, u) \in T \times \Omega \tq t_1 < t_2 \text{ et } \varphi(t_2, t_1, x^{(1)}, u) = x^{(2)}.\]
	\end{déf}

	\begin{déf} Un système est dit \textit{connexe à l'instant $t \in T$} lorsque $\forall (x^{(1)}, x^{(2)}) \in X^2 : x^{(2)}$ est accessible à l'instant
	$t$ à partir de $x^{(1)}$.

	Si un système est connexe pour tout $t \in T$, alors il est dit connexe.
	\end{déf}

	\begin{déf} Soient $x^{(1)}, x^{(2)} \in X$. On dit que $x^{(1)}$ et $x^{(2)}$ sont équivalents à l'instant $t_0 \in T$ lorsque~:
	\[\forall u \in \Omega : \forall t \geq t_0 : \eta\left(t, \varphi\left(t, t_0, x^{(1)}, u\right)\right)
		= \eta\left(t, \varphi\left(t, t_0, x^{(2)}, u\right)\right).\]
	\end{déf}

	\begin{déf} Un système est dit en \textit{forme réduite} si $\forall (x^{(1)}, x^{(2)}) \in X^2 : x^{(1)} \neq x^{(2)} \Rightarrow x^{(1)}$ n'est pas
	équivalent à $x^{(2)}$.
	\end{déf}

	\begin{déf} Soit $\hat x \in X$. L'état $\hat x$ est dit observable à l'instant $t_0 \in T$ lorsque $\exists (t, u) \in T \times \Omega \tq x(t_0)$ peut
	être retrouvé de manière univoque à l'aide de $\restr u{[t_0, t)}$ et $\restr y{[t, t_0)}$.
	\end{déf}

	\subsection{Systèmes dynamiques complexes}

	\begin{déf} Un \textit{sous-système dynamique} est un système dynamique faisant partie d'un système dynamique complexe.
	\end{déf}

	\begin{déf} Soient $S_1$ et $S_2$ deux systèmes dynamiques. $S_1$ et $S_2$ sont dits \textit{connectés en cascade} lorsque~:
	\[y_1 = u_2,\]
	c-à-d lorsque la sortie du premier système sert d'entrée au second.
	\end{déf}

	\begin{rmq} Pour que deux systèmes $S_1$ et $S_2$ soient connectés en cascade, il est nécessaire que $T_1 = T_2$, $\Gamma_1 \subseteq \Omega_2$
	(et donc $Y_1 \subseteq U_2$).
	\end{rmq}

	\begin{prp} Soient les deux systèmes dynamiques suivants~:
	\begin{align*}
		S_1 &= \left(T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1\right), \\
		S_2 &= \left(T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2\right).
	\end{align*}

	Le système dynamique résultant de la cascade de $S_1$ et $S_2$ est donné par~:
	\[S = \left(T, U_1, \Omega_1, X_1 \times X_2, Y_2, \Gamma_2, \varphi, \eta_2\right),\]
	où~:
	\begin{align*}
		&T = T_1 = T_2 \\
		&\varphi : T \times T \times (X_1 \times X_2) \times \Omega_1 \to X : \\
		&\qquad\left((t, t_0, \left(x_1(t_0), x_2(t_0)\right), u\right) \mapsto
				\left(\varphi_1\left(t, t_0, x_1(t_0), u\right), \varphi_2\left(t, t_0, x_2(t_0), y_1(t_0, x_1, u)\right)\right), \\
		&y_1(t_0, x_1, u) : T \to Y_1 \subseteq U_2 : t \mapsto \eta_1\left(t, \varphi_1\left(t, t_0 x_1(t_0), u\right)\right).
	\end{align*}
	\end{prp}

	\begin{déf} Soient $S_1$ et $S_2$ deux systèmes dynamiques. $S_1$ et $S_2$ sont dits \textit{connectés en parallèle} lorsque~:
	\[u_1 = u_2,\]
	c-à-d lorsqu'ils ont la même fonction d'entrée.
	\end{déf}

	\begin{rmq} Pour que deux systèmes dynamiques soient connectés en parallèle, il est nécessaire que $T_1 = T_2$, $\Omega_1 = \Omega_2$ (et donc $U_1 = U_2$).
	\end{rmq}

	\begin{prp} Soient les deux systèmes dynamiques suivants~:
	\begin{align*}
		S_1 &= \left(T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1\right), \\
		S_2 &= \left(T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2\right).
	\end{align*}

	Le système dynamique résultant des systèmes $S_1$ et $S_2$ en parallèle est donné par~:
	\[S = \left(T, U, \Omega, X_1 \times X_2, Y_1 \times Y_2, \Gamma_1 \times \Gamma_2, \varphi, \eta\right),\]
	où~:
	\begin{align*}
		T &= T_1 = T_2 \\
		U &= U_1 = U_2 \\
		\Omega &= \Omega_1 = \Omega_2 \\
		\varphi &: (t, t_0, x, u) \mapsto \left(\varphi_1(t, t_0, x, u), \varphi_2(t, t_0, x, u)\right) \\
		\eta &: \left(t, (x_1, x_2)\right) \mapsto \left(\eta_1(t, x_1), \eta_2(t, x_2)\right)
	\end{align*}
	\end{prp}

	\subsection{Rétroaction}

	\begin{déf} Deux systèmes $S_1 = (T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1)$ et $S_2 = (T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2)$
	sont dits en rétroaction l'un sur l'autre lorsqu'il existe $v_1 : T \to U_1, v_2 : T \to U_2$ et~:
	\[\psi_1 : Y_1 \times U_2 \times T \to U_2 \qquad\qquad \text{ et } \qquad\qquad \psi_2 : Y_2 \times U_1 \times T \to U_1\]
	tels que~:
	\begin{align*}
		u_1(t) &= \psi_2\left(y_1(t), v_2(t), t\right) \\
		u_2(t) &= \psi_1\left(y_2(t), v_1(t), t\right).
	\end{align*}
	\end{déf}

	\begin{déf} On parle de \textit{rétroaction négative} lorsqu'une modification de $y_1(t)$ entraine une modification de $y_2(t)$ qui s'oppose au changement
	de $y_1(t)$.

	De même, on parle de \textit{rétroaction positive} lorsqu'une modification de $y_1(t)$ entraine une modification de $y_2(t)$ qui amplifie le changement de
	$y_2(t)$.
	\end{déf}

	\begin{rmq} Ce type de construction est le plus simple contenant une boucle.

	De plus, il est ici question de rétroaction sur la sortie. Il peut être plus intéressant de définir une rétroaction sur l'état.
	\end{rmq}

	\begin{déf} Un système est dit \textit{rétroactionné sur l'état} lorsqu'il existe $v : T \to U$ et $\psi : X \times U \times T \to U$ tels que~:
	\[u(t) = \psi\left(x(t), v(t), t\right).\]

	Cette fonction $\psi$ est appelée \textit{loi de contrôle}.
	\end{déf}

\section{Automates --- systèmes à temps discret et et à espace d'états discret}
	\begin{déf} Un \textit{automate} est un système dynamique invariant à temps discret et avec un espace d'états discret, et où les ensembles d'entrée et de
	sortie sont finis.
	\end{déf}

	\begin{déf} Un automate est dit \textit{fini} lorsque l'espace d'états est fini.
	\end{déf}

	\begin{prp} Dans un système dynamique invariant à temps discret, la fonction $\varphi$ de transition peut être remplacée par~:
	\[x(t+1) = \delta(x(t), u(t)),\]
	et la fonction de transformation de sortie peut être remplacée par~:
	\[y(t) = \eta(x(t)),\]
	ce qui implique que l'observation du système dépend uniquement de l'état, et que l'état à un certain instant ne dépend plus que de la valeur à l'état
	précédent (modèle markovien).
	\end{prp}

	\begin{déf} Un automate \textit{cellulaire} de dimension $(n_1, \ldots, n_k) \in {\N^*}^k$ est un automate tel que $X = \chi^{\prod_{i=1}^kn_i}$, où $\chi$
	est un ensemble fini d'états tel que~:
	\[\forall \alpha \in {\N^*}^k : \left(\forall 1 \leq j \leq k : 1 \leq \alpha_j \leq n_k\right) \Rightarrow \left(\forall t \in T : x_\alpha(t) \in \chi\right),\]
	et tel que $x(t+1) = (\delta \circ x)(t)$, à savoir, aucune entrée $u \in \Omega$ n'est présente.

	Les telles valeurs $x_\alpha$ sont appelées les cellules de l'automate.
	\end{déf}

	\begin{rmq} Dans un automate cellulaire, la nombre de variables d'états est vite très grand, mais reste toute fois fini.
	\end{rmq}

	\begin{déf} la fonction de transition d'un automate cellulaire $\delta : X \times U \to X$ est une fonction à valeurs dans $X = \chi^{\prod_{i=1}^kn_i}$.
	Chaque fonction $\delta_\alpha$ telle que $x_\alpha(t+1) = \delta_\alpha(x(t))$ est défini sur un \textit{voisinage} de $\alpha \in {\N^*}^k$. Et donc,
	on peut écrire $x_\alpha(t+1) = \delta_\alpha\left(\gamma(x(t), \alpha)\right)$, où $\gamma : X \times {\N^*}^k$ est une fonction renvoyant uniquement
	un sous-ensemble (non-strict) de $x(t) \in X$.
	\end{déf}

	\begin{ex} Un automate cellulaire de dimension $(n_1, n_2) \in \N^* \times \N^*$ représente donc une \textit{grille} de cellules, où l'état de chaque cellule
	$x_{i\,j}$ à l'instant $t+1 \in T$ ne dépend que d'un voisinage de $(i, j) \in \N^* \times \N^*$. Par exemple, dans le jeu de la vie (J. Conway), le
	voisinage de $(i, j)$ est défini par~:
	\[\left\{(k, \ell) \in \N^* \times \N^* \tq \abs {k-i} = \abs {\ell-j} = 1\right\}.\]
	\end{ex}

	\begin{rmq} Ces systèmes dynamiques que représentent les automates cellulaires (finis) font partie des systèmes complexes suite à leur grand nombre de
	variables d'état. Ils ont entre autre prouvé que des règles simples et déterministes pouvaient engendrer un comportement très compliqué à décrire et à
	prédire. En effet, un \textit{simple} automate cellulaire de dimension $(n_1, n_2) \in \N^* \times \N^*$ peut produire plusieurs comportements distincts
	et simultanés dans plusieurs voisinages de cellules, certains périodiques, d'autres erratiques.
	\end{rmq}

\section{Systèmes continus}
	Dans cette section, on considère l'espace $T = [t_0, +\infty) \subset \R$, pour $t_0 \in \R^+$, et donc continu.

	\subsection{Systèmes réguliers}

	\begin{déf} Un système dynamique $S$ est dit \textit{de dimensionnalité finie} lorsque les ensembles $U, X$ et $Y$ sont des espaces vectoriels de dimension
	finie (pas nécessairement la même dimension), i.e. $\exists n_1, n_2, n_3 \in \N^*$ tels que $(U, X, Y) = (\K_1^{n_1}, \K_2^{n_2}, \K_3^{n_3})$, où
	les $\K_i$ sont des corps (habituellement $\K \in \{\R, \C\}$).
	\end{déf}

	\begin{rmq} Nous ferons ici l'hypothèse que ces espaces vectoriels sont normés, afin de pouvoir définir une distance~:
	\[\forall a, b \in \K^d : d_\K(a, b) = \norm {a-b}_\K,\]
	où $\norm \cdot_\K : \K \to \R$ est la norme de l'espace vectoriel normé $(\K, \norm \cdot_\K)$.
	\end{rmq}

	\begin{déf} Un système dynamique continu de dimensionnalité finie est dit \textit {régulier} lorsque~:
	\begin{itemize}
		\item les espaces $U, X, Y, \Omega, \Gamma$ sont des espaces vectoriels normés~;
		\item la fonction de transition $\varphi$ est continue sur $T \times T \times X \times \Omega$~;
		\item la fonction de transition $\varphi$ est continûment dérivable par rapport au temps sur le sous-ensemble de définition de $u \in \Omega$ où
			$u$ est continue~;
		\item la fonction $\eta$ est continue sur $X \times T$.
	\end{itemize}
	\end{déf}

	\begin{rmq} On fait ici les hypothèses de régularité suffisantes pour lier les systèmes dynamiques continus aux équations différentielles ordinaires, donc
	ici en particulier, afin d'assurer l'existence d'une solution maximale unique, il est nécessaire de supposer $\od \varphi t$ localement lipschitzienne sur $X$
	en plus de sa continuité (théorème de Cauchy-Lipschitz local).
	\end{rmq}

	L'équation différentielle vectorielle du premier ordre $\od xt = f(x(t), u(t), t)$ peut se réécrire indépendamment selon les composantes\footnote{Toute
	équation vectorielle, peu importe son degré, peut se réécrire comme une équation différentielle vectorielle d'ordre 1.}~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t), t) \\
		\od {x_2}t(t) &= f_2(x(t), u(t), t) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t), t),
	\end{cases}\]
	où $n$ est la dimension d'arrivée de $f$, et donc la dimensionnalité de $X$.

	\begin{thm} Pour $t_0 \in T$ fixé, le mouvement $t \mapsto \varphi(t, t_0, x^{(0)}, u)$ pour $x^{(0)} = x(t_0)$ d'un système dynamique régulier est solution
	unique maximale d'une équation différentielle de la forme~:
	\begin{align}\label{eq:equadiffvec}
		\od xt = f(x(t), u(t), t).
	\end{align}
	\end{thm}

	\begin{déf} Dans l'équation~\eqref{eq:equadiffvec}, la fonction $f : X \times U \times T \to X$ est appelée \textit{fonction génératrice du système}.
	\end{déf}

	\begin{rmq} Il est souvent très difficile (voire impossible) de déterminer analytiquement la solution d'un système exprimé sous forme différentielle
	(équation~\eqref{eq:equadiffvec}). Dans ces cas, la simulation numérique est requise.
	\end{rmq}

	\begin{déf} Un système régulier est dit \textit{autonome} lorsque $\od xt = f(x(t))$, c'est-à-dire lorsque $f$ ne fait pas intervenir le temps explicitement.
	\end{déf}

	\begin{prp} Tout système d'équations différentielles peut être mis sous forme autonome.
	\end{prp}

	\begin{proof} Le système suivant~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t), t) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t), t)
	\end{cases}\]
	peut être réécrit comme suit~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t)) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t)) \\
		\od {x_{n+1}}t(t) &= \od tt = 1
	\end{cases}\]
	\end{proof}

	\subsection{Espace et portrait de phases}

	\begin{déf} L'espace d'états $X$ est également appelé \textit{espace des phases}, dans lequel tout état $x \in X$ représente un point $(x_1, \ldots, x_n) \in X$
	de l'espace des phases.
	\end{déf}

	\begin{rmq} Selon cette définition, la trajectoire d'un système représente donc la projection du mouvement dans l'espace des phases, ce qui correspond à
	une courbe de dimension 1 dans $X$.
	\end{rmq}

	\begin{déf} On appelle \textit{portrait de phases} la représentation du champ de vecteurs $f : X \times U \times T \to X$ dans l'espace des phases.
	\end{déf}

	\begin{rmq} Le portrait de phases d'un système donne une représentation qualitative de l'évolution du système. Cette représentation est très pratique du fait
	qu'elle ne requiert rien d'autre que la fonction $f$, génératrice du système, qui est connue. Il est donc toujours possible de dessiner un portrait de phases,
	même lorsqu'il est impossible de résoudre analytiquement l'équation.

	Afin de rendre l'information encore plus qualitative, il est commun de renormaliser tous les vecteurs du champ lors de la représentation. Ainsi, toute
	information sur $t$ est perdue (ce qui ne change rien dans le cas d'un système autonome).
	\end{rmq}

	\subsection{Stabilité des points d'équilibre}

	La stabilité est la notion qui va permettre de classifier les points d'équilibre selon leur comportement induit suite à des perturbations.

	\begin{déf} Soient $(\bar t, \bar x, \bar u) \in T \times X \times \Omega$. Le mouvement $t \mapsto \varphi(t, \bar t, \bar x, \bar u)$ d'un système $S$
	est dit \textit{stable} lorsque~:
	\[\forall \varepsilon > 0 : \exists \delta > 0 \tq \forall x \in X : \left(\norm {x-\bar x} < \delta\right) \Rightarrow
		\left(\forall t \in T : t \geq \bar t \Rightarrow \norm {\varphi(t, \bar t, \bar x, \bar u) - \varphi(t, \bar t, x, \bar u)} < \varepsilon\right).\]

	Si un mouvement n'est pas stable, il est dit \textit{instable}.
	\end{déf}

	\begin{déf} Soit $(\bar x, \bar u, \bar t) \in X \times \Omega \times T$, où $\bar x$ est un point d'équilibre pour $\bar u$ à l'instant $\bar t$.
	Le point d'équilibre $\bar x$ est dit \textit{stable} lorsque~:
	\[\forall \varepsilon > 0 : \exists \delta > 0 \tq \forall x \in X : \left(\norm {x-\bar x} < \delta\right) \Rightarrow
		\left(\forall t \in T : t \geq \bar t \Rightarrow \norm {\varphi(t, \bar t, x, \bar u) - \bar x} < \varepsilon\right).\]
	\end{déf}

	\begin{déf} Un point d'équilibre $\bar x \in X$ pour une entrée $\bar u \in \Omega$ à l'instant $\bar t \in T$ est dit \textit{asymptotiquement stable}
	lorsqu'il est stable, et~:
	\[\lim_{t \to +\infty}\norm {\varphi(t, \bar t, x, \bar u) - \bar x} = 0,\]
	ou encore~:
	\[\lim_{t \to +\infty}\varphi(t, \bar t, x, \bar u) = \bar x,\]
	pour $x \in X \tq \norm {x-\bar x} < \delta$ de la définition de stabilité.
	\end{déf}

		\subsubsection{Critère de Liapounov}

	\begin{déf} Une fonction $V : X \to \R$ est dite définie positive (respectivement négative) en $\bar x \in X$ lorsqu'il existe $\mathcal V \subseteq X$, un
	voisinage de $\bar x$ tel que~:
	\[V(\bar x) = 0 \qquad\qquad \text{ et } \qquad\qquad \forall x \in \mathcal V : V(x) > 0 \text{ (respectivement $V(x) < 0$)}.\]
	\end{déf}

	\begin{déf} Une fonction $V : X \to \R$ est dite semi-définie positive (respectivement négative) lorsque les inégalités ci-dessus ne sont pas strictes.
	\end{déf}

	\begin{déf} Soit $A \in \K^{n \times n}$ pour $n \in \N^*$, une matrice symétrique sur un corps $\K$.

	On dit que $A$ est définie positive (respectivement négative) lorsque la forme quadratique associée $x \mapsto x^TAx$ est définie positive
	(respectivement négative).

	On dit que $A$ est semi-définie positive (respectivement négative) lorsque la forme quadratique associée $x \mapsto x^TAx$ est semi-définie positive
	(respectivement négative).
	\end{déf}

	\begin{thm}[Critère de Sylvester] Soit $A \in \K^{n \times n}$, pour $n \in \N^*$, une matrice symétrique sur un corps $\K$. $A$ est définie positive
	si et seulement si~:
	\[\forall k \in \intint 1n : \det
	\begin{bmatrix}
		a_{11} & \ldots & a_{1k} \\
		\vdots & \ddots & \vdots \\
		a_{k1} & \ldots & a_{kk}
	\end{bmatrix} > 0\]
	\end{thm}

	\begin{cor} Soit $A \in \K^{n \times n}$ pour $n \in \N^*$. Si $A$ est définie positive, alors $\det(A) \neq 0$.
	\end{cor}

	\begin{thm}[Critère de stabilité de Liapounov] Soit une équation différentielle vectorielle d'ordre 1~:
	\[\od xt(t) = f(x(t), u(t)).\]
	Soit $\bar \in X$, un point d'équilibre pour l'entrée constante $t \mapsto \bar u \in U$.

	S'il existe une fonction $V : X \xrightarrow{C^1} X$ telle que~:
	\[\od Vt(x) = \scpr {\nabla V(x)}{f(x, \bar u)}\]
	semi-définie négative (respectivement définie négative) en $\bar x$, alors $\bar x$ est asymptotiquement stable (respectivement stable).
	\end{thm}

	\begin{déf} Une telle fonction $V : X \to X$ est appelée une fonction de Liapounov.
	\end{déf}

	\newpage

	\begin{thm}[Critère d'instbilité de Liapounov] Soit une équation différentielle vectorielle d'ordre 1~:
	\[\od xt(t) = f(x(t), u(t)).\]
	Soit $\bar x \in X$, un point d'équilibre pour l'entrée constante $t \mapsto \bar u \in U$.

	S'il existe une fonction $V : X \to X$ continûment dérivable sur un voisinage de $\bar x$ telle que $V$ est définie positive en $\bar x$ et~:
	\[\od Vt(x) = \scpr {\nabla V(x)}{f(x, \bar u)}\]
	est définie positive en $\bar x$, alors $\bar x$ est instable.
	\end{thm}

\section{Systèmes dynamiques linéaires à temps continu}

	\begin{déf} On définit le \textit{mouvement libre} d'un système comme étant la fonction~:
	\[\varphi_\ell : T \times T \times X \to X : (t, t_0, x^{(0))} \mapsto \varphi(t, t_0, x^{(0)}, \mathbf{0}),\]
	avec $\mathbf{0} : t \mapsto 0$, la fonction nulle.

	On définit le \textit{mouvement forcé} d'un système comme étant la fonction~:
	\[\varphi_f : T \times T \times \Omega \to X : (t, t_0, u) \mapsto \varphi(t, t_0, 0_X, u),\]
	avec $0_X$, l'élément neutre de $X$ (qui existe car $X$ est un espace vectoriel).
	\end{déf}

	\begin{prp} Dans un système linéaire, la fonction de transition $\varphi$ est linéaire par rapport à $x \in X$, et $u \in \Omega$, et $\varphi$
	est superposable par $\varphi_\ell$ et $\varphi_f$, i.e.~:
	\begin{align*}
		&\forall \lambda, \mu, \gamma, \delta \in \K : \forall (t, t_0) \in T^2 : \forall (x^{(1)}, x^{(2)}) \in X^2 : \forall (u_1, u_2) \in \Omega : \\
		&\varphi\left(t, t_0, \lambda x^{(1)} + \mu x^{(2)}, \gamma u_1 + \delta u_2\right) =
			\lambda \varphi_\ell(t, t_0, x^{(1)}) + \mu \varphi_\ell(t, t_0, x^{(2)}) + \gamma \varphi_f(t, t_0, u_1) + \delta \varphi_f(t, t_0, u_2).
	\end{align*}
	\end{prp}

	\begin{prp} Dans un système linéaire, la fonction de transformation de sortie $\eta : X \to Y$ est linéaire par rapport à $x \in X$ pour tout $t \in T$, i.e.~:
	\[\forall t \in T : \eta(x(t)) = H(t)x(t),\]
	pour $H : T \to \K^{n \times n}$ et $n = \dim(X) \in \N^*$.
	\end{prp}

	\begin{thm} Tout système dynamique linéaire régulier à temps continu peut être exprimé sous la forme~:
	\begin{align}
		\begin{cases}
			\od xt(t) &= A(t)x(t) + B(t)u(t) \\
			y(t) &= C(t)x(t),
		\end{cases}
	\end{align}
	avec $A : T \to \K^{\dim(X) \times \dim(X)}$, $B : T \to \K^{\dim(X) \times \dim(U)}$, et $C : T \to \K^{\dim(Y) \times \dim(X)}$, toutes trois continues
	en temps.
	\end{thm}

	\begin{rmq} Le cas des systèmes linéaires autonomes (où les fonctions $A, B, C$ sont constantes) est \textit{simple} à résoudre analytiquement (au sens où
	il existe une solution qu'il est possible de déterminer \textit{à la main}).
	\end{rmq}

	\begin{thm} Dans un système dynamique linéaire, la stabilité (respectivement instabilité) d'un mouvement en particulier implique la stabilité (respectivement
	l'instabilité) de tous les mouvements.
	\end{thm}

	\begin{proof} Soient $\hat x : T \to X$ et $\tilde x : T \to X$, les mouvements associés à l'entrée $\bar u \in \Omega$ et à l'état initial respectivement
	$x^{(1)} \in X$ et $x^{(2)} \in X$. On pose~:
	\[z : T \to X : t \mapsto \hat x(t) - \tilde x(t).\]

	Le mouvement $z$ correspond donc, par linéarité, à~:
	\[z(t) = \varphi(t, t_0, x^{(1)}, \bar u) - \varphi(t, t_0, x^{(2)}, \bar u) = \varphi(t, t_0, x{(1)}-x^{(2)}, \mathbf{0}) = \varphi_f(t, t_0, x^{(1)}-x^{(2)}).\]

	On sait cependant~:
	\[\begin{cases}
		\od {\hat x}t(t) &= A(t)\hat x(t) + B(t)\bar u(t) \\
		\od {\tilde t}t(t) &= A(t)\tilde x(t) + B(t)\bar u(t).
	\end{cases}\]

	Dès lors, on détermine la dynamique de $z$~:
	\[\od zt(t) = \od {\hat x}t(t) - \od {\tilde x}t(t) = A(t)\hat x(t) + B(t)\bar u(t) - A(t)\tilde x(t) - B(t)\bar u(t) = A(t)\left(\hat x(t) - \tilde x(t)\right) = A(t)z(t),\]
	qui a l'origine pour point fixe.

	Dès lors, en étudiant la stabilité de l'origine, on a la stabilité de tous les mouvements du système.
	\end{proof}

	\begin{cor} Dans un système dynamique linéaire, l'étude de stabilité ne dépend que de la matrice $A(t)$.
	\end{cor}

	\begin{déf} Un système dynamique linéaire est dit \textit{simplement stable} lorsque pour tout $x^{(0)} \in X$, le mouvement libre
	$t \mapsto \varphi_\ell(t, t_0, x^{(0)})$ est borné.

	Un système dynamique linéaire non stable est dit \textit{instable}.
	\end{déf}

	\begin{déf} Un système dynamique linéaire est dit \textit{asymptotiquement stable} lorsque~:
	\[\forall x^{(0)} \in X : \lim_{t \to +\infty}\varphi_\ell(t, t_0, x^{(0)}) = 0_X.\]
	\end{déf}

	\subsection{Stabilité et valeurs propres}

	\begin{déf} Soit $A \in \K^{n \times n}$ une matrice. On définit son polynôme caractéristique par~:
	\[\pi(A) \coloneqq \det(A - \lambda I).\]

	On appelle \textit{valeur propre} de $A$ tout $\lambda^* \in \K$ tel que $(\lambda - \lambda^*)$ divise $\pi(A)$.

	On appelle \textit{vecteur propre} de $A$ tout $v \in \K^n$ tel qu'il existe une valeur propre $\lambda$ avec $Av = \lambda v$.
	\end{déf}

	\begin{thm}[Stabilité d'un système linéaire selon les valeurs propres] Soit le système dynamique linéaire $\od xt(t) = A(t)x(t)$. Alors~:
	\begin{enumerate}
		\item le système est asymptotiquement stable si et seulement si toutes les valeurs propres de $A$ sont de partie réelle négative~;
		\item le système est simplement stable si toutes les valeurs propres ont soit une partie réelle négative, soit nulle mais sont de multiplicité 1~;
		\item le système est instable sinon.
	\end{enumerate}
	\end{thm}

	\begin{rmq} Il n'est pas toujours nécessaire de calculer toutes les valeurs propres de $A$ afin de déterminer la stabilité du système. Il existe certains
	critères pour le signe des valeurs propres.
	\end{rmq}

	\begin{thm}[Test de Hurwitz] Soit $A \in \K^{n \times n}$, pour $n = \dim(X) \in \N^*$. Soit $\pi(A)$ le polynôme caractéristique de $A$ tel que~:
	\[\pi(A)(\lambda) = \sum_{i=0}^na_i\lambda^{n-i},\]
	avec $a_0 = (-1)^n$. En posant $a_k = 0$ pour tout $k \gneqq n = \dim(X)$ et pour tout $k < 0$, on a que les valeurs propres de $A$ sont toutes de partie
	réelle négative si et seulement si~:
	\[H = [a_{2i-j}]_{1 \leq i,j \leq n}\]
	n'admet que des mineurs principaux positifs, i.e.~:
	\[\forall k \in \intint 1n : \det\left([a_{2i-j}]_{1 \leq i, j \leq k}\right) > 0.\]
	\end{thm}

	\begin{prp} Si tous les $a_i$, coefficients du polynôme caractéristique $\pi(A)$ ne sont pas de même signe (i.e. s'il en existe deux de signe différent),
	alors le système dynamique linéaire associé à $A$ n'est pas asymptotiquement stable.
	\end{prp}

	\begin{prp}[Formule de Souriau] Soit $A \in \K^{n \times n}$ une matrice. Les coefficients du polynôme~:
	\[\det(\lambda I - A) = (-1)^n\det(A - \lambda I) = \lambda^n\sum_{i=1}^n\lambda^{n-i}a_i,\]
	où $n = \dim(X)$, sont donnés par~:
	\[a_n = -\frac 1n\left(\Tr(A^n) + \sum_{k=1}^{n-1}a_k\Tr(A^{n-k})\right)\]
	\end{prp}

	\begin{rmq} La formule de Souriau permet de ne pas calculer le déterminant (complexité $O(n^3)$) pour de grandes matrices.
	\end{rmq}

	\begin{prp} Soit $A \in \K^{n \times n}$. Si $\lambda_1, \ldots, \lambda_p$ sont les valeurs propres de $A$, alors~:
	\[\sum_{i=1}^p\lambda_i = \Tr(A).\]
	\end{prp}

	\begin{proof} Par décomposition en blocs de Jordan (ou diagonalisation, si toutes les valeurs propres sont de multiplicité 1), on a~:
	\[A = PJP^{-1}.\]
	Par les propriétés de manipulation de trace, on a~:
	\[\Tr(A) = \Tr(PJP^{-1}) = \Tr(JP^{-1}P) = \Tr(J) = \sum_{i=1}^n\lambda_i.\]
	\end{proof}

	\begin{cor} Si un système dynamique linéaire $\od xt(t) = A(t)x(t)$ est asymptotiquement stable, alors $\Re\Tr(A) < 0$.
	\end{cor}

	\begin{proof} Un système linéaire est asymptotiquement stable si et seulement si toutes ses valeurs propres sont de partie réelle négative.
	On détermine donc~:
	\[\Tr(A) = \sum_{j=1}^n\lambda_j = \sum_{j=1}^n\Re\lambda_j + i\Im\lambda_j = \sum_{j=1}^n\Re\lambda_i + i\sum_{j=1}^n\Im\lambda_j.\]

	Et donc~:
	\[\Re\Tr(A) = \sum_{j=1}^n\Re\lambda_j < 0.\]
	\end{proof}

	\subsection{Systèmes linéaires du premier ordre}

	Soit $\od xt(t) = ax(t)$, pour $x : T \to R$ et $a \in \R$. La solution de cette équation est $x(t) = x(t_0)\exp(a(t-t_0))$. $x=0$ est un point d'équilibre du
	système. Pour $a < 0$, ce point d'équilibre est asymptotiquement stable, pour $a=0$, le système est simplement stable, et pour $a > 0$, le système est
	instable.

	\begin{déf} Dans le cas de stabilité asymptotique, quand $a < 0$, on définit $\tau \coloneqq \frac {-1}a \in \R_0^+$, que l'on appelle
	\textit{constante de temps}.
	\end{déf}

	\begin{rmq} Pour de grandes valeurs de $a$ (en valeur absolue), $\tau$ se rapprochera de 0, et donc le mouvement tend \textit{vite} vers l'origine, alors
	que pour de faibles valeurs de $a$ (toujours en valeur absolue), $\tau$ sera grand, et donc le mouvement tendra \textit{lentement} vers l'origine.

	On considère de manière générale que l'équilibre est atteint après un temps $\Delta t = 4\tau$. En effet~:
	\[x(t_0 + 4\tau) = x(t_0)\exp(a(t_0+4\tau-t_0)) = x(t_0)\exp(4a\tau) = x(t_0)\exp(-4) \simeq \frac {x(t_0)}{50}.\]

	On considère donc que proportionnellement, la valeur est suffisamment proche de l'origine.
	\end{rmq}

	Les comportements ici sont très restreints~: soit les trajectoires se rapprochent du point fixe ($x=0$), soit elles s'en éloignent, selon qu'il soit stable
	ou instable.

	\subsection{Systèmes linéaires autonomes du second ordre}

	Soit le système dynamique linéaire du second ordre suivant~:
	\[\begin{bmatrix}\od {x_1}t(t) \\\od {x_2}t(t)\end{bmatrix} = \od xt(t) = Ax(t)
		= \begin{bmatrix}a_{11} & a_{12} \\a_{21} & a_{22}\end{bmatrix}\begin{bmatrix}x_1(t) \\ x_2(t)\end{bmatrix}.\]

	\begin{déf} le système est dit \textit{simple} lorsque la matrice $A$ est non-singulière et est dit \textit{non-simple} sinon.
	\end{déf}

	\begin{prp} Un système dynamique linéaire du second ordre simple admet un unique point fixe, à savoir $(x_1, x_2) = (0, 0) = 0_X$.

	Un système dynamique linéaire du second ordre non-simple admet une infinité de points fixes représentant une droite vectorielle passant par l'origine.
	\end{prp}

	\begin{proof} Soit $A$ non-singulière. On sait donc que $A^{-1}$ existe. Dès lors, en multipliant $\od xt(t) = Ax(t)$ par $A^{-1}$ à gauche, on trouve~:
	\[A^{-1}\od xt(t) = x(t).\]

	Or, si $x(t)$ est un point fixe, on sait $\od xt(t) = 0$. Donc $x(t) = A^{-1}\od xt(t) = A^{-1}[0, 0]^T = [0, 0]^T$ est l'unique solution.

	Supposons maintenant $\det A = 0$. Ça implique que les deux lignes ou les deux colonnes de $A$ sont multiples l'une de l'autre. Il y a donc un degré de
	liberté au système, mais $(0, 0)$ reste une solution. Le système admet donc une infinité de points fixes placés sur une droite vectorielle passant par
	l'origine.
	\end{proof}

	\begin{prp} Le polynôme caractéristique de la matrice $A$ est équivalent à~:
	\[\pi(A)(\lambda) = \lambda^2 - \Tr(A) + \det(A).\]
	\end{prp}

	\begin{proof} Le polynôme caractéristique est donné par~:
	\[\pi(A)(\lambda) = (a_{11}-\lambda)(a_{22}-\lambda) - (a_{12}a_{21}) = \lambda^2 - (a_{11} + a_{22})\lambda + (a_{11}a_{22} - a_{21}a_{12}).\]

	On observe donc~:
	\[a_{11} + a_{22} = \Tr(A)\]
	et~:
	\[a_{11}a_{22} - a_{21}a_{12} = \det(A).\]

	On a alors en effet~:
	\[\pi(A)(\lambda) = \lambda^2 - \Tr(A)\lambda + \det(A).\]
	\end{proof}

	\begin{thm} Les solutions d'un système d'équations différentielles (pas nécessairement linéaires ou autonomes) est un espace vectoriel. En particulier,
	la combinaison linéaire de solutions sont également solutions.
	\end{thm}

	\subsection{Trajectoires et valeurs propres distinctes}

	Les axes des vecteurs propres sont des invariants. En effet, si $x(t)$ est un vecteur propre, alors $\od xt(t) = \lambda x(t)$, et donc $x(t)$
	et $\od xt(t)$ \textit{pointent} dans la même direction. Les vecteurs propres évoluent donc dans une trajectoire rectiligne (et se dirigent soit vers l'infini
	soit vers l'origine selon que l'origine soit stable ou non).

	Si $\lambda_1$ et $\lambda_2$ sont les deux valeurs propres de la matrice $A$ et si $v_1$ et $v_2$ sont les vecteurs propres associés, alors on
	a deux solutions distinctes et linéairement indépendantes~:
	\[t \mapsto \exp(\lambda_1t)v_1 \qquad\qquad \text{ et } \qquad\qquad t \mapsto \exp(\lambda_2t)v_2.\]

	La solution générale est donc~:
	\[t \mapsto C_1\exp(\lambda_1t)v_1 + C_2\exp(\lambda_2t)v_2,\]
	pour $C_1, C_2 \in \K$.

	\begin{prp} Pour $t \to +\infty$ (respectivement $t \to -\infty$), la trajectoire s'aligne avec le vecteur propre le plus lent (respectivement le plus rapide).
	\end{prp}

	\begin{proof} Soient $\lambda_1, \lambda_2$ les deux valeurs propres de $A$, telles que $\lambda_1 < \lambda_2$ (changer les indices si nécessaire, donc
	sans perte de généralité). On a alors~:
	\[\lim_{t \to +\infty}\frac {x_1(t)}{x_2(t)} = \lim_{t \to +\infty}\frac {C_2\exp(\lambda_2t)v_{21}}{C_2\exp(\lambda_2t)v_{22}} = \frac {v_{21}}{v_{22}}.\]

	De même, on trouve~:
	\[\lim_{t \to -\infty}\frac {x_1(t)}{x_2(t)} = \lim_{t \to -\infty}\frac {C_1\exp(\lambda_1t)v_{11}}{C_1\exp(\lambda_1t)v_{12}} = \frac {v_{11}}{v_{12}}.\]

	On en déduit donc qu'en $t \to +\infty$, la trajectoire s'aligne sur $v_2$, le vecteur propre lié à la valeur propre la plus lente, et pour $t \to -\infty$,
	la trajectoire s'aligne sur $v_1$, le vecteur propre lié à la valeur propre la plus rapide.
	\end{proof}

	\begin{déf} Si les deux valeurs propres de la matrice $A$ sont de partie réelle de signe opposé, alors l'origine est un état d'équilibre instable, que l'on
	appelle \textit{col} (ou encore \textit{nœud de selle}, \textit{saddle node} en anglais).

	Si les deux valeurs propres sont de partie réelle négative, alors l'origine est un état d'équilibre stable appelé \textit{nœud stable}.

	Si les deux valeurs propres sont de partie réelle positive, alors l'origine est un état d'équilibre instable et est appelé \textit{nœud instable}.
	\end{déf}

	\begin{rmq} Si le point d'équilibre est une selle, alors on trouve que $\det(A) = \lambda_1\lambda_2 < 0$ car les valeurs propres sont de signe opposé. Dans
	les deux autres cas, le déterminant est de signe positif. Mais c'est le signe de la trace qui change. Dans le cas de la selle, on ne peut rien prévoir sur
	le signe de la trace. La trace peut tout à fait être positive, négative, voire nulle.
	\end{rmq}

	\subsubsection{Systèmes non-simples}

	Les systèmes non-simples sont de déterminant nul. Or, comme $\det(A) = \lambda_1\lambda_2$, on sait qu'une des valeurs propres est nulle. Posons
	$\lambda_1 = 0$, et intéressons-nous à $\lambda_2$.

	\begin{prp} Si une des deux valeurs propres est nulle, alors la droite de points fixes est donnée par~:
	\[a_{11}x_1 + a_{12}x_2 = 0.\]

	De plus, toutes les trajectoires sont parallèles à $v_2$, le vecteur propre associé à la valeur propre $\lambda_2$, et les points fixes sont stables si et
	seulement si $\Re\lambda_2 < 0$.
	\end{prp}

	\subsection{Trajectoires et valeurs propres identiques (non-distinctes)}

	\begin{déf} Si $A$ est diagonalisable (et donc tous les vecteurs sont des vecteurs propres), et $\lambda_1 = \lambda_2 = \lambda \neq 0$, alors l'origine
	est un état d'équilibre que l'on appelle \textit{nœud singulier}.

	Si $A$ n'est pas diagonalisable (et donc il existe un seul vecteur propre, et donc une seule trajectoire en droite), l'origine est un état d'équilibre
	que l'on appelle \textit{nœud dégénéré}.
	\end{déf}

	\begin{rmq} Un nœud singulier ou un nœud dégénéré est stable si et seulement si $\lambda < 0$ (théorème de stabilité selon les valeurs propres, avec une
	seule valeur propre de partie réelle nulle).
	\end{rmq}


	\begin{rmq} Si $\lambda_1 = \lambda_2 = \lambda = 0$ est l'unique valeur propre, et de multiplicité 2, alors il existe une infinité d'états d'équilibre
	n'ayant pas de nom particulier mais dont toutes les trajectoires sont sur des droites parallèles.
	\end{rmq}

	\subsection{Trajectoires et valeurs propres complexes}

	\begin{prp}\label{prp:polynômeracinecomplexeconjugée} Soit $P$ un polynôme à coefficients réels. Si $\lambda \in \C$ est tel que $P(\lambda) = 0$, alors
	$P(\bar \lambda) = 0$.
	\end{prp}

	\begin{proof} Soit $n \in \N$ et soient $(a_i)_{0 \leq i \leq n} \in \R^n$ Notons $P : \C \to \C : x \mapsto \sum_{i=0}^na_ix^i$.
	Soit $\lambda \in \C$, une racine de $P$. On a~:
	\[P(\overline \lambda) = \sum_{i=1}^na_i\overline {\lambda^i} = \overline {\sum_{i=1}^na_i\lambda^i} = \overline {P(\lambda)} = \overline 0 = 0.\]
	\end{proof}

	\begin{cor} Tout polynôme de degré impair admet au moins une racine réelle.
	\end{cor}

	\begin{rmq} Ce qui peut également se démontrer par le théorème de Rolle, ou le théorème des accroissements finis.
	\end{rmq}

	On déduit de la Proposition~\ref{prp:polynômeracinecomplexeconjugée} que les deux racines propres sont obligatoirement deux complexes sous la forme~:
	\[\lambda_1 = a+ib \qquad\qquad \text{ et } \qquad\qquad \lambda_2 = \overline {\lambda_1} = a - ib,\]
	pour $a, b \in \R$.

	La solution générale devient donc
	\begin{align}\label{eq:solgénéralevalproprescomplexes}
		\begin{cases}
			x_1(t) &= \exp(at)\left( C_1\cos(bt) + C_2\sin(bt)\right) \\
			x_2(t) &= \exp(at)\left(-C_1\sin(bt) + C_2\cos(bt)\right).
		\end{cases}
	\end{align}

	\begin{déf} Dans un tel cas, lorsque $a = 0$, l'origine est un point d'équilibre que l'on appelle \textit{un centre} (les trajectoires forment des ellipses
	concentriques).

	Lorsque $a < 0$, l'origine est un point d'équilibre que l'on appelle \textit{un foyer stable}, et si $a > 0$, on l'appelle \textit{foyer instable}.
	\end{déf}

	\begin{prp} Un centre est un état d'équilibre simplement stable, un foyer stable est un état d'équilibre asymptotiquement stable, et un foyer instable est
	un état d'équilibre instable.
	\end{prp}

	\begin{proof} Par les théorèmes de stabilité par la partie réelle des valeurs propres.
	\end{proof}

	\begin{rmq} On observe que ces trois formes de systèmes sont oscillants de nature, même pour une fonction d'entrée inexistante (nulle).

	On observe également que l'équation~\eqref{eq:solgénéralevalproprescomplexes} montre bien que c'est de $a$ que dépend la stabilité, car $b$ n'intervient
	qu'en composition dans une fonction bornée (selon les constantes).
	\end{rmq}

	\begin{déf} Soit un système dynamique linéaire de dimension $n \in \N^*$. On appelle \textit{isocline} tout lieu de point tel que $\od {x_k}t = 0$.
	\end{déf}

	\begin{rmq} Les isoclines forment un hyper-plan de dimension $n-1$ séparant à chaque fois l'espace des phases en deux régions disjointes telles que le signe
	de la dérivée de $x_k$ y est opposé.

	Lors d'un dessin qualitatif, les isoclines servent donc à représenter les courbes sur lesquelles le champ de vecteur vitesse est orthogonal aux axes, et
	les parties de l'espace où ce champ de vecteurs est de signe constant (au sens de vecteur signe correspondant au signe de chaque composante).
	\end{rmq}

\section{Systèmes dynamiques non-linéaires à temps continu}

	Le modélisation linéaire est efficace car résoluble analytiquement, mais correspond toujours à une simplification forte de la réalité. Ces systèmes ne
	correspondent souvent à la réalité modélisée que dans certains cas, mais peut devenir très mauvaise tant dans l'explication que dans la prédiction.

	\subsection{Bifurcations}

	\begin{déf} Soit un système dynamique non-linéaire paramétrisé par $r \in \K^d$. On appelle \textit{bifurcation} le phénomène qui amène un changement
	qualitatif de l'évolution du système suite à un changement du paramètre $r$. Ce changement peut être soit le changement de stabilité d'un ou plusieurs
	état(s) d'équilibre, soit la création ou la suppression d'un ou plusieurs état(s) d'équilibre.

	On appelle \textit{valeur critique} ou \textit{valeur de bifurcation} toute valeur de $r$ entraînant un tel changement.
	\end{déf}

	\begin{déf} On appelle \textit{diagramme de bifurcation} le graphique avec le paramètre $r$ sur l'axe horizontal et les points fixes $\bar x$ sur l'axe
	vertical où la position de chaque état d'équilibre est représentée ainsi que sa stabilité (la trajectoire d'un état stable est représentée par une courbe
	pleine alors que la trajectoire d'un état instable est représenté par une courbe en pointillés).
	\end{déf}

	\subsection{Linéarisation de systèmes non-linéaires}

	\begin{déf} Soit $S$ un système dynamique autonome non-linéaire à temps continu régi par le problème de Cauchy suivant~:
	\[\begin{cases}
		\od {\bar x}t(t) &= f(x(t), u(t)) \\
		\bar x(t_0) &= {\bar x}^{(0)}
	\end{cases}\qquad\qquad (t_0, {\bar x}^{(0)}) \in T \times X,\]

	Le mouvement de ce système est $\bar x : T \to X : t \mapsto \varphi(t, t_0, {\bar x}^{(0)}, u)$, avec $u \in \Omega$, l'entrée du système.

	On appelle \textit{système linéarisé associé au système et au mouvement $t \mapsto \bar x(t) \in X$} le système~:
	\[\od xt(t) = A(t)x(t) + B(t)u(t),\]
	avec~:
	\[A(t) = \pd fx(\bar x(t), u(t)) \qquad\qquad \text{ et } \qquad\qquad B(t) = \pd fu(\bar x(t), u(t)).\]
	\end{déf}

	\begin{prp} Le système linéarisé associé à un système $S$ autour d'un mouvement $t \mapsto \bar x(t)$ est une approximation du premier
	ordre du système original autour de $\bar x(t)$.
	\end{prp}

	\begin{proof} Soient $(\delta u, \delta x^{(0)}) \in \Omega \times X$. Soit $\delta \bar x \in X^T$ tel que~:
	\[\od {\bar x}t(t) + \od {\delta \bar x}t(t) = f\left(\bar x(t) + \delta \bar x(t), u(t) + \delta u(t)\right).\]

	Par expansion de Taylor, on trouve~:
	\[\od {\bar x}t(t) + \od {\delta \bar x}t(t) = f(\bar x(t), u(t), t) + \pd fx(\bar x(t), u(t))\delta \bar x(t) + \pd fu(\bar x(t), u(t))\delta u(t) + o(\bar x(t)) + o(u(t)).\]

	En soustrayant $\od xt(t)$ de part et d'autre et en omettant les termes d'ordre supérieur, on obtient~:
	\[\od {\delta \bar x}t(t) = \pd fx(\bar x(t), u(t))\delta \bar x(t) + \pd fu(\bar x(t), u(t))\delta u(t).\]

	Posons alors~:
	\[A(t) = \pd fx(\bar x(t), u(t)) \qquad\qquad \text{ et } \qquad\qquad B(t) = \pd fu(\bar x(t), u(t)).\]

	Il s'ensuit~:
	\[\od {\delta \bar x}t(t) = A(t)\delta \bar x(t) + B(t)\delta u(t).\]

	Dès lors, le système linéarisé fournit bien une approximation (du premier ordre par Taylor) pour de faibles perturbations (proche de $\bar x(t)$).
	\end{proof}

	\begin{rmq} Il est intéressant d'étudier le système linéarisé proche des états d'équilibre car il y a alors moyen d'en inférer des propriétés de stabilité.
	\end{rmq}

		\subsubsection{Linéarisation et stabilité}

	\begin{thm} Soit $S$ un système dynamique autonome non-linéaire, et soit $\bar x \in X$, un point d'équilibre de $S$ pour une entrée $\bar u \in \Omega$. Si
	le système linéarisé associé au mouvement $t \mapsto \bar x(t)$ autour de $\bar x$ est asymptotiquement stable, alors $\bar x$ est asymptotiquement stable
	pour $\od xt(t) = f(x(t), u(t))$.

	De même si le système linéarisé est instable, alors $\bar x$ est instable pour $\od xt(t) = f(x(t), u(t))$.
	\end{thm}

	\begin{rmq} On ne peut donc rien déduire d'un système linéarisé simplement stable.
	\end{rmq}

	\subsection{Systèmes dynamiques non-linéaires à temps continu d'ordre 1}

	On se concentre sur les systèmes définis par $\od xt(t) = f(x(t)) \in \R = X$.

		\subsubsection{Méthode géométrique}

	En traçant le graphique de $\od xt$ en fonction de $x$, on peut déduire les point d'équilibre, leur stabilité, et les trajectoires du système.

	En effet, toutes les valeurs de $x$ telles que $f(x)$ s'annule donnent les points fixes du système. Également, le signe de $f(x)$ donne une information
	sur la croissance ou décroissance de $x$, et donc de sa direction.

	Sur base du graphique, on peut alors déduire quatre types d'états d'équilibre $\bar x$ (points fixes de $t \mapsto x(t)$) de $\bar x$~:
	\begin{itemize}
		\item si $f$ est négative à gauche\footnote{On appelle ici \textit{gauche} de $\bar x$ l'ensemble $(-\infty, \bar x)$ et \textit{droite} l'ensemble
		$(x, +\infty)$.} de $\bar x$ et positive à droite de $\bar x$, alors l'état d'équilibre est instable~;
		\item si $f$ est positive à gauche de $\bar x$ et négative à droite, alors $\bar x$ est un état d'équilibre asymptotiquement stable~;
		\item si $f$ est négative à gauche de $\bar x$ et à droite de $\bar x$, alors l'état d'équilibre $\bar x$ est \textit{semi-asymptotiquement stable à
		droite}~;
		\item et si $f$ est positive à gauche et à droite de $\bar x$, alors l'état d'équilibre $\bar x$ est \textit{semi-asymptotiquement stable à gauche}.
	\end{itemize}

	\begin{rmq} Sur un graphique d'équilibre de $f$ en fonction de $x$, il est de convention de marquer les points stables par des cercles pleins, les points
	instables par des cercles vides, et les points semi-stables par des cercles semi-remplis du côté stable.
	\end{rmq}

	\begin{prp} Dans le cas d'un système d'ordre 1, la trajectoire $x : T \subseteq \R \to X = \R$ suit un mouvement monotone pour tout état initial.
	\end{prp}

	\begin{proof} Les comportements sont, en dimension 1, très limités~: une trajectoire peut soit converger vers un point fixe, soit diverger vers l'infini.

	En effet, en supposant $f$ continue, on oblige qu'un changement de signe de $f$ induise un point fixe (de stabilité asymptotique ou instable). Pour que la
	trajectoire puisse «~rebrousser chemin~», il lui faudrait passer un point fixe, ce qui est impossible~: les points fixes ne sont atteints qu'en $t \to \pm \infty$
	et ne sont jamais traversés en dimension 1.
	\end{proof}

	\begin{cor} Une trajectoire ne peut pas suivre de trajectoire périodique.
	\end{cor}

	\begin{thm} Soit un système dynamique (linéaire ou non-linéaire) autonome. Par un point de l'espace des phases passe au plus une trajectoire.
	\end{thm}

	\begin{proof} Soit un point tel qu'il existe une solution passant par ce point (Cauchy-Lipschitz dont le caractère lipschitzien de $f$ est supposé dans tous
	les cas). $\od xt = f$ admet une unique valeur en ce point. Donc toute trajectoire passant par ce point doit suivre la même tangente, et donc la même trajectoire.

	Supposons qu'il existe deux trajectoires (mouvements $t \mapsto \hat x(t)$ et $t \mapsto \tilde x(t)$) distinctes passant par ce point. On a bien une
	contradiction car $f$ devrait admettre deux valeurs distinctes.
	\end{proof}

	\subsection{Systèmes dynamiques non-linéaires à temps continu d'ordre 2}

	\begin{déf} Une trajectoire est dite \textit{isolée} lorsqu'elle n'est pas transformation de ses trajectoires avoisinantes.
	\end{déf}

	\begin{déf} Un \textit{cycle limite} est une trajectoire close isolée.
	\end{déf}

	\begin{déf} Soit $C$, un cycle limite.

	\begin{itemize}
		\item $C$ est dit \textit{simple} (ou \textit{attracteur}) lorsque les trajectoires avoisinantes convergent vers $C$~;
		\item $C$ est dit \textit{instable} lorsque les trajectoires avoisinantes divergent de $C$~;
		\item $C$ est dit \textit{semi-stable} lorsque les trajectoires internes (respectivement externes) à $C$ convergent vers $C$, alors que les trajectoires
		externes (respectivement internes) à $C$ divergent de $C$.
	\end{itemize}
	\end{déf}

	\begin{rmq} Un cycle limite stable implique des oscillations spontanées du système, même en l'absence d'entrée périodique. De plus, ces cycles ne peuvent
	exister dans un système linéaire (bien que des oscillations soient possibles par des trajectoires circulaires en cas de valeurs propres complexes) car un
	système linéaire a des propriétés générales~: des trajectoires isolées n'existent pas.
	\end{rmq}

	\begin{rmq} Il est difficile de déterminer si un système d'ordre 2 admet ou non un cycle limite.
	\end{rmq}

	\begin{thm}[Théorème de Bendixon] Soit $R$ une région close, connexe et bornée de l'espace des phases bidimensionnel. Si la fonction~:
	\[t \mapsto \scpr {\nabla f}{\mathbf 1}(t),\]
	pour $\mathbf 1 : t \mapsto 1$, est de signe constant sur $R$ et s'annule sur un ensemble de mesure nulle, alors $R$ ne contient aucun cycle limite.
	\end{thm}

	\begin{thm}[Théorème de Poincaré] Soit $R$, une région close, bornée et annulaire (au sens où $R \setminus D \simeq D$) de l'espace des phases
	bidimensionnel. S'il n'existe aucun état d'équilibre dans $R$, et si toutes les trajectoires passant par $\partial R$ (le bord de $R$) sont entrantes dans
	$R$, alors il existe au moins un cycle limite dans $R$.
	\end{thm}

	\begin{rmq} Ce théorème affirme à nouveau que la famille des trajectoires en dimension 2 est limité.
	\end{rmq}

	\subsection{Invariants}

\end{document}
