\documentclass{article}

\usepackage{commath}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{palatino, eulervm}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage[bottom]{footmisc}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{stmaryrd}
\usepackage{hyperref}

%%%%%  amsthm  %%%%%
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollaire}
\newtheorem{lem}[thm]{Lemme}
\addto\captionsfrench{\renewcommand\proofname{\underline{Démonstration}}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}[section]

% link amsthm and mdframed
\iftrue
%\iffalse
	% pre-amsthm
	\mdfdefinestyle{resultstyle}{%
		hidealllines=true,%
		leftline=true,%
		rightline=true,%
		innerleftmargin=10pt,%
		innerrightmargin=10pt,%
		innertopmargin=10pt,%
		innerbottommargin=8pt,%
	}

	\surroundwithmdframed[style=resultstyle]{thm}
	\surroundwithmdframed[style=resultstyle]{prp}
	\surroundwithmdframed[style=resultstyle]{cor}
	\surroundwithmdframed[style=resultstyle]{lem}
\fi

\DeclareMathOperator{\Tr}{Tr}

\newcommand{\N}{\mathbb N}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\K}{\mathbb K}
\newcommand{\tq}{\text{ t.q. }}
\newcommand{\restr}[2]{\left.#1\vphantom{\big|}\right|_{#2}}
\newcommand{\intint}[2]{{\left\llbracket#1, #2\right\rrbracket}}
\newcommand{\scpr}[2]{{\left\langle#1, #2\right\rangle}}

\title{Modélisation et simulation --- INFOF-305}
\author{R. Petit}
\date{Année académique 2016 - 2017}

\begin{document}
\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}
\setcounter{page}1

\section{Introduction aux systèmes dynamiques}
	\subsection{Généralités}

	\begin{déf} Soit $T$, \textit{l'ensemble de temps}. Selon la nature de $T$, on parle de \textit{système à temps discret}, ou de \textit{système à temps
	continu}. Les applications~:
	\[u : T \to U \subseteq \R^n \qquad\qquad \text{ et } \qquad\qquad y : T \to Y \subseteq \R^m\]
	sont respectivement appelées \textit{fonction d'entrée} et \textit{fonction de sortie}. L'application $u$ correspond aux apports que subit le système, alors
	que l'application $y$ correspond à l'observation du système.

	Le couple d'applications $(u, y)$ appartient à $\Omega \times \Gamma$, où $\Omega$ est l'ensemble des fonctions d'entrées acceptables et $\Gamma$ est
	l'ensemble des fonctions de sortie acceptables.
	\end{déf}

	\begin{rmq} $\forall (u, y) \in \Omega \times \Gamma : \forall t \in T : \left(u(t), y(t)\right) \in U \times Y$.
	\end{rmq}

	\begin{déf} On appelle variable d'état la variable $x : T \to X \subseteq \R^d$ représentant l'\textit{état interne du système} en fonction du temps.

	L'évolution du système sera décrite comme un système d'équations différentielles ou d'équations aux différences par rapport à la variable d'état.
	\end{déf}

	\begin{rmq} Le fait qu'une variable supplémentaire soit introduite induit que la connaissance de $(t_0, u, y) \in T \times \Omega \times \Gamma$ ne permet
	pas de prédire $y(t)$ pour $T \ni t > t_0$. Pour cela, il faut également connaître $x^0 \coloneqq x(t_0) \in \R^d$. Alors les théorèmes de Cauchy-Lipschitz
	sont applicables (habituellement) pour affirmer que $t \mapsto x(t)$ est une solution.
	\end{rmq}

	\begin{déf} Un système est dit \textit{statique} (ou \textit{memoryless}) lorsque la sortie ne dépend que de l'entrée, et pas de la variable d'état.
	\end{déf}

	\begin{rmq} Dans un tel système, connaitre $(t_0, u, y)$ est suffisant pour connaitre $y(t)$ pour tout $t > t_0$.
	\end{rmq}

	\begin{déf} L'application~:
	\[\varphi : T \times T \times X \times \Omega \to \R^d\]
	telle que $\forall t \in T : x(t) = \varphi(t_0, t, x^0, u)$ est appelée \textit{fonction d'état}.

	L'application~:
	\[\eta : T \times X \to Y\]
	telle que $\forall t \in T : y(t) = \eta(t, x(t))$ est appelée \textit{fonction de transformation de sortie}.
	\end{déf}

	\begin{déf} Un système dynamique se définit alors par le 8-uple suivant~:
	\[S = \left(T, U, \Omega, X, Y, \Gamma, \varphi, \eta\right).\]
	\end{déf}

	\begin{rmq} On peut donc synthétiser un système dynamique par~:
	\[u(t) \xrightarrow{\varphi(t)} x(t) \xrightarrow{\eta(t)} y(t).\]
	\end{rmq}

	\begin{prp} L'application $\varphi$ admet les propriétés suivantes~:
	\begin{itemize}
		\item consistance~: $\forall (t, x, u) \in T \times X \times \Omega : \varphi(t, t, x, u) = x$~;
		\item irréversibilité~: $\varphi$ est définie sur $[t_0, +\infty) \cap T$~;
		\item composition~: $\forall t_0 < t_1 < t_2 \in T : \forall (u, x) \in \Omega \times X : \varphi(t_2, t_0, x, u)
			= \varphi\left(t_2, t_1, \varphi\left(t_1, t_0, x, u\right), u\right)$~;
		\item causalité~: $\forall t_0 \in T : \forall u_1, u_2 \in \Omega : \left(\forall t \in T : u_1(t) = u_2(t)\right)
			\Rightarrow \left(\forall t \in T : \varphi(t, t_0, x, u_) = \varphi(t, t_0, x, u_2)\right)$.
	\end{itemize}
	\end{prp}

	\begin{déf} Soit un système dynamique régi par~:
	\[x(t) = \varphi(t, t_0, x(t_0), u).\]

	On appelle le \textit{mouvement du système} l'ensemble $\left\{(t, x(t)) \tq t \geq t_0\right\}$.

	On appelle la \textit{trajectoire du système} l'ensemble $\left\{x(t) \tq t \geq t_0\right\}$.
	\end{déf}

	\begin{rmq} La trajectoire est donc la projection du mouvement parallèlement au temps.
	\end{rmq}

	\begin{déf} Soit $\overline x \in X$. On dit que $\overline x$ est un \textit{état d'équilibre (en temps infini)} lorsque~:
	\[\exists u \in \Omega \tq \forall (t, t_0) \in T^2 : t \geq t_0 \Rightarrow \varphi(t, t_0, \overline x, u) = \overline x.\]
	\end{déf}

	\begin{déf} Soit $\overline y \in Y$. On dit que $\overline y$ est une \textit{sortie d'équilibre (en temps infini)} lorsque~:
	\[\forall t_0 \in T : \exists (x, u) \in X \times \Omega \tq \forall t \geq t_0 : \eta\left(t, \varphi(t, t_0, x, u)\right) = \overline y.\]
	\end{déf}

	\begin{déf} Un système est dit \textit{invariant} lorsque~:
	\begin{enumerate}
		\item $T$ est stable par l'addition~;
		\item $\forall (u, \delta) \in \Omega \times T : \Omega \ni u^{(\delta)} : T \to U : t \mapsto u(t-\delta)$~;
		\item $\forall (t_0, \delta, x^0) \in T \times T \times X : \forall t \geq t_0 : \varphi\left(t, t_0, x^0, u\right)
			= \varphi\left(t+\delta, t_0+\delta, x^0, u^{(\delta)}\right)$~;
		\item $y$ est indépendante de $t$, c-à-d~: $y(t) = (\eta \circ x)(t))$.
	\end{enumerate}
	\end{déf}

	\begin{déf} Soient $x^{(1)}, x^{(2)} \in X$. On dit que $x^{(2)}$ est \textit{accessible} à l'instant $t_2 \in T$ à partir de $x^{(1)}$ lorsque~:
	\[\exists (t_1, u) \in T \times \Omega \tq t_1 < t_2 \text{ et } \varphi(t_2, t_1, x^{(1)}, u) = x^{(2)}.\]
	\end{déf}

	\begin{déf} Un système est dit \textit{connexe à l'instant $t \in T$} lorsque $\forall (x^{(1)}, x^{(2)}) \in X^2 : x^{(2)}$ est accessible à l'instant
	$t$ à partir de $x^{(1)}$.

	Si un système est connexe pour tout $t \in T$, alors il est dit connexe.
	\end{déf}

	\begin{déf} Soient $x^{(1)}, x^{(2)} \in X$. On dit que $x^{(1)}$ et $x^{(2)}$ sont équivalents à l'instant $t_0 \in T$ lorsque~:
	\[\forall u \in \Omega : \forall t \geq t_0 : \eta\left(t, \varphi\left(t, t_0, x^{(1)}, u\right)\right)
		= \eta\left(t, \varphi\left(t, t_0, x^{(2)}, u\right)\right).\]
	\end{déf}

	\begin{déf} Un système est dit en \textit{forme réduite} si $\forall (x^{(1)}, x^{(2)}) \in X^2 : x^{(1)} \neq x^{(2)} \Rightarrow x^{(1)}$ n'est pas
	équivalent à $x^{(2)}$.
	\end{déf}

	\begin{déf} Soit $\hat x \in X$. L'état $\hat x$ est dit observable à l'instant $t_0 \in T$ lorsque $\exists (t, u) \in T \times \Omega \tq x(t_0)$ peut
	être retrouvé de manière univoque à l'aide de $\restr u{[t_0, t)}$ et $\restr y{[t, t_0)}$.
	\end{déf}

	\subsection{Systèmes dynamiques complexes}

	\begin{déf} Un \textit{sous-système dynamique} est un système dynamique faisant partie d'un système dynamique complexe.
	\end{déf}

	\begin{déf} Soient $S_1$ et $S_2$ deux systèmes dynamiques. $S_1$ et $S_2$ sont dits \textit{connectés en cascade} lorsque~:
	\[y_1 = u_2,\]
	c-à-d lorsque la sortie du premier système sert d'entrée au second.
	\end{déf}

	\begin{rmq} Pour que deux systèmes $S_1$ et $S_2$ soient connectés en cascade, il est nécessaire que $T_1 = T_2$, $\Gamma_1 \subseteq \Omega_2$
	(et donc $Y_1 \subseteq U_2$).
	\end{rmq}

	\begin{prp} Soient les deux systèmes dynamiques suivants~:
	\begin{align*}
		S_1 &= \left(T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1\right), \\
		S_2 &= \left(T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2\right).
	\end{align*}

	Le système dynamique résultant de la cascade de $S_1$ et $S_2$ est donné par~:
	\[S = \left(T, U_1, \Omega_1, X_1 \times X_2, Y_2, \Gamma_2, \varphi, \eta_2\right),\]
	où~:
	\begin{align*}
		&T = T_1 = T_2 \\
		&\varphi : T \times T \times (X_1 \times X_2) \times \Omega_1 \to X : \\
		&\qquad\left((t, t_0, \left(x_1(t_0), x_2(t_0)\right), u\right) \mapsto
				\left(\varphi_1\left(t, t_0, x_1(t_0), u\right), \varphi_2\left(t, t_0, x_2(t_0), y_1(t_0, x_1, u)\right)\right), \\
		&y_1(t_0, x_1, u) : T \to Y_1 \subseteq U_2 : t \mapsto \eta_1\left(t, \varphi_1\left(t, t_0 x_1(t_0), u\right)\right).
	\end{align*}
	\end{prp}

	\begin{déf} Soient $S_1$ et $S_2$ deux systèmes dynamiques. $S_1$ et $S_2$ sont dits \textit{connectés en parallèle} lorsque~:
	\[u_1 = u_2,\]
	c-à-d lorsqu'ils ont la même fonction d'entrée.
	\end{déf}

	\begin{rmq} Pour que deux systèmes dynamiques soient connectés en parallèle, il est nécessaire que $T_1 = T_2$, $\Omega_1 = \Omega_2$ (et donc $U_1 = U_2$).
	\end{rmq}

	\begin{prp} Soient les deux systèmes dynamiques suivants~:
	\begin{align*}
		S_1 &= \left(T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1\right), \\
		S_2 &= \left(T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2\right).
	\end{align*}

	Le système dynamique résultant des systèmes $S_1$ et $S_2$ en parallèle est donné par~:
	\[S = \left(T, U, \Omega, X_1 \times X_2, Y_1 \times Y_2, \Gamma_1 \times \Gamma_2, \varphi, \eta\right),\]
	où~:
	\begin{align*}
		T &= T_1 = T_2 \\
		U &= U_1 = U_2 \\
		\Omega &= \Omega_1 = \Omega_2 \\
		\varphi &: (t, t_0, x, u) \mapsto \left(\varphi_1(t, t_0, x, u), \varphi_2(t, t_0, x, u)\right) \\
		\eta &: \left(t, (x_1, x_2)\right) \mapsto \left(\eta_1(t, x_1), \eta_2(t, x_2)\right)
	\end{align*}
	\end{prp}

	\subsection{Rétroaction}

	\begin{déf} Deux systèmes $S_1 = (T, U_1, \Omega_1, X_1, Y_1, \Gamma_1, \varphi_1, \eta_1)$ et $S_2 = (T, U_2, \Omega_2, X_2, Y_2, \Gamma_2, \varphi_2, \eta_2)$
	sont dits en rétroaction l'un sur l'autre lorsqu'il existe $v_1 : T \to U_1, v_2 : T \to U_2$ et~:
	\[\psi_1 : Y_1 \times U_2 \times T \to U_2 \qquad\qquad \text{ et } \qquad\qquad \psi_2 : Y_2 \times U_1 \times T \to U_1\]
	tels que~:
	\begin{align*}
		u_1(t) &= \psi_2\left(y_1(t), v_2(t), t\right) \\
		u_2(t) &= \psi_1\left(y_2(t), v_1(t), t\right).
	\end{align*}
	\end{déf}

	\begin{déf} On parle de \textit{rétroaction négative} lorsqu'une modification de $y_1(t)$ entraine une modification de $y_2(t)$ qui s'oppose au changement
	de $y_1(t)$.

	De même, on parle de \textit{rétroaction positive} lorsqu'une modification de $y_1(t)$ entraine une modification de $y_2(t)$ qui amplifie le changement de
	$y_2(t)$.
	\end{déf}

	\begin{rmq} Ce type de construction est le plus simple contenant une boucle.

	De plus, il est ici question de rétroaction sur la sortie. Il peut être plus intéressant de définir une rétroaction sur l'état.
	\end{rmq}

	\begin{déf} Un système est dit \textit{rétroactionné sur l'état} lorsqu'il existe $v : T \to U$ et $\psi : X \times U \times T \to U$ tels que~:
	\[u(t) = \psi\left(x(t), v(t), t\right).\]

	Cette fonction $\psi$ est appelée \textit{loi de contrôle}.
	\end{déf}

\section{Automates --- systèmes à temps discret et et à espace d'états discret}
	\begin{déf} Un \textit{automate} est un système dynamique invariant à temps discret et avec un espace d'états discret, et où les ensembles d'entrée et de
	sortie sont finis.
	\end{déf}

	\begin{déf} Un automate est dit \textit{fini} lorsque l'espace d'états est fini.
	\end{déf}

	\begin{prp} Dans un système dynamique invariant à temps discret, la fonction $\varphi$ de transition peut être remplacée par~:
	\[x(t+1) = \delta(x(t), u(t)),\]
	et la fonction de transformation de sortie peut être remplacée par~:
	\[y(t) = \eta(x(t)),\]
	ce qui implique que l'observation du système dépend uniquement de l'état, et que l'état à un certain instant ne dépend plus que de la valeur à l'état
	précédent (modèle markovien).
	\end{prp}

	\begin{déf} Un automate \textit{cellulaire} de dimension $(n_1, \ldots, n_k) \in {\N^*}^k$ est un automate tel que $X = \chi^{\prod_{i=1}^kn_i}$, où $\chi$
	est un ensemble fini d'états tel que~:
	\[\forall \alpha \in {\N^*}^k : \left(\forall 1 \leq j \leq k : 1 \leq \alpha_j \leq n_k\right) \Rightarrow \left(\forall t \in T : x_\alpha(t) \in \chi\right),\]
	et tel que $x(t+1) = (\delta \circ x)(t)$, à savoir, aucune entrée $u \in \Omega$ n'est présente.

	Les telles valeurs $x_\alpha$ sont appelées les cellules de l'automate.
	\end{déf}

	\begin{rmq} Dans un automate cellulaire, la nombre de variables d'états est vite très grand, mais reste toute fois fini.
	\end{rmq}

	\begin{déf} la fonction de transition d'un automate cellulaire $\delta : X \times U \to X$ est une fonction à valeurs dans $X = \chi^{\prod_{i=1}^kn_i}$.
	Chaque fonction $\delta_\alpha$ telle que $x_\alpha(t+1) = \delta_\alpha(x(t))$ est défini sur un \textit{voisinage} de $\alpha \in {\N^*}^k$. Et donc,
	on peut écrire $x_\alpha(t+1) = \delta_\alpha\left(\gamma(x(t), \alpha)\right)$, où $\gamma : X \times {\N^*}^k$ est une fonction renvoyant uniquement
	un sous-ensemble (non-strict) de $x(t) \in X$.
	\end{déf}

	\begin{ex} Un automate cellulaire de dimension $(n_1, n_2) \in \N^* \times \N^*$ représente donc une \textit{grille} de cellules, où l'état de chaque cellule
	$x_{i\,j}$ à l'instant $t+1 \in T$ ne dépend que d'un voisinage de $(i, j) \in \N^* \times \N^*$. Par exemple, dans le jeu de la vie (J. Conway), le
	voisinage de $(i, j)$ est défini par~:
	\[\left\{(k, \ell) \in \N^* \times \N^* \tq \abs {k-i} = \abs {\ell-j} = 1\right\}.\]
	\end{ex}

	\begin{rmq} Ces systèmes dynamiques que représentent les automates cellulaires (finis) font partie des systèmes complexes suite à leur grand nombre de
	variables d'état. Ils ont entre autre prouvé que des règles simples et déterministes pouvaient engendrer un comportement très compliqué à décrire et à
	prédire. En effet, un \textit{simple} automate cellulaire de dimension $(n_1, n_2) \in \N^* \times \N^*$ peut produire plusieurs comportements distincts
	et simultanés dans plusieurs voisinages de cellules, certains périodiques, d'autres erratiques.
	\end{rmq}

\section{Systèmes continus}
	Dans cette section, on considère l'espace $T = [t_0, +\infty) \subset \R$, pour $t_0 \in \R^+$, et donc continu.

	\subsection{Systèmes réguliers}

	\begin{déf} Un système dynamique $S$ est dit \textit{de dimensionnalité finie} lorsque les ensembles $U, X$ et $Y$ sont des espaces vectoriels de dimension
	finie (pas nécessairement la même dimension), i.e. $\exists n_1, n_2, n_3 \in \N^*$ tels que $(U, X, Y) = (\K_1^{n_1}, \K_2^{n_2}, \K_3^{n_3})$, où
	les $\K_i$ sont des corps (habituellement $\K \in \{\R, \C\}$).
	\end{déf}

	\begin{rmq} Nous ferons ici l'hypothèse que ces espaces vectoriels sont normés, afin de pouvoir définir une distance~:
	\[\forall a, b \in \K^d : d_\K(a, b) = \norm {a-b}_\K,\]
	où $\norm \cdot_\K : \K \to \R$ est la norme de l'espace vectoriel normé $(\K, \norm \cdot_\K)$.
	\end{rmq}

	\begin{déf} Un système dynamique continu de dimensionnalité finie est dit \textit {régulier} lorsque~:
	\begin{itemize}
		\item les espaces $U, X, Y, \Omega, \Gamma$ sont des espaces vectoriels normés~;
		\item la fonction de transition $\varphi$ est continue sur $T \times T \times X \times \Omega$~;
		\item la fonction de transition $\varphi$ est continûment dérivable par rapport au temps sur le sous-ensemble de définition de $u \in \Omega$ où
			$u$ est continue~;
		\item la fonction $\eta$ est continue sur $X \times T$.
	\end{itemize}
	\end{déf}

	\begin{rmq} On fait ici les hypothèses de régularité suffisantes pour lier les systèmes dynamiques continus aux équations différentielles ordinaires, donc
	ici en particulier, afin d'assurer l'existence d'une solution maximale unique, il est nécessaire de supposer $\od \varphi t$ localement lipschitzienne sur $X$
	en plus de sa continuité (théorème de Cauchy-Lipschitz local). De manière plus large, on suppose ici le champ de vecteur $f$ de $\od xt = f(x)$ continûment
	différentiable (ce qui implique le caractère lipschitzien).
	\end{rmq}

	L'équation différentielle vectorielle du premier ordre $\od xt = f(x(t), u(t), t)$ peut se réécrire indépendamment selon les composantes\footnote{Toute
	équation vectorielle, peu importe son degré, peut se réécrire comme une équation différentielle vectorielle d'ordre 1.}~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t), t) \\
		\od {x_2}t(t) &= f_2(x(t), u(t), t) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t), t),
	\end{cases}\]
	où $n$ est la dimension d'arrivée de $f$, et donc la dimensionnalité de $X$.

	\begin{thm} Pour $t_0 \in T$ fixé, le mouvement $t \mapsto \varphi(t, t_0, x^{(0)}, u)$ pour $x^{(0)} = x(t_0)$ d'un système dynamique régulier est solution
	unique maximale d'une équation différentielle de la forme~:
	\begin{align}\label{eq:equadiffvec}
		\od xt = f(x(t), u(t), t).
	\end{align}
	\end{thm}

	\begin{déf} Dans l'équation~\eqref{eq:equadiffvec}, la fonction $f : X \times U \times T \to X$ est appelée \textit{fonction génératrice du système}.
	\end{déf}

	\begin{rmq} Il est souvent très difficile (voire impossible) de déterminer analytiquement la solution d'un système exprimé sous forme différentielle
	(équation~\eqref{eq:equadiffvec}). Dans ces cas, la simulation numérique est requise.
	\end{rmq}

	\begin{déf} Un système régulier est dit \textit{autonome} lorsque $\od xt = f(x(t))$, c'est-à-dire lorsque $f$ ne fait pas intervenir le temps explicitement.
	\end{déf}

	\begin{prp} Tout système d'équations différentielles peut être mis sous forme autonome.
	\end{prp}

	\begin{proof} Le système suivant~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t), t) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t), t)
	\end{cases}\]
	peut être réécrit comme suit~:
	\[\begin{cases}
		\od {x_1}t(t) &= f_1(x(t), u(t)) \\
		\vdots \\
		\od {x_n}t(t) &= f_n(x(t), u(t)) \\
		\od {x_{n+1}}t(t) &= \od tt = 1
	\end{cases}\]
	\end{proof}

	\subsection{Espace et portrait de phases}

	\begin{déf} L'espace d'états $X$ est également appelé \textit{espace des phases}, dans lequel tout état $x \in X$ représente un point $(x_1, \ldots, x_n) \in X$
	de l'espace des phases.
	\end{déf}

	\begin{rmq} Selon cette définition, la trajectoire d'un système représente donc la projection du mouvement dans l'espace des phases, ce qui correspond à
	une courbe de dimension 1 dans $X$.
	\end{rmq}

	\begin{déf} On appelle \textit{portrait de phases} la représentation du champ de vecteurs $f : X \times U \times T \to X$ dans l'espace des phases.
	\end{déf}

	\begin{rmq} Le portrait de phases d'un système donne une représentation qualitative de l'évolution du système. Cette représentation est très pratique du fait
	qu'elle ne requiert rien d'autre que la fonction $f$, génératrice du système, qui est connue. Il est donc toujours possible de dessiner un portrait de phases,
	même lorsqu'il est impossible de résoudre analytiquement l'équation.

	Afin de rendre l'information encore plus qualitative, il est commun de renormaliser tous les vecteurs du champ lors de la représentation. Ainsi, toute
	information sur $t$ est perdue (ce qui ne change rien dans le cas d'un système autonome).
	\end{rmq}

	\subsection{Stabilité des points d'équilibre}

	La stabilité est la notion qui va permettre de classifier les points d'équilibre selon leur comportement induit suite à des perturbations.

	\begin{déf} Soient $(\bar t, \bar x, \bar u) \in T \times X \times \Omega$. Le mouvement $t \mapsto \varphi(t, \bar t, \bar x, \bar u)$ d'un système $S$
	est dit \textit{stable} lorsque~:
	\[\forall \varepsilon > 0 : \exists \delta > 0 \tq \forall x \in X : \left(\norm {x-\bar x} < \delta\right) \Rightarrow
		\left(\forall t \in T : t \geq \bar t \Rightarrow \norm {\varphi(t, \bar t, \bar x, \bar u) - \varphi(t, \bar t, x, \bar u)} < \varepsilon\right).\]

	Si un mouvement n'est pas stable, il est dit \textit{instable}.
	\end{déf}

	\begin{déf} Soit $(\bar x, \bar u, \bar t) \in X \times \Omega \times T$, où $\bar x$ est un point d'équilibre pour $\bar u$ à l'instant $\bar t$.
	Le point d'équilibre $\bar x$ est dit \textit{stable} lorsque~:
	\[\forall \varepsilon > 0 : \exists \delta > 0 \tq \forall x \in X : \left(\norm {x-\bar x} < \delta\right) \Rightarrow
		\left(\forall t \in T : t \geq \bar t \Rightarrow \norm {\varphi(t, \bar t, x, \bar u) - \bar x} < \varepsilon\right).\]
	\end{déf}

	\begin{déf} Un point d'équilibre $\bar x \in X$ pour une entrée $\bar u \in \Omega$ à l'instant $\bar t \in T$ est dit \textit{asymptotiquement stable}
	lorsqu'il est stable, et~:
	\[\lim_{t \to +\infty}\norm {\varphi(t, \bar t, x, \bar u) - \bar x} = 0,\]
	ou encore~:
	\[\lim_{t \to +\infty}\varphi(t, \bar t, x, \bar u) = \bar x,\]
	pour $x \in X \tq \norm {x-\bar x} < \delta$ de la définition de stabilité.
	\end{déf}

		\subsubsection{Critère de Liapounov}

	\begin{déf} Une fonction $V : X \to \R$ est dite définie positive (respectivement négative) en $\bar x \in X$ lorsqu'il existe $\mathcal V \subseteq X$, un
	voisinage de $\bar x$ tel que~:
	\[V(\bar x) = 0 \qquad\qquad \text{ et } \qquad\qquad \forall x \in \mathcal V : V(x) > 0 \text{ (respectivement $V(x) < 0$)}.\]
	\end{déf}

	\begin{déf} Une fonction $V : X \to \R$ est dite semi-définie positive (respectivement négative) lorsque les inégalités ci-dessus ne sont pas strictes.
	\end{déf}

	\begin{déf} Soit $A \in \K^{n \times n}$ pour $n \in \N^*$, une matrice symétrique sur un corps $\K$.

	On dit que $A$ est définie positive (respectivement négative) lorsque la forme quadratique associée $x \mapsto x^TAx$ est définie positive
	(respectivement négative).

	On dit que $A$ est semi-définie positive (respectivement négative) lorsque la forme quadratique associée $x \mapsto x^TAx$ est semi-définie positive
	(respectivement négative).
	\end{déf}

	\begin{thm}[Critère de Sylvester] Soit $A \in \K^{n \times n}$, pour $n \in \N^*$, une matrice symétrique sur un corps $\K$. $A$ est définie positive
	si et seulement si~:
	\[\forall k \in \intint 1n : \det
	\begin{bmatrix}
		a_{11} & \ldots & a_{1k} \\
		\vdots & \ddots & \vdots \\
		a_{k1} & \ldots & a_{kk}
	\end{bmatrix} > 0\]
	\end{thm}

	\begin{cor} Soit $A \in \K^{n \times n}$ pour $n \in \N^*$. Si $A$ est définie positive, alors $\det(A) \neq 0$.
	\end{cor}

	\begin{thm}[Critère de stabilité de Liapounov] Soit une équation différentielle vectorielle d'ordre 1~:
	\[\od xt(t) = f(x(t), u(t)).\]
	Soit $\bar \in X$, un point d'équilibre pour l'entrée constante $t \mapsto \bar u \in U$.

	S'il existe une fonction $V : X \xrightarrow{C^1} X$ telle que~:
	\[\od Vt(x) = \scpr {\nabla V(x)}{f(x, \bar u)}\]
	semi-définie négative (respectivement définie négative) en $\bar x$, alors $\bar x$ est asymptotiquement stable (respectivement stable).
	\end{thm}

	\begin{déf} Une telle fonction $V : X \to X$ est appelée une fonction de Liapounov.
	\end{déf}

	\newpage

	\begin{thm}[Critère d'instbilité de Liapounov] Soit une équation différentielle vectorielle d'ordre 1~:
	\[\od xt(t) = f(x(t), u(t)).\]
	Soit $\bar x \in X$, un point d'équilibre pour l'entrée constante $t \mapsto \bar u \in U$.

	S'il existe une fonction $V : X \to X$ continûment dérivable sur un voisinage de $\bar x$ telle que $V$ est définie positive en $\bar x$ et~:
	\[\od Vt(x) = \scpr {\nabla V(x)}{f(x, \bar u)}\]
	est définie positive en $\bar x$, alors $\bar x$ est instable.
	\end{thm}

\section{Systèmes dynamiques linéaires à temps continu}

	\begin{déf} On définit le \textit{mouvement libre} d'un système comme étant la fonction~:
	\[\varphi_\ell : T \times T \times X \to X : (t, t_0, x^{(0))} \mapsto \varphi(t, t_0, x^{(0)}, \mathbf{0}),\]
	avec $\mathbf{0} : t \mapsto 0$, la fonction nulle.

	On définit le \textit{mouvement forcé} d'un système comme étant la fonction~:
	\[\varphi_f : T \times T \times \Omega \to X : (t, t_0, u) \mapsto \varphi(t, t_0, 0_X, u),\]
	avec $0_X$, l'élément neutre de $X$ (qui existe car $X$ est un espace vectoriel).
	\end{déf}

	\begin{prp} Dans un système linéaire, la fonction de transition $\varphi$ est linéaire par rapport à $x \in X$, et $u \in \Omega$, et $\varphi$
	est superposable par $\varphi_\ell$ et $\varphi_f$, i.e.~:
	\begin{align*}
		&\forall \lambda, \mu, \gamma, \delta \in \K : \forall (t, t_0) \in T^2 : \forall (x^{(1)}, x^{(2)}) \in X^2 : \forall (u_1, u_2) \in \Omega : \\
		&\varphi\left(t, t_0, \lambda x^{(1)} + \mu x^{(2)}, \gamma u_1 + \delta u_2\right) =
			\lambda \varphi_\ell(t, t_0, x^{(1)}) + \mu \varphi_\ell(t, t_0, x^{(2)}) + \gamma \varphi_f(t, t_0, u_1) + \delta \varphi_f(t, t_0, u_2).
	\end{align*}
	\end{prp}

	\begin{prp} Dans un système linéaire, la fonction de transformation de sortie $\eta : X \to Y$ est linéaire par rapport à $x \in X$ pour tout $t \in T$, i.e.~:
	\[\forall t \in T : \eta(x(t)) = H(t)x(t),\]
	pour $H : T \to \K^{n \times n}$ et $n = \dim(X) \in \N^*$.
	\end{prp}

	\begin{thm} Tout système dynamique linéaire régulier à temps continu peut être exprimé sous la forme~:
	\begin{align}
		\begin{cases}
			\od xt(t) &= A(t)x(t) + B(t)u(t) \\
			y(t) &= C(t)x(t),
		\end{cases}
	\end{align}
	avec $A : T \to \K^{\dim(X) \times \dim(X)}$, $B : T \to \K^{\dim(X) \times \dim(U)}$, et $C : T \to \K^{\dim(Y) \times \dim(X)}$, toutes trois continues
	en temps.
	\end{thm}

	\begin{rmq} Le cas des systèmes linéaires autonomes (où les fonctions $A, B, C$ sont constantes) est \textit{simple} à résoudre analytiquement (au sens où
	il existe une solution qu'il est possible de déterminer \textit{à la main}).
	\end{rmq}

	\begin{thm} Dans un système dynamique linéaire, la stabilité (respectivement instabilité) d'un mouvement en particulier implique la stabilité (respectivement
	l'instabilité) de tous les mouvements.
	\end{thm}

	\begin{proof} Soient $\hat x : T \to X$ et $\tilde x : T \to X$, les mouvements associés à l'entrée $\bar u \in \Omega$ et à l'état initial respectivement
	$x^{(1)} \in X$ et $x^{(2)} \in X$. On pose~:
	\[z : T \to X : t \mapsto \hat x(t) - \tilde x(t).\]

	Le mouvement $z$ correspond donc, par linéarité, à~:
	\[z(t) = \varphi(t, t_0, x^{(1)}, \bar u) - \varphi(t, t_0, x^{(2)}, \bar u) = \varphi(t, t_0, x{(1)}-x^{(2)}, \mathbf{0}) = \varphi_f(t, t_0, x^{(1)}-x^{(2)}).\]

	On sait cependant~:
	\[\begin{cases}
		\od {\hat x}t(t) &= A(t)\hat x(t) + B(t)\bar u(t) \\
		\od {\tilde t}t(t) &= A(t)\tilde x(t) + B(t)\bar u(t).
	\end{cases}\]

	Dès lors, on détermine la dynamique de $z$~:
	\[\od zt(t) = \od {\hat x}t(t) - \od {\tilde x}t(t) = A(t)\hat x(t) + B(t)\bar u(t) - A(t)\tilde x(t) - B(t)\bar u(t) = A(t)\left(\hat x(t) - \tilde x(t)\right) = A(t)z(t),\]
	qui a l'origine pour point fixe.

	Dès lors, en étudiant la stabilité de l'origine, on a la stabilité de tous les mouvements du système.
	\end{proof}

	\begin{cor} Dans un système dynamique linéaire, l'étude de stabilité ne dépend que de la matrice $A(t)$.
	\end{cor}

	\begin{déf} Un système dynamique linéaire est dit \textit{simplement stable} lorsque pour tout $x^{(0)} \in X$, le mouvement libre
	$t \mapsto \varphi_\ell(t, t_0, x^{(0)})$ est borné.

	Un système dynamique linéaire non stable est dit \textit{instable}.
	\end{déf}

	\begin{déf} Un système dynamique linéaire est dit \textit{asymptotiquement stable} lorsque~:
	\[\forall x^{(0)} \in X : \lim_{t \to +\infty}\varphi_\ell(t, t_0, x^{(0)}) = 0_X.\]
	\end{déf}

	\subsection{Stabilité et valeurs propres}

	\begin{déf} Soit $A \in \K^{n \times n}$ une matrice. On définit son polynôme caractéristique par~:
	\[\pi(A) \coloneqq \det(A - \lambda I).\]

	On appelle \textit{valeur propre} de $A$ tout $\lambda^* \in \K$ tel que $(\lambda - \lambda^*)$ divise $\pi(A)$.

	On appelle \textit{vecteur propre} de $A$ tout $v \in \K^n$ tel qu'il existe une valeur propre $\lambda$ avec $Av = \lambda v$.
	\end{déf}

	\begin{thm}[Stabilité d'un système linéaire selon les valeurs propres] Soit le système dynamique linéaire $\od xt(t) = A(t)x(t)$. Alors~:
	\begin{enumerate}
		\item le système est asymptotiquement stable si et seulement si toutes les valeurs propres de $A$ sont de partie réelle négative~;
		\item le système est simplement stable si toutes les valeurs propres ont soit une partie réelle négative, soit nulle mais sont de multiplicité 1~;
		\item le système est instable sinon.
	\end{enumerate}
	\end{thm}

	\begin{rmq} Il n'est pas toujours nécessaire de calculer toutes les valeurs propres de $A$ afin de déterminer la stabilité du système. Il existe certains
	critères pour le signe des valeurs propres.
	\end{rmq}

	\begin{thm}[Test de Hurwitz] Soit $A \in \K^{n \times n}$, pour $n = \dim(X) \in \N^*$. Soit $\pi(A)$ le polynôme caractéristique de $A$ tel que~:
	\[\pi(A)(\lambda) = \sum_{i=0}^na_i\lambda^{n-i},\]
	avec $a_0 = (-1)^n$. En posant $a_k = 0$ pour tout $k \gneqq n = \dim(X)$ et pour tout $k < 0$, on a que les valeurs propres de $A$ sont toutes de partie
	réelle négative si et seulement si~:
	\[H = [a_{2i-j}]_{1 \leq i,j \leq n}\]
	n'admet que des mineurs principaux positifs, i.e.~:
	\[\forall k \in \intint 1n : \det\left([a_{2i-j}]_{1 \leq i, j \leq k}\right) > 0.\]
	\end{thm}

	\begin{prp} Si tous les $a_i$, coefficients du polynôme caractéristique $\pi(A)$ ne sont pas de même signe (i.e. s'il en existe deux de signe différent),
	alors le système dynamique linéaire associé à $A$ n'est pas asymptotiquement stable.
	\end{prp}

	\begin{prp}[Formule de Souriau] Soit $A \in \K^{n \times n}$ une matrice. Les coefficients du polynôme~:
	\[\det(\lambda I - A) = (-1)^n\det(A - \lambda I) = \lambda^n\sum_{i=1}^n\lambda^{n-i}a_i,\]
	où $n = \dim(X)$, sont donnés par~:
	\[a_n = -\frac 1n\left(\Tr(A^n) + \sum_{k=1}^{n-1}a_k\Tr(A^{n-k})\right)\]
	\end{prp}

	\begin{rmq} La formule de Souriau permet de ne pas calculer le déterminant (complexité $O(n^3)$) pour de grandes matrices.
	\end{rmq}

	\begin{prp} Soit $A \in \K^{n \times n}$. Si $\lambda_1, \ldots, \lambda_p$ sont les valeurs propres de $A$, alors~:
	\[\sum_{i=1}^p\lambda_i = \Tr(A).\]
	\end{prp}

	\begin{proof} Par décomposition en blocs de Jordan (ou diagonalisation, si toutes les valeurs propres sont de multiplicité 1), on a~:
	\[A = PJP^{-1}.\]
	Par les propriétés de manipulation de trace, on a~:
	\[\Tr(A) = \Tr(PJP^{-1}) = \Tr(JP^{-1}P) = \Tr(J) = \sum_{i=1}^n\lambda_i.\]
	\end{proof}

	\begin{cor} Si un système dynamique linéaire $\od xt(t) = A(t)x(t)$ est asymptotiquement stable, alors $\Re\Tr(A) < 0$.
	\end{cor}

	\begin{proof} Un système linéaire est asymptotiquement stable si et seulement si toutes ses valeurs propres sont de partie réelle négative.
	On détermine donc~:
	\[\Tr(A) = \sum_{j=1}^n\lambda_j = \sum_{j=1}^n\Re\lambda_j + i\Im\lambda_j = \sum_{j=1}^n\Re\lambda_i + i\sum_{j=1}^n\Im\lambda_j.\]

	Et donc~:
	\[\Re\Tr(A) = \sum_{j=1}^n\Re\lambda_j < 0.\]
	\end{proof}

	\subsection{Systèmes linéaires du premier ordre}

	Soit $\od xt(t) = ax(t)$, pour $x : T \to R$ et $a \in \R$. La solution de cette équation est $x(t) = x(t_0)\exp(a(t-t_0))$. $x=0$ est un point d'équilibre du
	système. Pour $a < 0$, ce point d'équilibre est asymptotiquement stable, pour $a=0$, le système est simplement stable, et pour $a > 0$, le système est
	instable.

	\begin{déf} Dans le cas de stabilité asymptotique, quand $a < 0$, on définit $\tau \coloneqq \frac {-1}a \in \R_0^+$, que l'on appelle
	\textit{constante de temps}.
	\end{déf}

	\begin{rmq} Pour de grandes valeurs de $a$ (en valeur absolue), $\tau$ se rapprochera de 0, et donc le mouvement tend \textit{vite} vers l'origine, alors
	que pour de faibles valeurs de $a$ (toujours en valeur absolue), $\tau$ sera grand, et donc le mouvement tendra \textit{lentement} vers l'origine.

	On considère de manière générale que l'équilibre est atteint après un temps $\Delta t = 4\tau$. En effet~:
	\[x(t_0 + 4\tau) = x(t_0)\exp(a(t_0+4\tau-t_0)) = x(t_0)\exp(4a\tau) = x(t_0)\exp(-4) \simeq \frac {x(t_0)}{50}.\]

	On considère donc que proportionnellement, la valeur est suffisamment proche de l'origine.
	\end{rmq}

	Les comportements ici sont très restreints~: soit les trajectoires se rapprochent du point fixe ($x=0$), soit elles s'en éloignent, selon qu'il soit stable
	ou instable.

	\subsection{Systèmes linéaires autonomes du second ordre}

	Soit le système dynamique linéaire du second ordre suivant~:
	\[\begin{bmatrix}\od {x_1}t(t) \\\od {x_2}t(t)\end{bmatrix} = \od xt(t) = Ax(t)
		= \begin{bmatrix}a_{11} & a_{12} \\a_{21} & a_{22}\end{bmatrix}\begin{bmatrix}x_1(t) \\ x_2(t)\end{bmatrix}.\]

	\begin{déf} le système est dit \textit{simple} lorsque la matrice $A$ est non-singulière et est dit \textit{non-simple} sinon.
	\end{déf}

	\begin{prp} Un système dynamique linéaire du second ordre simple admet un unique point fixe, à savoir $(x_1, x_2) = (0, 0) = 0_X$.

	Un système dynamique linéaire du second ordre non-simple admet une infinité de points fixes représentant une droite vectorielle passant par l'origine.
	\end{prp}

	\begin{proof} Soit $A$ non-singulière. On sait donc que $A^{-1}$ existe. Dès lors, en multipliant $\od xt(t) = Ax(t)$ par $A^{-1}$ à gauche, on trouve~:
	\[A^{-1}\od xt(t) = x(t).\]

	Or, si $x(t)$ est un point fixe, on sait $\od xt(t) = 0$. Donc $x(t) = A^{-1}\od xt(t) = A^{-1}[0, 0]^T = [0, 0]^T$ est l'unique solution.

	Supposons maintenant $\det A = 0$. Ça implique que les deux lignes ou les deux colonnes de $A$ sont multiples l'une de l'autre. Il y a donc un degré de
	liberté au système, mais $(0, 0)$ reste une solution. Le système admet donc une infinité de points fixes placés sur une droite vectorielle passant par
	l'origine.
	\end{proof}

	\begin{prp} Le polynôme caractéristique de la matrice $A$ est équivalent à~:
	\[\pi(A)(\lambda) = \lambda^2 - \Tr(A) + \det(A).\]
	\end{prp}

	\begin{proof} Le polynôme caractéristique est donné par~:
	\[\pi(A)(\lambda) = (a_{11}-\lambda)(a_{22}-\lambda) - (a_{12}a_{21}) = \lambda^2 - (a_{11} + a_{22})\lambda + (a_{11}a_{22} - a_{21}a_{12}).\]

	On observe donc~:
	\[a_{11} + a_{22} = \Tr(A)\]
	et~:
	\[a_{11}a_{22} - a_{21}a_{12} = \det(A).\]

	On a alors en effet~:
	\[\pi(A)(\lambda) = \lambda^2 - \Tr(A)\lambda + \det(A).\]
	\end{proof}

	\begin{thm} Les solutions d'un système d'équations différentielles (pas nécessairement linéaires ou autonomes) est un espace vectoriel. En particulier,
	la combinaison linéaire de solutions sont également solutions.
	\end{thm}

	\subsection{Trajectoires et valeurs propres distinctes}

	Les axes des vecteurs propres sont des invariants. En effet, si $x(t)$ est un vecteur propre, alors $\od xt(t) = \lambda x(t)$, et donc $x(t)$
	et $\od xt(t)$ \textit{pointent} dans la même direction. Les vecteurs propres évoluent donc dans une trajectoire rectiligne (et se dirigent soit vers l'infini
	soit vers l'origine selon que l'origine soit stable ou non).

	Si $\lambda_1$ et $\lambda_2$ sont les deux valeurs propres de la matrice $A$ et si $v_1$ et $v_2$ sont les vecteurs propres associés, alors on
	a deux solutions distinctes et linéairement indépendantes~:
	\[t \mapsto \exp(\lambda_1t)v_1 \qquad\qquad \text{ et } \qquad\qquad t \mapsto \exp(\lambda_2t)v_2.\]

	La solution générale est donc~:
	\[t \mapsto C_1\exp(\lambda_1t)v_1 + C_2\exp(\lambda_2t)v_2,\]
	pour $C_1, C_2 \in \K$.

	\begin{prp} Pour $t \to +\infty$ (respectivement $t \to -\infty$), la trajectoire s'aligne avec le vecteur propre le plus lent (respectivement le plus rapide).
	\end{prp}

	\begin{proof} Soient $\lambda_1, \lambda_2$ les deux valeurs propres de $A$, telles que $\lambda_1 < \lambda_2$ (changer les indices si nécessaire, donc
	sans perte de généralité). On a alors~:
	\[\lim_{t \to +\infty}\frac {x_1(t)}{x_2(t)} = \lim_{t \to +\infty}\frac {C_2\exp(\lambda_2t)v_{21}}{C_2\exp(\lambda_2t)v_{22}} = \frac {v_{21}}{v_{22}}.\]

	De même, on trouve~:
	\[\lim_{t \to -\infty}\frac {x_1(t)}{x_2(t)} = \lim_{t \to -\infty}\frac {C_1\exp(\lambda_1t)v_{11}}{C_1\exp(\lambda_1t)v_{12}} = \frac {v_{11}}{v_{12}}.\]

	On en déduit donc qu'en $t \to +\infty$, la trajectoire s'aligne sur $v_2$, le vecteur propre lié à la valeur propre la plus lente, et pour $t \to -\infty$,
	la trajectoire s'aligne sur $v_1$, le vecteur propre lié à la valeur propre la plus rapide.
	\end{proof}

	\begin{déf} Si les deux valeurs propres de la matrice $A$ sont de partie réelle de signe opposé, alors l'origine est un état d'équilibre instable, que l'on
	appelle \textit{col} (ou encore \textit{nœud de selle}, \textit{saddle node} en anglais).

	Si les deux valeurs propres sont de partie réelle négative, alors l'origine est un état d'équilibre stable appelé \textit{nœud stable}.

	Si les deux valeurs propres sont de partie réelle positive, alors l'origine est un état d'équilibre instable et est appelé \textit{nœud instable}.
	\end{déf}

	\begin{rmq} Si le point d'équilibre est une selle, alors on trouve que $\det(A) = \lambda_1\lambda_2 < 0$ car les valeurs propres sont de signe opposé. Dans
	les deux autres cas, le déterminant est de signe positif. Mais c'est le signe de la trace qui change. Dans le cas de la selle, on ne peut rien prévoir sur
	le signe de la trace. La trace peut tout à fait être positive, négative, voire nulle.
	\end{rmq}

	\subsubsection{Systèmes non-simples}

	Les systèmes non-simples sont de déterminant nul. Or, comme $\det(A) = \lambda_1\lambda_2$, on sait qu'une des valeurs propres est nulle. Posons
	$\lambda_1 = 0$, et intéressons-nous à $\lambda_2$.

	\begin{prp} Si une des deux valeurs propres est nulle, alors la droite de points fixes est donnée par~:
	\[a_{11}x_1 + a_{12}x_2 = 0.\]

	De plus, toutes les trajectoires sont parallèles à $v_2$, le vecteur propre associé à la valeur propre $\lambda_2$, et les points fixes sont stables si et
	seulement si $\Re\lambda_2 < 0$.
	\end{prp}

	\subsection{Trajectoires et valeurs propres identiques (non-distinctes)}

	\begin{déf} Si $A$ est diagonalisable (et donc tous les vecteurs sont des vecteurs propres), et $\lambda_1 = \lambda_2 = \lambda \neq 0$, alors l'origine
	est un état d'équilibre que l'on appelle \textit{nœud singulier}.

	Si $A$ n'est pas diagonalisable (et donc il existe un seul vecteur propre, et donc une seule trajectoire en droite), l'origine est un état d'équilibre
	que l'on appelle \textit{nœud dégénéré}.
	\end{déf}

	\begin{rmq} Un nœud singulier ou un nœud dégénéré est stable si et seulement si $\lambda < 0$ (théorème de stabilité selon les valeurs propres, avec une
	seule valeur propre de partie réelle nulle).
	\end{rmq}


	\begin{rmq} Si $\lambda_1 = \lambda_2 = \lambda = 0$ est l'unique valeur propre, et de multiplicité 2, alors il existe une infinité d'états d'équilibre
	n'ayant pas de nom particulier mais dont toutes les trajectoires sont sur des droites parallèles.
	\end{rmq}

	\subsection{Trajectoires et valeurs propres complexes}

	\begin{prp}\label{prp:polynômeracinecomplexeconjugée} Soit $P$ un polynôme à coefficients réels. Si $\lambda \in \C$ est tel que $P(\lambda) = 0$, alors
	$P(\bar \lambda) = 0$.
	\end{prp}

	\begin{proof} Soit $n \in \N$ et soient $(a_i)_{0 \leq i \leq n} \in \R^n$ Notons $P : \C \to \C : x \mapsto \sum_{i=0}^na_ix^i$.
	Soit $\lambda \in \C$, une racine de $P$. On a~:
	\[P(\overline \lambda) = \sum_{i=1}^na_i\overline {\lambda^i} = \overline {\sum_{i=1}^na_i\lambda^i} = \overline {P(\lambda)} = \overline 0 = 0.\]
	\end{proof}

	\begin{cor} Tout polynôme de degré impair admet au moins une racine réelle.
	\end{cor}

	\begin{rmq} Ce qui peut également se démontrer par le théorème de Rolle, ou le théorème des accroissements finis.
	\end{rmq}

	On déduit de la Proposition~\ref{prp:polynômeracinecomplexeconjugée} que les deux racines propres sont obligatoirement deux complexes sous la forme~:
	\[\lambda_1 = a+ib \qquad\qquad \text{ et } \qquad\qquad \lambda_2 = \overline {\lambda_1} = a - ib,\]
	pour $a, b \in \R$.

	La solution générale devient donc
	\begin{align}\label{eq:solgénéralevalproprescomplexes}
		\begin{cases}
			x_1(t) &= \exp(at)\left( C_1\cos(bt) + C_2\sin(bt)\right) \\
			x_2(t) &= \exp(at)\left(-C_1\sin(bt) + C_2\cos(bt)\right).
		\end{cases}
	\end{align}

	\begin{déf} Dans un tel cas, lorsque $a = 0$, l'origine est un point d'équilibre que l'on appelle \textit{un centre} (les trajectoires forment des ellipses
	concentriques).

	Lorsque $a < 0$, l'origine est un point d'équilibre que l'on appelle \textit{un foyer stable}, et si $a > 0$, on l'appelle \textit{foyer instable}.
	\end{déf}

	\begin{prp} Un centre est un état d'équilibre simplement stable, un foyer stable est un état d'équilibre asymptotiquement stable, et un foyer instable est
	un état d'équilibre instable.
	\end{prp}

	\begin{proof} Par les théorèmes de stabilité par la partie réelle des valeurs propres.
	\end{proof}

	\begin{rmq} On observe que ces trois formes de systèmes sont oscillants de nature, même pour une fonction d'entrée inexistante (nulle).

	On observe également que l'équation~\eqref{eq:solgénéralevalproprescomplexes} montre bien que c'est de $a$ que dépend la stabilité, car $b$ n'intervient
	qu'en composition dans une fonction bornée (selon les constantes).
	\end{rmq}

	\begin{déf} Soit un système dynamique linéaire de dimension $n \in \N^*$. On appelle \textit{isocline} tout lieu de point tel que $\od {x_k}t = 0$.
	\end{déf}

	\begin{rmq} Les isoclines forment un hyper-plan de dimension $n-1$ séparant à chaque fois l'espace des phases en deux régions disjointes telles que le signe
	de la dérivée de $x_k$ y est opposé.

	Lors d'un dessin qualitatif, les isoclines servent donc à représenter les courbes sur lesquelles le champ de vecteur vitesse est orthogonal aux axes, et
	les parties de l'espace où ce champ de vecteurs est de signe constant (au sens de vecteur signe correspondant au signe de chaque composante).
	\end{rmq}

\section{Systèmes dynamiques non-linéaires à temps continu}

	Le modélisation linéaire est efficace car résoluble analytiquement, mais correspond toujours à une simplification forte de la réalité. Ces systèmes ne
	correspondent souvent à la réalité modélisée que dans certains cas, mais peut devenir très mauvaise tant dans l'explication que dans la prédiction.

	\subsection{Bifurcations}

	\begin{déf} Soit un système dynamique non-linéaire paramétrisé par $r \in \K^d$. On appelle \textit{bifurcation} le phénomène qui amène un changement
	qualitatif de l'évolution du système suite à un changement du paramètre $r$. Ce changement peut être soit le changement de stabilité d'un ou plusieurs
	état(s) d'équilibre, soit la création ou la suppression d'un ou plusieurs état(s) d'équilibre.

	On appelle \textit{valeur critique} ou \textit{valeur de bifurcation} toute valeur de $r$ entraînant un tel changement.
	\end{déf}

	\begin{déf} On appelle \textit{diagramme de bifurcation} le graphique avec le paramètre $r$ sur l'axe horizontal et les points fixes $\bar x$ sur l'axe
	vertical où la position de chaque état d'équilibre est représentée ainsi que sa stabilité (la trajectoire d'un état stable est représentée par une courbe
	pleine alors que la trajectoire d'un état instable est représenté par une courbe en pointillés).
	\end{déf}

	\subsection{Linéarisation de systèmes non-linéaires}

	\begin{déf} Soit $S$ un système dynamique autonome non-linéaire à temps continu régi par le problème de Cauchy suivant~:
	\[\begin{cases}
		\od {\bar x}t(t) &= f(x(t), u(t)) \\
		\bar x(t_0) &= {\bar x}^{(0)}
	\end{cases}\qquad\qquad (t_0, {\bar x}^{(0)}) \in T \times X,\]

	Le mouvement de ce système est $\bar x : T \to X : t \mapsto \varphi(t, t_0, {\bar x}^{(0)}, u)$, avec $u \in \Omega$, l'entrée du système.

	On appelle \textit{système linéarisé associé au système et au mouvement $t \mapsto \bar x(t) \in X$} le système~:
	\[\od xt(t) = A(t)x(t) + B(t)u(t),\]
	avec~:
	\[A(t) = \pd fx(\bar x(t), u(t)) \qquad\qquad \text{ et } \qquad\qquad B(t) = \pd fu(\bar x(t), u(t)).\]
	\end{déf}

	\begin{prp} Le système linéarisé associé à un système $S$ autour d'un mouvement $t \mapsto \bar x(t)$ est une approximation du premier
	ordre du système original autour de $\bar x(t)$.
	\end{prp}

	\begin{proof} Soient $(\delta u, \delta x^{(0)}) \in \Omega \times X$. Soit $\delta \bar x \in X^T$ tel que~:
	\[\od {\bar x}t(t) + \od {\delta \bar x}t(t) = f\left(\bar x(t) + \delta \bar x(t), u(t) + \delta u(t)\right).\]

	Par expansion de Taylor, on trouve~:
	\[\od {\bar x}t(t) + \od {\delta \bar x}t(t) = f(\bar x(t), u(t), t) + \pd fx(\bar x(t), u(t))\delta \bar x(t) + \pd fu(\bar x(t), u(t))\delta u(t) + o(\bar x(t)) + o(u(t)).\]

	En soustrayant $\od xt(t)$ de part et d'autre et en omettant les termes d'ordre supérieur, on obtient~:
	\[\od {\delta \bar x}t(t) = \pd fx(\bar x(t), u(t))\delta \bar x(t) + \pd fu(\bar x(t), u(t))\delta u(t).\]

	Posons alors~:
	\[A(t) = \pd fx(\bar x(t), u(t)) \qquad\qquad \text{ et } \qquad\qquad B(t) = \pd fu(\bar x(t), u(t)).\]

	Il s'ensuit~:
	\[\od {\delta \bar x}t(t) = A(t)\delta \bar x(t) + B(t)\delta u(t).\]

	Dès lors, le système linéarisé fournit bien une approximation (du premier ordre par Taylor) pour de faibles perturbations (proche de $\bar x(t)$).
	\end{proof}

	\begin{rmq} Il est intéressant d'étudier le système linéarisé proche des états d'équilibre car il y a alors moyen d'en inférer des propriétés de stabilité.
	\end{rmq}

		\subsubsection{Linéarisation et stabilité}

	\begin{thm} Soit $S$ un système dynamique autonome non-linéaire, et soit $\bar x \in X$, un point d'équilibre de $S$ pour une entrée $\bar u \in \Omega$. Si
	le système linéarisé associé au mouvement $t \mapsto \bar x(t)$ autour de $\bar x$ est asymptotiquement stable, alors $\bar x$ est asymptotiquement stable
	pour $\od xt(t) = f(x(t), u(t))$.

	De même si le système linéarisé est instable, alors $\bar x$ est instable pour $\od xt(t) = f(x(t), u(t))$.
	\end{thm}

	\begin{rmq} On ne peut donc rien déduire d'un système linéarisé simplement stable.
	\end{rmq}

	\subsection{Systèmes dynamiques non-linéaires à temps continu d'ordre 1}

	On se concentre sur les systèmes définis par $\od xt(t) = f(x(t)) \in \R = X$.

		\subsubsection{Méthode géométrique}

	En traçant le graphique de $\od xt$ en fonction de $x$, on peut déduire les point d'équilibre, leur stabilité, et les trajectoires du système.

	En effet, toutes les valeurs de $x$ telles que $f(x)$ s'annule donnent les points fixes du système. Également, le signe de $f(x)$ donne une information
	sur la croissance ou décroissance de $x$, et donc de sa direction.

	Sur base du graphique, on peut alors déduire quatre types d'états d'équilibre $\bar x$ (points fixes de $t \mapsto x(t)$) de $\bar x$~:
	\begin{itemize}
		\item si $f$ est négative à gauche\footnote{On appelle ici \textit{gauche} de $\bar x$ l'ensemble $(-\infty, \bar x)$ et \textit{droite} l'ensemble
		$(x, +\infty)$.} de $\bar x$ et positive à droite de $\bar x$, alors l'état d'équilibre est instable~;
		\item si $f$ est positive à gauche de $\bar x$ et négative à droite, alors $\bar x$ est un état d'équilibre asymptotiquement stable~;
		\item si $f$ est négative à gauche de $\bar x$ et à droite de $\bar x$, alors l'état d'équilibre $\bar x$ est \textit{semi-asymptotiquement stable à
		droite}~;
		\item et si $f$ est positive à gauche et à droite de $\bar x$, alors l'état d'équilibre $\bar x$ est \textit{semi-asymptotiquement stable à gauche}.
	\end{itemize}

	\begin{rmq} Sur un graphique d'équilibre de $f$ en fonction de $x$, il est de convention de marquer les points stables par des cercles pleins, les points
	instables par des cercles vides, et les points semi-stables par des cercles semi-remplis du côté stable.
	\end{rmq}

	\begin{prp} Dans le cas d'un système d'ordre 1, la trajectoire $x : T \subseteq \R \to X = \R$ suit un mouvement monotone pour tout état initial.
	\end{prp}

	\begin{proof} Les comportements sont, en dimension 1, très limités~: une trajectoire peut soit converger vers un point fixe, soit diverger vers l'infini.

	En effet, en supposant $f$ continue, on oblige qu'un changement de signe de $f$ induise un point fixe (de stabilité asymptotique ou instable). Pour que la
	trajectoire puisse «~rebrousser chemin~», il lui faudrait passer un point fixe, ce qui est impossible~: les points fixes ne sont atteints qu'en $t \to \pm \infty$
	et ne sont jamais traversés en dimension 1.
	\end{proof}

	\begin{cor} Une trajectoire ne peut pas suivre de courbe périodique.
	\end{cor}

	\begin{thm} Soit un système dynamique (linéaire ou non-linéaire) autonome. Par un point de l'espace des phases passe au plus une trajectoire.
	\end{thm}

	\begin{proof} Soit un point tel qu'il existe une solution passant par ce point (Cauchy-Lipschitz dont le caractère lipschitzien de $f$ est supposé dans tous
	les cas). $\od xt = f$ admet une unique valeur en ce point. Donc toute trajectoire passant par ce point doit suivre la même tangente, et donc la même trajectoire.

	Supposons qu'il existe deux trajectoires (mouvements $t \mapsto \hat x(t)$ et $t \mapsto \tilde x(t)$) distinctes passant par ce point. On a bien une
	contradiction car $f$ devrait admettre deux valeurs distinctes.
	\end{proof}

	\subsection{Systèmes dynamiques non-linéaires à temps continu d'ordre 2}

	\begin{déf} Une trajectoire est dite \textit{isolée} lorsqu'elle n'est pas transformation de ses trajectoires avoisinantes.
	\end{déf}

	\begin{déf} Un \textit{cycle limite} est une trajectoire close isolée.
	\end{déf}

	\begin{déf} Soit $C$, un cycle limite.

	\begin{itemize}
		\item $C$ est dit \textit{simple} (ou \textit{attracteur}) lorsque les trajectoires avoisinantes convergent vers $C$~;
		\item $C$ est dit \textit{instable} lorsque les trajectoires avoisinantes divergent de $C$~;
		\item $C$ est dit \textit{semi-stable} lorsque les trajectoires internes (respectivement externes) à $C$ convergent vers $C$, alors que les trajectoires
		externes (respectivement internes) à $C$ divergent de $C$.
	\end{itemize}
	\end{déf}

	\begin{rmq} Un cycle limite stable implique des oscillations spontanées du système, même en l'absence d'entrée périodique. De plus, ces cycles ne peuvent
	exister dans un système linéaire (bien que des oscillations soient possibles par des trajectoires circulaires en cas de valeurs propres complexes) car un
	système linéaire a des propriétés générales~: des trajectoires isolées n'existent pas.
	\end{rmq}

	\begin{rmq} Il est difficile de déterminer si un système d'ordre 2 admet ou non un cycle limite.
	\end{rmq}

	\begin{thm}[Théorème de Bendixon] Soit $R$ une région close, connexe et bornée de l'espace des phases bidimensionnel. Si la fonction~:
	\[t \mapsto \scpr {\nabla f}{\mathbf 1}(t),\]
	pour $\mathbf 1 : t \mapsto 1$, est de signe constant sur $R$ et s'annule sur un ensemble de mesure nulle, alors $R$ ne contient aucun cycle limite.
	\end{thm}

	\begin{thm}[Théorème de Poincaré] Soit $R$, une région close, bornée et annulaire (au sens où $R \setminus D \simeq D$) de l'espace des phases
	bidimensionnel. S'il n'existe aucun état d'équilibre dans $R$, et si toutes les trajectoires passant par $\partial R$ (le bord de $R$) sont entrantes dans
	$R$, alors il existe au moins un cycle limite dans $R$.
	\end{thm}

	\begin{rmq} Ce théorème affirme à nouveau que la famille des trajectoires en dimension 2 est limité.
	\end{rmq}

	\subsection{Invariants}

	\begin{déf} Un \textit{invariant} d'un système dynamique est un sous-ensemble $I$ de dimension $d \lneqq n$ de son espace des phases $X$ tel que~:
	\[\forall x \in X^T : \forall t_0 \in T : \left(x(t_0) \in I \Rightarrow \left(\forall t \in T : t \geq t_0 \Rightarrow x(t) \in I\right)\right).\]
	\end{déf}

	\begin{rmq} On impose $\dim(I) \lneqq \dim(X)$ car le seul sous-ensemble (à isomorphisme près) de $X$ de même dimension que $X$ est $X$. $X$ est
	donc un invariant trivial de $X$.
	\end{rmq}

		\subsubsection{Invariants dans un espace des phases de dimension 1}

	Il n'existe que des points de $X$ comme sous-ensembles de dimension 0, les seuls invariants d'un système de dimension 1 sont les points fixes.

		\subsubsection{Invariants dans un espace des phases de dimension 2}

	Deux types d'invariants sont possibles~: les points d'équilibre, \textbf{et} les cycles. Il existe également des trajectoires dites respectivement
	\textit{hétérocliniques} et \textit{homocliniques}. Les premières rejoignent un point fixe à un autre, et les secondes sont des trajectoires cycliques
	contenant un point fixe.

		\subsubsection{Invariants dans un espace des phases de dimension 3}

	Les points fixes sont toujours des invariants, mais les cycles ont alors la possibilité d'être continûment déformés et donc de suivre plusieurs circuits
	\textit{indépendants}.

	En dimension 2, des surfaces de type ellipsoïdal ou torique peuvent être des invariants.

	\begin{déf} Soient $\theta$ et $\phi$ les coordonnées angulaires permettant de reporter la trajectoire le long d'un tore. On note $T_\theta$ et $T_\phi$
	la période relative à chacune des coordonnées.

	Si $\frac {T_\theta}{T_\phi} \in \Q$, la trajectoire est une orbite close le long du tore. Si $\frac {T_\theta}{T_\phi} \in \R \setminus \Q$, les
	trajectoires sont des hélices qui forment une partition de la surface du tore. On dit d'une telle trajectoire qu'elle est \textit{quasi-périodique}.
	\end{déf}

	\begin{rmq} Certains invariants en dimension $n = \dim(X) \geq 3$ peuvent être des fractales.
	\end{rmq}

	\subsection{Fractales}

	Au sens algébrique strict du terme, la dimension représente le nombre de coordonnées minimum nécessaire pour exprimer chaque point de manière univoque.
	Pour un espace vectoriel, c'est donc la cardinalité d'une base quelconque, et donc un nombre naturel. Les fractales sont des objets géométrique dimension
	fractionnaire voire irrationnelle.

	\begin{déf} Soit un espace euclidien $E \simeq \R^d$ pour un $d \in \N^*$. Pour $\varepsilon \in \R_0^+$, on définit $c_E(\varepsilon)$, le cube (de dimension
	$d$) de côté $\varepsilon$. Considérons $E$ comme \textit{pavé} par des cubes $c_E(\varepsilon)$.

	Soit $S$ une partie bornée de $\R^d$. On définit $\mathcal N_E^S(\varepsilon) \in \N$ le nombre maximal de cubes $c_E(\varepsilon)$ du pavage dont
	l'intersection avec $S$ est non-nulle.
	\end{déf}

	\begin{déf} Soit un espace euclidien $\R^d$ pavé d'hyper-cubes $c_E(\varepsilon)$ pour $\varepsilon \in \R_0^+$. Soit $S$ une partie bornée de $\R^d$.
	On appelle \textit{dimension de Hausdorff de $S$} la quantité~:
	\[D_H(S) \coloneqq \lim_{\varepsilon \to 0}\frac {\log \mathcal N_E^S(\varepsilon)}{-\log\varepsilon}.\]
	\end{déf}

	\begin{rmq} Pour des parties de dimension $d$ dans l'espace euclidien $\R^d$, la dimension de Hausdorff correspond bien avec la notion de dimension
	vectorielle associée aux espaces vectoriels. En effet, si $S$ est de dimension 2, la quantité $\mathcal N_E^S(\varepsilon)$ va croitre comme
	$\varepsilon^{-2}$. Et donc $D_H(S)$ sera 2. De même, en dimension $d=3$, le volume croit comme le cube de $\varepsilon^{-1}$, et la dimension de
	Hausdorff est 3.

	Mais de manière plus générale, la dimension de Hausdorff est une valeur réelle et non une valeur naturelle.
	\end{rmq}

	\begin{déf} Un objet géométrique est appelé \textit{fractal} lorsqu'il possède au moins une des caractéristiques suivantes~:
	\begin{enumerate}
		\item il est invariant d'échelle (similarités à des échelles arbitraires)~;
		\item il est trop compliqué pour être décrit par la géométrie traditionnelle~;
		\item il est autosimilaire~;
		\item sa dimension de Hausdorff n'est pas naturelle.
	\end{enumerate}
	\end{déf}

	\begin{rmq} Lorsqu'un objet fractal est trop compliqué à décrire, on l'exprime par un processus itératif de fragmentation.

	Soient un espace euclidien $\R^d$, un partie non-vide bornée $F \subset \R^d$, et $r \in (0, 1)$. Prenons $N \in \N^*$ copies conformes de $F$ telles que~:
	\[Nr^d \in (0, 1),\]
	et assemblons-les.
	\end{rmq}

	\begin{prp} Soient l'espace euclidien $\R^d$, et $F$ une partie non-vide bornée de $\R^d$. Soient $(N, r) \in \N^* \times (0, 1)$ les paramètres de
	fragmentation de $F$. Alors~:
	\[D_H(F) = \frac {\log N}{-\log r}.\]
	\end{prp}

	\begin{proof} En considérant l'espace comme pavé d'hyper-cubes $c_E(\varepsilon)$, posons $k \in \N^*$ l'étape de fragmentation. On trouve~:
	\[\mathcal N_{\R^d}^F(\varepsilon) = N^k.\]

	De même, à la $k$ème étape, on trouve~:
	\[\varepsilon = r^k.\]

	On trouve finalement~:
	\[D_H(F) = \lim_{\varepsilon \to 0}\frac {\log \mathcal N_{\R^d}^F(\varepsilon)}{-\log\varepsilon} = \lim_{k \to +\infty}\frac {k\log N}{-k\log r}
		= \frac {\log N}{-\log r}\]
	\end{proof}

	\begin{rmq} $r \in (0, 1)$, dès lors $\log r \in \R_0^-$. Donc $-\log r \in \R_0^+$, $D_H(F)$ reste bien une quantité positive.
	\end{rmq}

	\begin{rmq} \textbf{Attention: } cette formule alternative ne tient que pour les objets fractals auto-similaires, car sinon les paramètres $(N, r)$ ne
	sont pas définis.
	\end{rmq}

		\subsubsection{Attracteurs}

	\begin{déf} Soient $X \simeq \R^n$, un espace de phases, et $B \subseteq X$, une partie non-vide et bornée de $X$. Pour tout $x \in X$, on définit
	la distance entre $x$ et $B$ par~:
	\[d_X(x, B) \coloneqq \min\left\{d_X(x, b) \tq c \in B\right\}.\]
	\end{déf}

	\begin{déf} Une partie $A \subset X$ de l'espace des phases est un \textit{attracteur} lorsque~:
	\begin{enumerate}
		\item $A$ est un invariant~;
		\item $\exists U \in \mathcal V(A)$ ouvert et $u \in \Omega$ tels que~:
			\[\forall (t, t_0) \in T^2 : x(t_0) \in U \Rightarrow d_X(x(t), A) \xrightarrow[t \to +\infty]{} 0~;\]
		\item $A$ est minimal.
	\end{enumerate}
	\end{déf}

	\begin{déf} Un attracteur fractal est appelé \textit{attracteur étrange}.
	\end{déf}

		\subsubsection{Chaos et exposant de Liapounov}

	Il est question de \textit{comportement chaotique} (ou plus simplement \textit{chaos}) lorsqu'un système déterministe devient impossible à prédire au-delà
	d'un certain intervalle temporel, peu importe la précision de la condition initiale.

	La \textit{dépendance sensible aux conditions initiales} (ou \textit{sensitive dependence on initial conditions} en anglais) est le fait que deux trajectoires
	arbitrairement proches l'une de l'autre divergent l'une de l'autre et adoptent un comportement qualitativement différent, ce qui rend également les
	prédictions impossibles à faire.

	\begin{déf} Soient $S$ un système dynamique avec les mouvements $t \mapsto x(t)$ et $t \mapsto \bar x(t)$ tels que pour $\delta : T \to X$, on a~:
	\[x(t) = \bar x(t) - \delta(t).\]

	Si, pour $t \geq t_0$, on approxime $\delta(t)$ par $\norm {\delta(t)} \simeq \norm {\delta(t_0)}\exp\left(\lambda(t-t_0)\right)$, pour un certain $\lambda$
	réel, on appelle ce paramètre l'\textit{exposant de Liapounov} du système.
	\end{déf}

	\begin{déf} Si l'exposant de Liapounov d'un système est strictement positif, alors on dit que ce système est fortement dépendant des conditions initiales.
	\end{déf}

	\begin{rmq} Si $t_0 = 0$, alors $\log \norm {\delta(t)} \simeq \log \norm {\delta(0)} + \lambda t$. L'exposant de Liapounov est alors la pente de la droite
	$t \mapsto \log \norm {\delta(t)}$. On peut alors estimer $\lambda$ par régression linéaire de $\log \norm {\delta(t)}$.
	\end{rmq}

	\begin{déf} Soient un système dynamique $S$ dont l'exposant de Liapounov est positif, et $\delta : T \to X$. Soit $\Delta \in \R_0^+$ tel que les mesures
	sont acceptables si $\norm {\delta(t)} \leq \Delta$. On définit l'\textit{horizon de prédictibilité induit par $\Delta$} l'intervalle de temps $[t_0, t_h]$,
	avec~:
	\[T \ni t_h = t_0 + \frac 1\lambda \log\frac \Delta{\norm {\delta(t)}}.\]
	\end{déf}

	\begin{rmq} Cet intervalle correspond à l'ensemble des instants $t$ tels que l'erreur induite par l'erreur initiale est acceptée.

	La longueur de cet intervalle est inversement proportionnelle à l'exposant de Liapounov, et proportionnelle au $\log$ de $\Delta$. Dès lors, même en
	augmentant l'ordre de grandeur de $\Delta$ et en diminuant celui de $\delta(t_0)$, cet intervalle ne s'agrandira que, proportionnellement, très peu.
	\end{rmq}

\section{Systèmes dynamiques à temps discret}
	Les systèmes à temps discret sont beaucoup plus simples à manipuler par ordinateurs car il n'est pas nécessaire d'avoir recours à des algorithmes
	d'intégration numérique. De plus, ils peuvent être parfois plus adaptés que des modèles continus, et les dynamiques chaotiques y sont plus facilement
	générées.

	\begin{déf} Soit $S = (T, U, \Omega, X, Y, \Gamma, \varphi, \eta)$ un système dynamique où $T$ est un ensemble discret (dénombrable car infini).

	Lorsque le système est décrit par l'\textit{équation vectorielle aux différences} suivante~:
	\[\begin{cases}
		x(t+1) &= f(x(t), u(t), t) \\
		y(t) &= \eta(t, x(t)),
	\end{cases}\]
	on dit que le système est \textit{synchrone à temps discret}.
	\end{déf}

	\begin{rmq} Il est possible de changer l'\textit{échelle de temps} de manière à avoir toujours un écart $x(t+1) = f(\ldots)$ car on considère que tous les
	points consécutifs de $T$ sont équidistants.
	\end{rmq}

	\begin{déf} Lorsque $f$ et $\eta$ ne dépendent pas explicitement du temps, le système est dit \textit{invariant}.
	\end{déf}

	\begin{déf} Un \textit{système synchrone à temps discret linéaire} est déterminé par les trois «~matrices~»~:
	\[\begin{cases}
		A &: T \to \R^{\dim(X) \times \dim(X)}, \\
		B &: T \to \R^{\dim(X) \times \dim(U)}, \\
		C &: T \to \R^{\dim(Y) \times \dim(X)},
	\end{cases}\]
	et est exprimé sous la forme~:
	\[\begin{cases}
		x(t+1) &= A(t)x(t) + B(t)u(t), \\
		y(t) &= C(t)x(t).
	\end{cases}\]
	\end{déf}

	\begin{rmq} Dans les systèmes à caractère continu, la représentation appropriée était les équations différentielles. Concernant les systèmes à caractère
	discret, on préfère les équations aux différences.
	\end{rmq}

	\begin{déf} Pour tout $k \in T$, on pose $x_k \coloneqq x(k) \in X$. Soit $f : T \times X^n$. On appelle \textit{forme normale de l'équation aux différences
	d'ordre $n$} l'équation récursive suivante~:
	\begin{align}\label{eq:eqdifférences}\tag{\#}
		x_{k+n} = f(k, x_{k+n-1}, \ldots, x_k).
	\end{align}
	\end{déf}

	\subsection{Solutions d'une équation aux différences}

	\begin{déf} Toute fonction $x : T \to X$ satisfaisant~\eqref{eq:eqdifférences} est appelée \textit{solution de~\eqref{eq:eqdifférences}}.

	L'ensemble de toutes les solutions d'une équation aux différences est appelé sa solution générale.
	\end{déf}

	\begin{thm} Toute équation aux différences d'ordre $n \in \N^*$ admet exactement une solution pour tout $n$-uple $(x(t_0), x(t_0+1), \ldots, x(t_0+n-1)) \in X^n$.
	\end{thm}

	\begin{thm} Pour toute solution $x_p : T \to X$ d'une équation aux différences non-homogène, si $x_h : T \to X$ est solution de l'équation homogène associée,
	alors $x_p+x_h : T \to X$ est solution de l'équation non-homogène.
	\end{thm}

	\begin{thm} L'ensemble de solution générale d'une équation aux différences est un espace vectoriel fonctionnel.
	\end{thm}

	\begin{déf} Soit l'équation aux différences linéaire homogène suivante~:
	\[\sum_{k=0}^na_kx(t+k) = 0.\]
	On appelle \textit{polynôme caractéristique} le polynôme suivant~:
	\[P : \lambda \mapsto \sum_{k=0}^na_k\lambda^k.\]
	\end{déf}

	\begin{déf} Pour une équation aux différences linéaire et homogène et son polynôme caractéristique $P$, on appelle \textit{équation caractéristique}
	l'équation suivante~:
	\[P(\lambda) = 0.\]
	\end{déf}

	\begin{rmq} Et par le théorème fondamental de l'algèbre, il existe $n$ solutions complexes (multiplicité prise en compte).
	\end{rmq}

	\begin{prp} Soit $\lambda \in \R$, solution de l'équation caractéristique. Posons $m(\lambda)$ la multiplicité de cette racine. Alors~:
	\[x : t \mapsto t^k\lambda^t\]
	est une solution de l'équation aux différences pour $k = 0, \ldots, m(\lambda)-1$, et toutes ces solutions sont linéairement indépendantes.
	\end{prp}

	\begin{rmq} En travaillant avec des polynômes, on prend pour convention $0^0 = 1$.
	\end{rmq}

	\begin{prp} Soit $\lambda = \rho\exp(i\theta) \in \C$, solution de l'équation caractéristique. Alors~:
	\[x_1 : t \mapsto t^k\rho\cos(t\theta) \qquad\qquad \text{ et } \qquad\qquad x_2 : t \mapsto t^k\rho\sin(t\theta)\]
	sont solutions de l'équation aux différences pour $k = 0, \ldots m(\lambda)-1$, et toutes ces $2m(\lambda)$ solutions sont linéairement indépendantes.
	\end{prp}

	\subsection{États d'équilibre}

	\begin{déf} Soit une équation aux différences linéaire et homogène~:
	\[\sum_{k=0}^na_kx(t+k) = b.\]

	Un état d'équilibre de l'équation est un état $\bar x \in X$ tel que la fonction constante $x : t \mapsto \bar x$ est une solution.
	\end{déf}

	\begin{prp} Soit l'équation aux différences linéaire homogène suivante~:
	\[\sum_{k=0}^na_kx(t+k) = b.\]

	Alors~:
	\begin{itemize}
		\item si $\sum_{k=0}^na_k \neq 0$, alors il existe un unique état fixe donné par~:
		\[X \ni \bar x = \frac b{\sum_{k=0}^na_k}~;\]
		\item sinon~:
		\begin{itemize}
			\item si $b = 0$, alors tout $\bar x \in X$ est un point d'équilibre~;
			\item si $b \neq 0$, alors le système n'admet aucun point d'équilibre.
		\end{itemize}
	\end{itemize}
	\end{prp}

	\begin{déf} Soit $\bar x \in X$ un état d'équilibre. $\bar x$ est dit \textit{stable} lorsque~:
	\[\forall \varepsilon > 0 : \exists \delta > 0, t_0 > 0 \tq \sum_{j=0}^{n-1}\abs {x(j)-\bar x} < \delta \Rightarrow
		\forall t > t_0 : \abs {x(t)-\bar x} < \varepsilon.\]
	\end{déf}

	\begin{déf} Un équilibre $\bar x \in X$ est dit \textit{asymptotiquement stable} (ou \textit{attractif}) lorsque~:
	\[\lim_{t \to +\infty}x(t) = \bar x.\]
	\end{déf}

	\begin{thm}[Équilibre d'une équation aux différences linéaire] Soit $P$ le polynôme caractéristique d'une équation aux différences et soit $\bar x \in X$ une
	équilibre de cette équation. Alors $\bar x$ est~:
	\begin{itemize}
		\item stable si et seulement si toute solution $\lambda_i$ de $P$ est telle que
		$\abs {\lambda_i} \leq 1$ et $\abs {\lambda_i} = 1 \Rightarrow m(\lambda_i) = 1$~;
		\item asymptotiquement stable si et seulement si toute solution $\lambda_i$ de $P$ est telle que $\abs {\lambda_i} \lneqq 1$.
	\end{itemize}
	\end{thm}

	\subsection{Équations non-linéaires homogènes d'ordre 1}

	On parle ici d'équations aux différences sous la forme~:
	\[x(t+1) = f(x(k)),\]
	avec $f \in C^\infty(T, I \subset X)$. Ce système est noté par le couple $(f, I)$.

	\begin{déf} La valeur $\bar x \in I$ est dite d'\textit{équilibre} pour le système $(f, I)$ lorsque~:
	\[\bar x = f(\bar x).\]
	\end{déf}

	\begin{thm} Soient $I = [a, b]$ un intervalle réel et $f : I \to I$ continue. Alors il existe $\bar x \in I$ d'équilibre pour $(f, I)$.
	\end{thm}

	\begin{déf} L'équilibre $\bar x \in I$ est dit \textit{globalement attractif} (ou \textit{globalement asymptotiquement stable}) lorsque~:
	\[\forall x^0 \in I : x(t_0) = x^0 \Rightarrow \lim_{t \to +\infty}x(t) = \bar x.\]

	Et l'équilibre $\bar x$ est dit \textit{localement attractif} (ou \textit{localement asymptotiquement stable}) lorsque~:
	\[\exists \delta > 0 \tq \forall x^0 \in I \cap [\bar x \pm \delta] : x(t_0) = x^0 \Rightarrow \lim_{t \to +\infty}x(t) = \bar x.\]
	\end{déf}

		\subsubsection{Cycles et stabilité}

	\begin{déf} Soit $(f, I)$ un système discret d'ordre 1. On appelle \textit{cycle d'ordre $s \in \N^*$} tout ensemble $\{\bar x^{(k)} \tq 0 \leq k < s\}$
	tel que~:
	\[\bar x^{(0)} = f(\bar x^{(s-1)}) \qquad\qquad \text{ et } \qquad\qquad \forall 1 \leq k \lneqq s : \bar x^{(k)} = f(\bar x^{(k-1)}).\]

	On dit également que $s$ est la \textit{période} du cycle.
	\end{déf}

	\begin{thm} Soit un système discret d'ordre 1 $(f, I)$. L'ensemble $\{\bar x^{(k)} \tq 0 \leq k \lneqq s\}$ pour $s \in \N^*$ est un cycle de période $s$
	de $f$ si et seulement si les $\bar x^{(k)}$ sont des équilibres de $f^s$ et ne sont cycle d'aucun $f^\sigma$ pour $\sigma \in \{1, \ldots, s-1\}$.
	\end{thm}

	\begin{thm} Soit $(f, I)$ un système discret d'ordre 1 et soit $\bar x \in I$ un équilibre de $(f, I)$.

	\begin{itemize}
		\item Si $\abs {f'(\bar x)} \lneqq 1$, alors $\bar x$ est localement attractif~;
		\item si $\abs {f'(\bar x)} \gneqq 1$, alors $\bar x$ est instable~;
		\item si $\abs {f'(\bar x)} = 1$, $\bar x$ peut être soit stable soit instable.
	\end{itemize}
	\end{thm}

	\begin{thm} Si selon les hypothèses précédentes, $\abs {f'(\bar x)} = 1$, alors~:
	\begin{itemize}
		\item si $f''(\bar x) \lneqq 0$, alors $\bar x$ est supérieurement attractif et inférieurement instable~;
		\item si $f''(\bar x) \gneqq 0$, alors $\bar x$ est inférieurement attractif et supérieurement instable.
	\end{itemize}
	\end{thm}

		\subsubsection{Attracteurs et bifurcations}

	\begin{déf} Soit $(f, I)$ un système discret d'ordre 1. Un ensemble $A \subset I$ est appelé \textit{attracteur} lorsque~:
	\begin{enumerate}
		\item $f(A) = A$~;
		\item $A$ est le plus petit ensemble (au sens de l'inclusion) tel qu'il existe $\delta > 0$ tel que~:
		\[\left(\forall x(0) \in I : d_I(x(0), A) < \delta\right) \Rightarrow \lim_{t \to +\infty} d_I(x(t), A) = 0.\]
	\end{enumerate}
	\end{déf}

	\begin{déf} L'ensemble $\{x(0) \in I \tq \lim_{t \to +\infty} d_I(x(t), A) = 0\}$ est appelé \textit{bassin d'attraction}.
	\end{déf}

	\begin{déf} Soit $(f_a, I)$ un système discret d'ordre 1 tel que la fonction $f$ dépend continûment d'un paramètre $a \in A \subset \R$.
	La valeur $\bar a \in A$ est une \textit{valeur de bifurcation} si pour tout $\varepsilon > 0$, il existe une discontinuité dans
	$\overline N_{f_a}(a)$ sur $(\bar a \pm \varepsilon)$, où $\overline N_{f_a} : A \to \N$ retourne le nombre d'équilibres de $f_a$ pour la valeur $a$
	du paramètre.
	\end{déf}

	\begin{rmq} Des systèmes très simples tels que l'équation logistique discrète~:
	\[x(t+1) = ax(t)(1 - x(t))\]
	admettent une infinité de valeurs de bifurcations, et ont un comportement chaotique pour certaines valeurs de $a$.
	\end{rmq}

	\begin{déf} Soit $(f, I)$ un système discret d'ordre 1. Ce système est dit \textit{chaotique} lorsque~:
	\begin{itemize}
		\item $\forall (a, b) \subseteq I$, il existe au moins un cycle dans $(a, b)$~;
		\item \[\forall (x, y, \varepsilon) \in I \times I \times \R_0^+ : \exists (z, k) \in I \times \N \tq
			\abs {z-x} < \varepsilon \qquad \text{ et } \quad \abs {f^k(z) - y} < \varepsilon~;\]
		\item \[\exists \delta > 0 \tq \forall (x, \varepsilon) \in I \times \R_0^+ :
			\exists (z, k) \in I \times \N \tq \abs {z-x} < \varepsilon \quad \text{ et } \quad \abs {f^k(x)-f^k(z)} > \delta,\]
		ce qui correspond à  la dépendance aux conditions initiales.
	\end{itemize}
	\end{déf}

	\begin{rmq} Dans les systèmes discrets, le chaos peut apparaître dès l'ordre 1 (équation logistique), contrairement aux systèmes continus où il faut un
	ordre $\geq 3$.
	\end{rmq}

	\begin{déf} Soit $(f, I)$ un système d'ordre 1. On définit l'\textit{exposant de Liapounov} par~:
	\[L \coloneqq \lim_{N \to +\infty}\frac 1N\sum_{t=0}^{N-1}\ln \abs {\frac {\delta(t+1)}{\delta(t)}},\]
	avec $\delta : T = \N \to I$ telle que~:
	\[\forall t \in T : \delta(t) = f^t\left(x(0) + \delta(x(0))\right) - x(t),\]
	et avec $\delta(0)$ une perturbation initiale.
	\end{déf}

	\begin{rmq} L'exposant $L$ de Liapounov représente le taux moyen de divergence par itération.
	\end{rmq}

	\begin{déf} Si un système discret d'ordre 1 $(f, I)$ a un exposant de Liapounov $L$ positif, alors il est dit chaotique.
	\end{déf}

\end{document}
